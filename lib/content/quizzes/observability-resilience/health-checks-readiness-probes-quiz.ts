/**
 * Quiz questions for Health Checks & Readiness Probes section
 */

export const healthChecksQuiz = [
  {
    id: 'q1',
    question:
      'Explain the difference between liveness probes, readiness probes, and startup probes. When should each be used, and what happens when each fails?',
    sampleAnswer:
      'Liveness, readiness, and startup probes serve different purposes in Kubernetes and load balancer health checking. **Liveness Probe**: Question: "Is the application running?" Purpose: Detect deadlocked or crashed applications. Check: Very simple (just respond to HTTP request). When Fails: Kubernetes restarts the container. Example: app.get("/healthz/live", (req, res) => res.status(200).send("OK")); Use When: App might deadlock, hang, or enter unrecoverable state. **Readiness Probe**: Question: "Is the application ready to serve traffic?" Purpose: Determine if instance should receive requests. Check: Dependencies (database, cache, required services). When Fails: Kubernetes removes pod from service (load balancer stops sending traffic). Pod stays running, just doesn\'t receive requests. Example: Check database connection, Redis connection, cache warmed up. Use When: App depends on external services that might be temporarily unavailable. **Startup Probe**: Question: "Has the application finished starting up?" Purpose: Give slow-starting applications more time before liveness checks begin. Check: Startup completion status (data loaded, initialization done). When Fails: After many attempts (e.g., 30 × 10s = 5 minutes), restart container. Example: Large data loading, JVM warm-up, cache pre-population. Use When: App takes > 30 seconds to start. **Key Differences**: What they check: Liveness (can app respond at all?), Readiness (ready for traffic?), Startup (finished initializing?). What happens on failure: Liveness (restart), Readiness (remove from LB), Startup (eventual restart after long timeout). What to check: Liveness (minimal), Readiness (dependencies), Startup (initialization status). **Example Scenario - API Server**: Liveness: app.get("/healthz/live") → Just return 200 (proves app can respond). Readiness: app.get("/healthz/ready") → Check database.ping(), redis.ping(), cacheWarmed. Startup: app.get("/healthz/startup") → Check dataLoaded flag (loads 1GB dataset on start). **Flow**: 1. Pod starts → Startup probe checks every 10s. 2. After 60s, data loaded → Startup passes. 3. Readiness probe checks dependencies → Database connected → Passes. 4. Pod receives traffic. 5. Liveness probe checks continuously → App responsive → Stays running. **Common Mistake**: Using same endpoint for liveness and readiness. If database goes down: Readiness should fail (stop traffic) but liveness should pass (don\'t restart). If liveness checks database and fails → restarts app → database still down → infinite restart loop.',
    keyPoints: [
      'Liveness: Is app running? Restart if fails. Minimal checks.',
      'Readiness: Ready for traffic? Remove from LB if fails. Check dependencies.',
      'Startup: Finished starting? Long timeout for slow apps.',
      'Different endpoints: /healthz/live, /healthz/ready, /healthz/startup',
      "Don't check dependencies in liveness (causes restart loops)",
    ],
  },
  {
    id: 'q2',
    question:
      'What should you check in a liveness probe versus a readiness probe? Provide examples of checks that belong in each and explain the consequences of checking the wrong things.',
    sampleAnswer:
      'The distinction between liveness and readiness checks is critical. Checking dependencies in liveness causes restart loops. **Liveness Probe (Minimal Checks Only)**: ✅ Check: Can application respond to HTTP request? Application not deadlocked. ❌ DON\'T Check: Database connectivity, External API availability, Cache status, Disk space, Dependent services. **Why Minimal**: Liveness failure → Restart container. Restarting won\'t fix external dependency issues. Example: If liveness checks database, and database goes down → App restarts → Database still down → App restarts again → Infinite loop! **Liveness Examples**: Good: app.get("/healthz/live") → return 200 (proves app alive). Good: Check internal state (not deadlocked, can allocate memory). Bad: await database.ping() (DON\'T check external deps). Bad: await externalAPI.call() (DON\'T check dependencies). **Readiness Probe (Comprehensive Checks)**: ✅ Check: Database connectivity, Cache/Redis connectivity, Required configuration loaded, Dependent services available, Sufficient disk space, Memory not exhausted. ❌ DON\'T Check: Non-critical dependencies, Slow external APIs (unless critical), Time-consuming operations. **Why Comprehensive**: Readiness failure → Remove from load balancer (don\'t restart). Safe to check dependencies because it only affects traffic routing. Example: Database down → Readiness fails → No traffic sent to pod → Pod stays alive → When database recovers, readiness passes, traffic resumes. **Readiness Examples**: Good: await database.ping() (critical dependency). Good: await redis.ping() (cache dependency). Good: check cacheWarmedUp flag. Good: check diskUsage < 90%. Bad: await fetch("http://analytics-service") (non-critical). Bad: run expensive query (too slow). **Consequences of Wrong Checks**: **Database in Liveness (❌ Wrong)**: Database goes down (maintenance, failure). Liveness probe fails (can\'t connect to DB). Kubernetes restarts all pods. Pods restart but database still down. Liveness fails again immediately. Infinite restart loop → Complete outage! **Database in Readiness (✅ Right)**: Database goes down. Readiness probe fails. Pods removed from load balancer. Pods stay running (not restarted). When database recovers, readiness passes. Pods added back to load balancer. Graceful degradation instead of crash loop! **Non-Critical Service in Readiness (❌ Wrong)**: Analytics service (non-critical) is slow. Readiness probe times out. All pods marked unhealthy. All traffic stops → Complete outage for non-critical dependency! **Practical Configuration**: Liveness (simple): app.get("/healthz/live") → res.status(200).send("OK"). 10s period, 3 failures, 5s timeout. Readiness (comprehensive): app.get("/healthz/ready") → check DB, Redis, config. 5s period, 2 failures, 3s timeout. **Best Practice**: If in doubt, check in readiness, not liveness. Liveness should almost never check external dependencies.',
    keyPoints: [
      'Liveness: Minimal (can app respond?), no external dependencies',
      'Readiness: Comprehensive (database, cache, dependencies)',
      'Wrong: Database in liveness → restart loop when DB down',
      'Right: Database in readiness → graceful traffic removal',
      'Rule: If unsure, check in readiness not liveness',
    ],
  },
  {
    id: 'q3',
    question:
      'How do you implement graceful shutdown with readiness probes? Walk through what should happen when a pod receives a SIGTERM signal.',
    sampleAnswer:
      'Graceful shutdown ensures in-flight requests complete before pod terminates, preventing connection errors for users. Readiness probes play a critical role in this process. **The Problem Without Graceful Shutdown**: Pod receives SIGTERM (kubectl delete pod, deployment update). Pod terminates immediately (kills process). In-flight requests mid-processing. Connections abruptly closed → Users see errors. Load balancer still sending traffic → Requests fail. **The Solution - Graceful Shutdown Process**: **Step 1: Receive SIGTERM** (from Kubernetes): Kubernetes decides to terminate pod (rolling update, scale down). Sends SIGTERM signal to application. Gives grace period (default 30 seconds) before force kill (SIGKILL). **Step 2: Mark as Not Ready** (Immediately): Application handles SIGTERM signal. Sets readiness probe to fail (return 503). Readiness probe fails → Kubernetes removes pod from service endpoints. Load balancer stops sending new requests to this pod. **Step 3: Allow In-Flight Requests to Complete**: Continue processing existing requests. Don\'t accept new requests (readiness failing). Wait for all in-flight requests to finish. Timeout after grace period (e.g., 25 seconds of 30s grace period). **Step 4: Close Connections**: Close database connections. Close Redis connections. Flush buffers, logs. Save state if needed. **Step 5: Exit Cleanly**: Process exits with code 0. Kubernetes confirms termination. **Implementation Example**: let isShuttingDown = false; let server; // Readiness probe app.get("/healthz/ready", (req, res) => { if (isShuttingDown) { return res.status(503).send("Shutting down"); } // Check dependencies res.status(200).send("Ready"); }); // Handle SIGTERM process.on("SIGTERM", async () => { console.log("SIGTERM received, starting graceful shutdown"); isShuttingDown = true; // Mark as not ready setTimeout(() => { console.log("Grace period ended, forcing shutdown"); process.exit(0); }, 25000); // 25s of 30s grace period // Wait for in-flight requests server.close(() => { console.log("All connections closed"); process.exit(0); }); }); **Timeline**: T+0s: SIGTERM received. T+0.1s: isShuttingDown = true. T+0.2s: Readiness probe fails. T+1s: Kubernetes removes pod from service. T+1-25s: In-flight requests complete. T+25s: Connections closed, process exits. **Why This Works**: Readiness fails immediately → Load balancer stops sending new traffic (within 1-2 seconds). Existing requests have 25+ seconds to complete (plenty of time for most requests). Users don\'t see errors from connections closed mid-request. **Common Mistakes**: **Not marking readiness as failed**: Load balancer continues sending traffic → Requests fail. **Too short grace period**: In-flight requests don\'t have time to complete → Connection errors. **No SIGTERM handler**: Process killed immediately → Abrupt shutdown. **Best Practices**: Grace period > longest request duration (if p99 = 5s, grace period = 30s). Handle SIGTERM in all applications. Test graceful shutdown (kubectl delete pod, verify no errors). Monitor connection errors during deployments.',
    keyPoints: [
      'Graceful shutdown: Complete in-flight requests before terminating',
      'Step 1: Receive SIGTERM, mark readiness as failed immediately',
      'Step 2: Load balancer stops new traffic (1-2 seconds)',
      'Step 3: Complete existing requests (up to grace period)',
      'Step 4: Close connections, exit cleanly',
    ],
  },
];
