/**
 * Quiz questions for PII Detection & Removal section
 */

export const piidetectionremovalQuiz = [
  {
    id: 'pii-det-q-1',
    question:
      'Your PII detector uses regex patterns for email, phone, SSN. It misses 20% of PII in testing. A user\'s credit card number "4532 1234 5678 9010" passes through undetected.Design a comprehensive PII detection system combining regex, NER, and context- aware detection.How do you achieve > 95 % detection rate while keeping false positives < 5 %? ',
    hint: 'Consider multiple detection methods and validation strategies.',
    sampleAnswer:
      '**Problem:** Regex-only PII detection: 80% recall (misses 20%). Need: >95% detection rate, <5% false positives. **Multi-Method PII Detection:** **Method 1: Enhanced Regex Patterns** - Credit cards: Add pattern r"\\\\b(?:4[0-9]{12}(?:[0-9]{3})?|5[1-5][0-9]{14})\\\\b". Validate with Luhn algorithm (checksums). Phone numbers: Multiple formats: US: +1-555-123-4567, (555) 123-4567, 555.123.4567. International: +44 20 1234 5678. Email: Standard pattern but validate TLDs. SSN: r"\\\\b(?!000|666|9\\\\d{2})\\\\d{3}-(?!00)\\\\d{2}-(?!0{4})\\\\d{4}\\\\b". **Method 2: NER (Named Entity Recognition)** - Use model: StanfordAIMI/stanford-deidentifier-base. Detects: PERSON names, LOCATION, ORGANIZATION, DATE (potential DOB), ID numbers. Catches: "John Smith" (name not caught by regex). "Lives in 123 Main Street" (address). **Method 3: Context-Aware Detection** - Check context around potential PII: If number preceded by "SSN:", "Social Security:", "Card number:". If email-like string in context "contact me at", "email:", "reach me". Implementation: def check_context(text, match, match_type): window = text[max(0, match.start-20):match.end+20]. if match_type == "number": if any(kw in window.lower() for kw in ["ssn", "social security", "card",]): confidence = 0.95. return True, confidence. return False, 0.5. **Combined System:** def detect_pii_comprehensive(text): all_pii = []. # Method 1: Regex, regex_matches = regex_detector.detect(text). all_pii.extend(regex_matches). # Method 2: NER, ner_matches = ner_detector.detect(text). all_pii.extend(ner_matches). # Method 3: Context validation, validated_pii = []. for pii in all_pii: is_valid, confidence = validate_with_context(text, pii). if confidence > 0.7: validated_pii.append(pii). # Deduplicate, unique_pii = deduplicate_overlapping(validated_pii). return unique_pii. **Validation & False Positive Reduction:** (1) Luhn check for credit cards (reduces false positives). (2) Verify email TLD exists (.com, .org, not .asdf). (3) Phone number length validation (10-15 digits). (4) Name validation: Check if appears in common name database. **Testing:** Test set: 1000 texts with labeled PII. Results before: Regex only: 80% recall, 3% false positive. Results after (multi-method): Combined: 96% recall ✓, 4.5% false positive ✓. **Cost Analysis:** Regex: <1ms, free. NER: ~50ms, $0.0001 per request. Context validation: ~5ms, free. Total: ~56ms, $0.0001 per request. Acceptable.',
    keyPoints: [
      'Combine regex, NER, and context-aware detection',
      'Validate detected PII with algorithms (Luhn, TLD check)',
      'Use context to improve confidence and reduce false positives',
      'Test on diverse PII types to ensure >95% recall',
    ],
  },
  {
    id: 'pii-det-q-2',
    question:
      'You must implement GDPR Article 17 (Right to Erasure) for your AI system. A user requests deletion of all their data. Design a comprehensive data deletion system covering: logs, databases, backups, third-party systems, and caches. How do you ensure complete deletion while maintaining audit trails required by law?',
    hint: 'Consider data inventory, deletion cascades, and retention requirements.',
    sampleAnswer:
      '**GDPR Article 17:** User has right to request deletion of personal data. Must delete from: All systems, databases, logs, backups, third-party systems. Exception: Can retain data required by law (audit logs for compliance). **Comprehensive Deletion System:** **Step 1: Data Inventory** - Know where user data exists: Primary database: User table, interactions table. Logs: Application logs (contain user IDs, prompts). Caches: Redis (user sessions). Backups: Daily database backups (last 30 days). Third-party: Analytics (Mixpanel), Support (Zendesk). Create data map: USER_DATA_LOCATIONS = {database: ["users", "interactions", "sessions",], logs: ["app.log", "safety.log",], cache: ["redis://sessions",], backups: ["s3://backups/",], third_party: ["mixpanel", "zendesk",]}. **Step 2: Deletion Process** - Mark for deletion: UPDATE users SET deleted_at = NOW(), email = \'DELETED\', name = \'DELETED\' WHERE user_id = \'user_123\'. Keep user_id for audit trail, delete PII. Delete associated data: DELETE FROM interactions WHERE user_id = \'user_123\'. DELETE FROM sessions WHERE user_id = \'user_123\'. Purge from cache: redis.delete(f"session:{user_id}"). **Step 3: Log Anonymization** - Logs contain PII (prompts, responses). Can\'t delete logs entirely (needed for audits). Solution: Anonymize: Replace user_id in logs: sed -i \'s/user_123/DELETED_USER/g\' app.log. Or: Pseudonymize: user_123 → anonymous_abc123 (irreversible hash). Retain: Aggregate data (request counts, no PII). **Step 4: Backup Handling** - Backups contain deleted data. GDPR: Must delete from backups or make inaccessible. Approaches: (1) Incremental deletion: Next backup excludes deleted user. Old backups expire naturally (30-day retention). Mark: Add to "deleted_users" table. If restoring backup, re-apply deletions. (2) Backup encryption with data-specific keys: Encrypt user data with user-specific key. On deletion: Delete encryption key → Data unreadable. **Step 5: Third-Party Deletion** - Use APIs to delete from third parties: Mixpanel: mixpanel.people.delete_user(user_id). Zendesk: zendesk.users.delete(user_id). Verify: Check deletion completed successfully. **Step 6: Verification** - Confirm deletion: Query all systems: SELECT * FROM users WHERE user_id = \'user_123\';  # Should return no PII. grep "user_123" logs/  # Should return only anonymized. Check cache, backups, third-parties. Generate deletion report: {"user_id": "user_123", "deletion_date": "2024-01-15", "systems_deleted": ["database", "logs", "cache", "mixpanel", "zendesk",], "retained": [{"system": "audit_logs", "reason": "legal_requirement", "data": "user_id only"}]}. **Audit Trail (Retain for Compliance):** - What to retain: User ID (not other PII). Deletion request date. Systems deleted from. Reason for deletion (user request). Why retain: Prove compliance if questioned. Prevent re-registration abuse. Legal requirement in some jurisdictions. How: Store in separate audit database: CREATE TABLE deletion_audit (user_id VARCHAR, deletion_date TIMESTAMP, requested_by VARCHAR, reason VARCHAR, systems_deleted JSON). **Automation:** def delete_user_data(user_id, reason): audit_id = log_deletion_request(user_id, reason). # Step 1: Mark deleted in database, db.execute("UPDATE users SET deleted_at = NOW() WHERE user_id = %s", user_id). # Step 2: Delete associated data, db.execute("DELETE FROM interactions WHERE user_id = %s", user_id). # Step 3: Anonymize logs, anonymize_logs(user_id). # Step 4: Clear cache, redis.delete(f"session:{user_id}"). # Step 5: Third-party deletion, for service in THIRD_PARTY_SERVICES: service.delete_user(user_id). # Step 6: Record completion, complete_deletion_audit(audit_id, systems_deleted=["db", "logs", "cache", "third_party",]). return {"deleted": True, "audit_id": audit_id}. **Timeline:** User requests deletion → Confirm identity → Execute deletion (within 24 hours) → Verify completion → Send confirmation email → Keep audit record (forever). **GDPR Compliance:** Article 17: Deletion within 1 month (we do 24 hours ✓). Exceptions: Legal compliance data retained (audit logs ✓). Proof: Deletion audit trail available for data protection authority.\',',
    keyPoints: [
      'Create complete inventory of where user data exists',
      'Delete from all systems: database, logs, cache, backups, third-parties',
      'Anonymize logs instead of deletion (for audit compliance)',
      'Retain minimal audit trail: user ID, deletion date, proof of compliance',
    ],
  },
  {
    id: 'pii-det-q-3',
    question:
      'Your PII detector flags 25% of requests as containing PII, but manual review shows only 10% actually have PII (15% false positives). Design a strategy to reduce false positives while ensuring zero PII leakage in production. How do you balance detection sensitivity with system usability?',
    hint: 'Consider precision-recall tradeoff and adaptive thresholds.',
    sampleAnswer:
      '**Problem:** 25% flagged, 10% actual PII → 60% precision (25-10=15 false positives). False positive rate: 15% (too high). Need: Reduce false positives while maintaining 100% recall (catch all real PII). **Analysis of False Positives:** Common false positives: (1) Numbers that look like phones but aren\'t: "Call me at extension 5551" (not a phone number). "My score is 555-123-4567" (score format, not phone). (2) Email-like strings: "support@example dot com" (not valid email). "john[at]company.com" (obfuscated email, intentionally not valid). (3) Names that are common words: "This doc was created by Word" (Word = program, not person). "Contact support" (Support = team name, not person). **Optimization Strategy:** **Strategy 1: Confidence Scoring** - Assign confidence to each detection: def detect_with_confidence(text): matches = regex_detect(text). scored_matches = []. for match in matches: confidence = calculate_confidence(match, text). scored_matches.append((match, confidence)). return scored_matches. def calculate_confidence(match, text): confidence = 1.0. # Reduce confidence for suspicious patterns, if match.type == "phone": if "extension" in surrounding_text(match, text): confidence *= 0.5  # Likely not a real phone number. if match.type == "email": if "dot com" in match.value or "[at]" in match.value: confidence *= 0.3  # Obfuscated, not real email. if match.type == "name": if match.value in COMMON_WORDS: confidence *= 0.4  # Likely not a person name. return confidence. Threshold: Only flag if confidence > 0.7. Result: 25% → 12% flagged, false positive rate: 15% → 3%. **Strategy 2: Context Validation** - Check context to validate PII: if detect_email(text): # Check if preceded by contact keywords, context = get_surrounding_text(email_match). if any(kw in context for kw in ["email:", "contact:", "reach me",]): is_real_pii = True, confidence = 0.95. else: is_real_pii = False, confidence = 0.4. **Strategy 3: Allowlist** - Common false positives → allowlist: ALLOWLIST_PATTERNS = ["extension [0-9]+", "score is [0-9-]+", "dot com"  # "example dot com", "support@"  # Generic support email]. Before flagging: if any(pattern in text for pattern in ALLOWLIST_PATTERNS): skip_pii_detection(). **Strategy 4: NER Validation** - Use NER to validate detections: regex_match = "John Word". ner_result = ner_model("John Word"). if ner_result.label == "PERSON" and ner_result.confidence > 0.8: real_pii = True. else: # "Word" might be Microsoft Word, not a person name, real_pii = False. **Strategy 5: Luhn/Format Validation** - Validate numbers: credit_card_candidate = "1234 5678 9012 3456". if luhn_check(credit_card_candidate): real_credit_card = True. else: just_random_numbers = True. **Combined System:** def detect_pii_optimized(text): # Step 1: Initial detection, candidates = regex_detect(text) + ner_detect(text). # Step 2: Filter allowlist, candidates = [c for c in candidates if not in_allowlist(c)]. # Step 3: Score confidence, scored = [(c, calculate_confidence(c, text)) for c in candidates]. # Step 4: Validate with context, validated = [(c, conf) for c, conf in scored if validate_context(c, text)]. # Step 5: Threshold, final_pii = [c for c, conf in validated if conf > 0.7]. return final_pii. **Balancing Sensitivity:** Goal: Zero PII leakage (100% recall) + Low false positives (<5%). Approach: (1) Layer 1 (Regex): High recall (catch everything), confidence-scored. (2) Layer 2 (Context): Reduce false positives. (3) Layer 3 (Validation): Final filter. Threshold tuning: Confidence 0.9: Block (certain PII). Confidence 0.7-0.9: Redact + flag for review. Confidence <0.7: Allow (likely false positive). **Testing:** Test set: 1000 texts. Before: 25% flagged, 10% real PII, 15% false positive. After: 11% flagged, 10% real PII, 1% false positive ✓. Recall: 100% (all real PII caught) ✓. **Monitoring:** Track: PII detection rate (should stabilize around 10%). False positive rate (measure via user feedback). PII leakage incidents (should be 0). Adjust thresholds based on feedback.',
    keyPoints: [
      'Use confidence scoring to distinguish real PII from false positives',
      'Validate with context, NER, and format checks (Luhn)',
      'Allowlist common false positive patterns',
      'Set adaptive thresholds: high confidence block, medium review, low allow',
    ],
  },
];
