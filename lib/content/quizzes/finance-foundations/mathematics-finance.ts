export const mathematicsFinanceQuiz = [
    {
        id: 'mf-q-1',
        question:
            'Build a portfolio optimization system using Modern Portfolio Theory (Markowitz): (1) Calculate expected returns (use historical means or factor models), (2) Build covariance matrix (pairwise correlations), (3) Efficient frontier (optimize for all risk levels), (4) Sharpe-optimal portfolio (max Sharpe ratio), (5) Constraints (no shorting, position limits, sector exposure). Include: rebalancing logic (monthly or when drift >5%), transaction cost modeling (commissions + slippage), out-of-sample testing (train on 3 years, test on 1 year). Handle edge cases: singular covariance matrix (highly correlated assets), negative expected returns, unbounded solutions. How do you scale to 1000+ assets?',
        sampleAnswer: `Portfolio optimization implementation: Expected returns estimation: historical mean (simple: mean of past 252 days), factor models (CAPM: return = rf + beta × market_premium, Fama-French 3-factor), shrinkage (James-Stein estimator: shrink individual estimates toward grand mean to reduce estimation error), Covariance matrix: historical covariance (np.cov(returns.T)), exponentially weighted (recent data weighted more: lambda=0.94), ledoit-wolf shrinkage (shrink toward diagonal matrix to avoid singular matrix), Efficient frontier: for target_returns in [0.05, 0.06, ..., 0.20], solve: minimize w^T Σ w subject to w^T μ = target_return, sum(w) = 1, 0 ≤ w ≤ 1 (long-only), generate 100 portfolios along frontier, plot risk vs return, Sharpe-optimal: maximize (w^T μ - rf) / sqrt(w^T Σ w), equivalent to minimizing variance per unit excess return, scipy.optimize.minimize with objective = -sharpe_ratio, Constraints implementation: bounds: [(0, 1)] × n_assets for long-only, [(0, 0.10)] for max 10% per position, {'type': 'eq', 'fun': lambda w: sum(w) - 1} for fully invested, {'type': 'ineq', 'fun': lambda w: 0.30 - w[tech_indices].sum()} for max 30% tech sector, Rebalancing: calculate current_weights = position_values / total_value, target_weights from optimization, drift = abs(current - target), if max(drift) > 0.05 (5%), execute rebalances, Transaction costs: shares_traded = (target - current) × portfolio_value / price, commission = max($1, $0.005 × shares) per trade, slippage = half_spread for limit orders or 1 basis point estimate, total_cost = sum(commission + slippage), subtract from expected_return in optimization, Out-of-sample testing: split data into train (2018-2020) and test (2021), optimize weights on train period, execute strategy on test period (monthly rebalance), calculate realized Sharpe ratio, compare to benchmark (SPY), Edge cases: singular covariance (rank-deficient): add regularization (cov + lambda × I where lambda=1e-5), use Ledoit-Wolf shrinkage, remove highly correlated assets (correlation >0.95), negative expected returns: set minimum expected return constraint (μ ≥ 0.03), or allow shorting with bounds [(-0.30, 1.30)], unbounded solutions: always include position limits (max 20% per asset), check optimization convergence (result.success), Scale to 1000+ assets: sparse optimization (most weights will be zero, use L1 regularization), hierarchical risk parity (cluster assets, allocate between clusters, then within), index sampling (optimize on 100 representative stocks instead of all 1000), cloud computing (AWS Lambda for parallel optimizations per strategy).`,
        keyPoints: [
            'Expected returns: Historical mean, factor models (CAPM/Fama-French), shrinkage estimators (James-Stein) to reduce estimation error',
            'Covariance: Historical cov, exponentially weighted (lambda=0.94), Ledoit-Wolf shrinkage to avoid singular matrix',
            'Optimization: Minimize variance subject to target return + sum(w)=1 + bounds, maximize Sharpe = (return-rf) / sqrt(variance)',
            'Constraints: Long-only [(0,1)], position limits [(0, 0.10)], sector limits (sum of sector weights ≤ 30%)',
            'Scaling: Sparse optimization (L1 regularization), hierarchical risk parity (cluster first), index sampling (100 representative stocks)',
        ],
    },
    {
        id: 'mf-q-2',
        question:
            'Implement Monte Carlo simulation for option pricing and risk analysis: (1) Geometric Brownian motion (dS = μS dt + σS dW), (2) Price path generation (10,000 simulations), (3) Option payoff calculation (call, put, exotic options), (4) Greeks via finite differences (delta, gamma, vega), (5) Value at Risk (VaR 95%, 99%). Include variance reduction techniques (antithetic variates, control variates). How do you handle: path-dependent options (Asian, barrier)? Early exercise (American options)? Multiple assets (basket options, correlation)? Validate against Black-Scholes for European options.',
        sampleAnswer: `Monte Carlo options pricing: Geometric Brownian Motion: dS/S = μ dt + σ dW discretized as: S(t+dt) = S(t) × exp((μ - σ²/2) dt + σ √dt × Z) where Z ~ N(0,1), use log-space to ensure positive prices, Path generation: for each simulation: S_path = [S0], for t in range(steps): Z = np.random.normal(), S_next = S_path[-1] × exp((r - 0.5×σ²)×dt + σ×sqrt(dt)×Z), S_path.append(S_next), European option payoff: call = max(S_T - K, 0), put = max(K - S_T, 0), Asian option: average_S = mean(S_path), payoff = max(average_S - K, 0), Barrier option: if any(S_path > barrier): payoff = 0 (knock-out), else: payoff = max(S_T - K, 0), Option price = exp(-r×T) × mean(payoffs) across simulations, Greeks via finite differences: delta: price_up = MC(S + dS), price_down = MC(S - dS), delta = (price_up - price_down) / (2×dS), gamma = (price_up - 2×price + price_down) / dS², vega: price_vol_up = MC(S, σ + dσ), vega = (price_vol_up - price) / dσ, use same random seed for finite differences (reduce variance), Value at Risk: run MC on portfolio (sum of option values), sort final values ascending, VaR_95 = percentile(final_values, 5) - initial_value (5% chance of losing this much or more), VaR_99 = percentile(final_values, 1), Variance reduction: antithetic variates: for each Z, also simulate with -Z (paired opposites reduce variance), control variates: price European call with MC and BS, adjustment = BS_price - MC_price, apply adjustment to exotic option price, importance sampling: sample more frequently in regions that matter (near strike for options), American options (early exercise): Longstaff-Schwartz LSM algorithm: simulate paths forward, at each time step, regress continuation value on current stock price, if exercise value > continuation value, exercise, Multiple assets: S1(t+1) = S1(t) × exp(...), S2(t+1) = S2(t) × exp(...), use correlated random numbers: Z = cholesky(corr_matrix) @ Z_independent, basket option payoff = max(w1×S1 + w2×S2 - K, 0), Validation: European call price by MC should match Black-Scholes within 1% (if 10K sims), increase simulations until convergence (100K+ for accurate Greeks).`,
        keyPoints: [
            'GBM: S(t+1) = S(t) × exp((μ - σ²/2)dt + σ√dt×Z), use log-space for positive prices, discretize with small dt (1 day)',
            'Option payoffs: European (max(S_T - K, 0)), Asian (average price), barrier (knock-out if hits level), discount at risk-free rate',
            'Greeks: Delta via finite diff (price(S+dS) - price(S-dS))/2dS, gamma second derivative, use same random seed to reduce noise',
            'VaR: Sort simulated portfolio values, VaR_95 = 5th percentile loss, VaR_99 = 1st percentile (worst 1% outcome)',
            'Variance reduction: Antithetic variates (simulate Z and -Z), control variates (adjust using known BS price), importance sampling',
        ],
    },
    {
        id: 'mf-q-3',
        question:
            'Design a statistical arbitrage system using principal component analysis (PCA): (1) Collect returns for 50 correlated stocks (e.g., all tech stocks), (2) Perform PCA to identify common factors, (3) Calculate stock-specific residuals (return not explained by factors), (4) Mean-reversion strategy on residuals (z-score >2 = short, <-2 = long), (5) Portfolio construction (equal-weight, factor-neutral). Include: rolling PCA (recalculate monthly), regime detection (change in factor structure), risk management (stop-loss, position limits). How do you ensure factor neutrality? How do you handle changing factor loadings? Backtest on 5 years of data.',
        sampleAnswer: `PCA stat arb system: Data collection: fetch daily returns for 50 tech stocks (AAPL, MSFT, GOOGL, ...) for 5 years, returns_matrix shape = (1260 days, 50 stocks), PCA decomposition: center returns (returns - mean), covariance matrix Σ = cov(returns), eigenvalues, eigenvectors = eig(Σ), sort by eigenvalues descending, first 3-5 PCs typically explain 60-80% variance, Factor loadings: factor_loadings = eigenvectors[:, :n_factors], stocks' exposure to each factor, Stock returns decomposition: factor_returns = returns @ factor_loadings (common factors), residuals = returns - (factor_returns @ factor_loadings.T), residuals are stock-specific moves not explained by factors, Mean-reversion strategy: for each stock: z_score = (residual - rolling_mean) / rolling_std (use 20-day rolling), if z_score > 2: short stock (expecting revert to mean), if z_score < -2: long stock, if abs(z_score) < 0.5: close position, Portfolio construction: equal weight all signals (if 10 stocks trigger, each gets 10% portfolio weight), factor neutrality: portfolio_factor_exposure = sum(weights × factor_loadings), should be ≈ 0 for each factor, adjust weights using optimization: minimize sum(abs(portfolio_factor_exposure)) subject to sum(abs(weights)) = 1, Rolling PCA: recalculate PCA monthly using last 252 days, factor structure changes over time (e.g., tech factor strength varies), update factor_loadings, recompute residuals, Regime detection: track explained_variance_ratio = eigenvalues / sum(eigenvalues), if first PC explains >50% (normally 30-40%), market-wide regime (crisis mode), reduce leverage, eigenvalue time series shows structural breaks (e.g., COVID crash changed correlations), Risk management: stop-loss: close position if loss >2% on single stock, position limits: max 5% per stock, max 50% total leverage, drawdown control: if portfolio drawdown >10%, reduce positions 50%, Changing factor loadings: stocks rotate between factors (e.g., TSLA becomes less tech-factor, more auto-factor), detect using rolling regression: regress stock returns on factor returns, if R² decreases (factor explains less), stock structure changed, exclude from strategy temporarily, Backtest: train PCA on 2018-2019, trade 2020, roll forward (retrain monthly), calculate: Sharpe ratio (target >1.5 for stat arb), market neutrality (beta to SPY ≈ 0), turnover (daily turnover <20% for transaction costs), compare to: long-only tech portfolio, market-neutral benchmark (dollar-neutral longs+shorts).`,
        keyPoints: [
            'PCA: Center returns, compute eigenvectors of covariance matrix, first 3-5 factors explain 60-80% variance (common market/sector moves)',
            'Residuals: Stock-specific return = actual - (factor_loadings × factor_returns), mean-reverting component, z-score >2 short, <-2 long',
            'Factor neutrality: Portfolio should have zero exposure to factors (sum(weights × loadings) = 0), adjust weights via optimization',
            'Rolling PCA: Recalculate monthly (252-day window), factor structure changes over time, update loadings and residuals',
            'Risk management: Stop-loss per stock (2% max loss), position limits (5% max per stock), reduce leverage if drawdown >10%',
        ],
    },
];

