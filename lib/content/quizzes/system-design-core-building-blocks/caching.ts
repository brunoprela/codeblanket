/**
 * Quiz questions for Caching section
 */

export const cachingQuiz = [
  {
    id: 'q1',
    question:
      'Your application has 100K QPS and a 90% cache hit rate. You notice occasional database overload spikes. After investigation, you discover popular items expire simultaneously at midnight (TTL set at deployment time). Explain the problem and propose a solution.',
    sampleAnswer:
      'PROBLEM: CACHE STAMPEDE (THUNDERING HERD): What\'s happening: (1) All cached items deployed at same time with same TTL (e.g., 24 hours). (2) All items expire simultaneously at midnight. (3) At midnight: 100K QPS × 10% miss rate = 10K QPS normally hitting database. (4) When all cache expires: 100K QPS ALL hit database simultaneously. (5) Database overwhelmed (designed for 10K QPS, now receiving 100K QPS). (6) Queries slow down or timeout. (7) More cache misses (slow queries timeout), making problem worse. This is a cache stampede/thundering herd problem. SOLUTION 1: JITTERED TTL (Recommended): Instead of fixed TTL, add randomness. Implementation: BASE_TTL = 3600 seconds (1 hour). JITTER = random(0, 600) seconds (0-10 minutes). ACTUAL_TTL = BASE_TTL + JITTER. Code: cache.set("user:123", user_data, ttl=3600 + random.randint(0, 600)). Result: Items expire gradually over a 10-minute window, not all at once. Impact: Database load spreads out: Instead of 100K QPS spike at one moment, Spread over 10 minutes: Average ~16K QPS (manageable). Pros: Simple to implement (one line change). No coordination needed. Works for all cache keys. Cons: Items still expire (cache misses during the window). SOLUTION 2: PROBABILISTIC EARLY REFRESH: Refresh cache before it expires, with probability increasing as TTL approaches zero. Implementation: When serving from cache, calculate: time_until_expiry = ttl_remaining. probability_refresh = 1 / time_until_expiry. If random() < probability_refresh: Asynchronously refresh cache in background. Result: Cache refreshed before expiry, no mass expiration. Code example: def get_user (user_id): user, ttl_remaining = cache.get_with_ttl (f"user:{user_id}"). if user and ttl_remaining > 0: if random.random() < (1.0 / ttl_remaining): background_job.enqueue (refresh_user, user_id). return user. else: # Cache miss: load from database. Pros: Proactive (prevents stampede). Cache stays warm. Cons: More complex. Background job infrastructure needed. SOLUTION 3: CACHE LOCKING: When cache miss occurs, first request acquires lock and queries database. Other requests wait for cache to be populated. Implementation: Check cache. If miss: Try to acquire lock. If lock acquired: Query database, update cache, release lock. If lock not acquired: Wait briefly, retry reading cache. Result: Only ONE request hits database per expired key. Pros: Minimizes database load (only 1 query per key). Cons: Lock contention. Increased latency for waiting requests. Lock can become bottleneck. SOLUTION 4: BACKGROUND REFRESH: Separate background job refreshes cache before expiration. Implementation: When setting cache, also schedule background job to run before TTL expires. Job re-queries database and updates cache. Pros: Zero cache misses (proactive refresh). Predictable database load. Cons: Complexity (job scheduler needed). Might refresh data that\'s no longer accessed. RECOMMENDED APPROACH: Combine Solution 1 (Jittered TTL) + Solution 2 (Probabilistic Early Refresh): Jittered TTL: Spreads out expirations. Probabilistic refresh: Hot items stay cached. Implementation: cache.set (key, value, ttl=BASE_TTL + random.randint(0, JITTER)). In read path, probabilistically refresh. BEFORE vs AFTER: Before: Database load at midnight: 100K QPS spike (database crashes). After: Database load at midnight: Gradual increase from 10K to ~20K QPS over 10 minutes (smooth, manageable). MONITORING: Track: Cache expiration events per minute (should be smooth, not spiky). Database QPS over time (should be relatively flat). Cache hit rate (should stay high, ~90%). Alert if: Sudden drop in cache hit rate. Database QPS spike >2× normal. REAL-WORLD EXAMPLE: Twitter: Doesn\'t use fixed TTL, uses probabilistic early refresh. Ensures timeline cache always warm. Database load is predictable.',
    keyPoints: [
      'Simultaneous cache expiration causes database overload spike (cache stampede)',
      'Solution 1: Jittered TTL (add randomness to TTL to spread expirations)',
      'Solution 2: Probabilistic early refresh (refresh cache before expiry)',
      'Combine both: Jittered TTL + early refresh for hot items',
      'Result: Smooth database load instead of spikes',
    ],
  },
  {
    id: 'q2',
    question:
      'You\'re deciding whether to use write-through or write-around caching for a social media "like" counter. Discuss the trade-offs and recommend an approach.',
    sampleAnswer:
      'SCENARIO ANALYSIS: "Like" Counter Characteristics: (1) Write-heavy: Users frequently like posts (high write frequency). (2) Read-heavy: Like counts displayed everywhere (even more reads). (3) Eventual consistency OK: Seeing 1,234 vs 1,235 likes doesn\'t matter. (4) Stale data acceptable: Count can be few seconds old. (5) Aggregate data: Total count, not individual likes. OPTION 1: WRITE-THROUGH CACHE: Flow: User likes post → Update cache → Cache updates database. Pros: Cache always up-to-date. Reads always fast (always in cache). Consistency guaranteed. Cons: Every like hits database (slow, expensive). Database write bottleneck. Wasted effort (updating cache and DB immediately). Analysis for Like Counter: Not ideal because: (1) Likes are write-heavy: Every like = database write (expensive at scale). (2) Perfect consistency not needed: OK if count is slightly stale. (3) Database becomes bottleneck: 10K likes/sec = 10K DB writes/sec. OPTION 2: WRITE-AROUND CACHE: Flow: User likes post → Write directly to database, invalidate cache. Next read: Cache miss, fetch from database, populate cache. Pros: Simple. Avoids cache pollution (if data won\'t be read). Cons: Cache miss after every write (read penalty). For frequently read data (like likes), this is bad. Analysis for Like Counter: Not ideal because: (1) Likes are read-heavy: Invalidating cache causes cache miss on next read. (2) High read volume: 100K reads/sec → frequent cache misses → database overload. RECOMMENDED: WRITE-BACK (WRITE-BEHIND) CACHE: Flow: User likes post → Increment counter in cache → Return success immediately. Background job: Periodically flush cached counts to database (batched). Pros: (1) Instant writes: Increment in-memory counter (< 1ms). (2) Batched database writes: Instead of 10K individual writes, batch into 1 write per post every 5 seconds. (3) Reduces database load: 10K likes/sec → 200 DB writes/sec (50× reduction). (4) Scales well: Cache handles write volume. Cons: (1) Risk of data loss: If cache crashes before flushing, some likes lost. (2) Complexity: Need background job to flush. (3) Eventual consistency: Database lags behind cache. Mitigation for Data Loss: (1) Acceptable for likes: Losing few likes during crash is OK (not financial data). (2) Use persistent cache: Redis with AOF (append-only file) logs every increment. (3) Frequent flushes: Flush every 5-10 seconds (minimize data loss window). IMPLEMENTATION DETAILS: Redis: Use INCR command (atomic, fast). cache.incr (f"post:123:likes")  # Atomic increment. Background Job (Celery/Sidekiq): Every 5 seconds: (1) Fetch all dirty counters from cache. (2) Batch update database: UPDATE posts SET likes = likes + delta WHERE id IN (...). (3) Mark counters as flushed in cache. Read Path: Check cache first: likes = cache.get (f"post:123:likes"). If cache miss: Query database, populate cache. Result: Reads almost always cache hit. Writes instant (in-memory). Database handles 50× less load. ALTERNATIVE: HYBRID APPROACH (Write-Through + Batch): Flow: User likes post → Increment cache immediately → Return success. Every N likes (e.g., every 10 likes) OR every T seconds → Update database. Example: Like count in cache: 1, 2, 3, ..., 10 → Database write (batch 10 likes). Pros: Balances immediate writes with batching. Reduces database load. Limits data loss (at most N likes lost). Cons: Still complexity of batching logic. COMPARISON TABLE: Write-Through: Database Load: High (every write), Read Performance: Excellent, Consistency: Strong, Data Loss Risk: None, Complexity: Low. Write-Around: Database Load: High (every write), Read Performance: Poor (frequent misses), Consistency: Strong, Data Loss Risk: None, Complexity: Low. Write-Back: Database Load: Low (batched), Read Performance: Excellent, Consistency: Eventual, Data Loss Risk: Small (mitigated), Complexity: Medium. REAL-WORLD EXAMPLES: Facebook Likes: Use write-back with batching. Redis counters flushed periodically. Acceptable to lose few likes in crash. Twitter Favorites: Similar approach, batched writes. YouTube View Counts: Write-back, approximate counts (eventual consistency fine). FINAL RECOMMENDATION: Use Write-Back (Write-Behind) for like counters: (1) Increment cache immediately (fast user experience). (2) Batch writes to database every 5-10 seconds. (3) Use Redis with persistence (AOF). (4) Monitor cache health and flush frequency. Result: 50× reduction in database writes, instant user experience, scalable to billions of likes. Trade-off accepted: Small risk of data loss (mitigated) + eventual consistency (acceptable for likes).',
    keyPoints: [
      'Like counters: write-heavy, read-heavy, eventual consistency OK',
      "Write-through: every like hits database (doesn't scale)",
      'Write-around: invalidates cache on write (causes read misses)',
      'Recommended: Write-back (increment cache, batch flush to DB)',
      'Result: 50× less database load, instant writes, small data loss risk (acceptable)',
    ],
  },
  {
    id: 'q3',
    question:
      'Design a caching strategy for an e-commerce product catalog with 1M products. 80% of traffic goes to 1000 popular products (0.1% of catalog). How would you optimize cache size and hit rate?',
    sampleAnswer:
      'SCENARIO ANALYSIS: Key Facts: (1) 1M total products. (2) 80% traffic to 1000 products (hot items). (3) 20% traffic to 999,000 products (long tail). (4) Heavy skew (Pareto principle: 80/20 rule). Goal: Maximize cache hit rate while minimizing cache size. NAIVE APPROACH: Cache all 1M products. Assuming 10KB per product: 1M × 10KB = 10GB cache. Problem: Wastes memory. 999,000 products rarely accessed (cache pollution). Expensive (Redis memory costs). OPTIMIZED APPROACH: Cache based on access patterns. TARGET CACHE SIZE: Cache top 100K products (10% of catalog). 100K × 10KB = 1GB cache. Much more cost-effective! EXPECTED CACHE HIT RATE: Top 1000 products: 80% of traffic (always cached). Next 99,000 products: Some frequently accessed, some not. Estimate: 15% of remaining 20% traffic cached. Total hit rate: 80% + (20% × 0.75) = 95% hit rate. Result: 1GB cache achieves 95% hit rate (vs 10GB for 100% hit rate). CACHING STRATEGY: Combination of techniques: TECHNIQUE 1: LRU EVICTION: Use LRU (Least Recently Used) eviction policy. Hot products stay in cache. Cold products evicted automatically. Configuration: Max cache size: 1GB. Eviction policy: LRU. Result: Top 1000 products always cached. Frequently accessed long-tail products cached temporarily. TECHNIQUE 2: TIERED CACHING: Two-tier cache: (1) Tier 1 (Hot): 1000 products, never expire, always in memory. (2) Tier 2 (Warm): 99,000 products, LRU eviction, TTL 1 hour. Implementation: def get_product (product_id): # Tier 1: Hot products (no TTL). product = cache.get (f"product:hot:{product_id}"). if product: return product. # Tier 2: Warm products (1 hour TTL). product = cache.get (f"product:warm:{product_id}"). if product: return product. # Cache miss: query database. product = database.query (product_id). # Determine tier based on popularity. if product.popularity > THRESHOLD: cache.set (f"product:hot:{product_id}", product)  # No TTL. else: cache.set (f"product:warm:{product_id}", product, ttl=3600)  # 1 hour. return product. Pros: Hot products never evicted. Optimal memory usage. Cons: Need to track product popularity. TECHNIQUE 3: POPULARITY-BASED TTL: Hot products: Longer TTL (e.g., 24 hours). Cold products: Shorter TTL (e.g., 1 hour). Implementation: def get_cache_ttl (product): if product.views_last_week > 10000: return 86400  # 24 hours. elif product.views_last_week > 1000: return 3600  # 1 hour. else: return 600  # 10 minutes. Pros: Adaptive (hot products stay cached longer). Simple to implement. TECHNIQUE 4: PROACTIVE CACHE WARMING: On application startup or deployment: Pre-populate cache with top 1000 products. Background job: Every hour: (1) Query analytics for top products. (2) Refresh cache for these products. Pros: Top products always cached (zero cold starts). Predictable cache hit rate. Cons: Requires analytics infrastructure. TECHNIQUE 5: CACHE ASIDE WITH POPULARITY TRACKING: Track access count in Redis. Increment on each access: cache.incr (f"product:access_count:{product_id}"). Periodically analyze: Identify top N products. Ensure they\'re always cached. CODE EXAMPLE (CACHE ASIDE + LRU): def get_product (product_id): # Check cache. product = cache.get (f"product:{product_id}"). if product: # Track access (for popularity analysis). cache.incr (f"access:product:{product_id}"). return product. # Cache miss: query database. product = database.query (product_id). # Cache with TTL based on popularity. ttl = get_ttl_for_product (product). cache.set (f"product:{product_id}", product, ttl=ttl). return product. MONITORING & OPTIMIZATION: Metrics to track: (1) Cache hit rate (target: >95%). (2) Cache size (should stabilize around 1GB). (3) Eviction rate (how often items evicted). (4) Top 100 products by access count. Optimization: If hit rate < 95%: Increase cache size (e.g., 2GB). If cache consistently full: Analyze eviction patterns, adjust TTL. Weekly analysis: Refresh list of top 1000 products, proactively cache them. CACHE INVALIDATION: Product updates (price, description): Invalidate cache immediately: cache.delete (f"product:{product_id}"). Product deletion: Invalidate cache. Bulk updates: Flush cache keys matching pattern (carefully!). SCALABILITY: If catalog grows to 10M products: Same strategy scales: Cache top 100K (1% of catalog), Still achieve 95%+ hit rate, 1-2GB cache. Redis Cluster: Shard across multiple Redis nodes if needed. COST ANALYSIS: Naive approach: 10GB Redis cache: ~$200/month. Optimized approach: 1GB Redis cache: ~$20/month. Savings: $180/month (90% cost reduction). Performance: Similar (95% hit rate). REAL-WORLD EXAMPLES: Amazon: Doesn\'t cache all products. Caches bestsellers and recently viewed. Uses tiered caching (hot/warm/cold). Netflix: Doesn\'t cache all videos. Caches popular titles and personalized recommendations. Uses popularity-based TTL. FINAL RECOMMENDATION: Use LRU eviction with 1-2GB cache. Proactively warm cache with top 1000 products. Popularity-based TTL (hot = 24h, cold = 1h). Monitor hit rate and adjust size if needed. Result: 95% hit rate with 1GB cache (10× smaller than naive approach).',
    keyPoints: [
      'Pareto principle: 80% traffic to 0.1% of products (1000 of 1M)',
      "Don't cache entire catalog (wasteful): cache hot items only",
      'Use LRU eviction: hot products stay, cold products evicted',
      '1GB cache (100K products) achieves 95% hit rate vs 10GB (all products)',
      'Proactively warm cache with top products, use popularity-based TTL',
    ],
  },
];
