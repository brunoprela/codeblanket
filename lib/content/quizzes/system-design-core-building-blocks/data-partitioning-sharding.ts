/**
 * Quiz questions for Data Partitioning & Sharding section
 */

export const datapartitioningshardingQuiz = [
  {
    id: 'q1',
    question:
      'Your application shards user data by user_id using simple hash: shard_id = hash (user_id) % 4. You need to add a 5th shard. Walk through what happens and explain why this is problematic. How would you design it differently?',
    sampleAnswer:
      "PROBLEM WITH SIMPLE HASH SHARDING: Current setup: 4 shards, formula shard_id = hash (user_id) % 4. User 123: hash(123) = 1000 → 1000 % 4 = 0 → Shard 0. User 456: hash(456) = 2001 → 2001 % 4 = 1 → Shard 1. User 789: hash(789) = 3002 → 3002 % 4 = 2 → Shard 2. WHAT HAPPENS WHEN ADDING SHARD 5: New formula: shard_id = hash (user_id) % 5. User 123: hash(123) = 1000 → 1000 % 5 = 0 → Still Shard 0 (lucky!). User 456: hash(456) = 2001 → 2001 % 5 = 1 → Still Shard 1 (lucky!). User 789: hash(789) = 3002 → 3002 % 5 = 2 → Still Shard 2 (lucky!). But: User 111: hash(111) = 998 → OLD: 998 % 4 = 2 (Shard 2) → NEW: 998 % 5 = 3 (Shard 3) → MOVES!. SCALE OF PROBLEM: On average, ~80% of data needs to move! Why: Changing modulo from 4 to 5 completely changes hash distribution. Almost every key gets reassigned. IMPACT: (1) Massive data migration: Copy 80% of database across network. (2) Downtime: Application needs to pause while migration happens. (3) Time: Migrating 100GB database might take hours. (4) Risk: If migration fails midway, data inconsistent. (5) Cost: Network bandwidth, storage I/O, potential lost revenue. REAL EXAMPLE: Instagram had 100TB of data. Adding a shard would require moving 80TB. At 1Gbps network: 80TB = 640,000 Gb → 640,000 seconds = 7.4 days (!). BETTER DESIGN: CONSISTENT HASHING. How Consistent Hashing Works: (1) Hash ring: Circle from 0 to 2^32-1. (2) Place shards on ring: Shard 0 at 25%, Shard 1 at 50%, Shard 2 at 75%, Shard 3 at 100%. (3) Place data on ring: hash (user_id) gives position on ring. (4) Assign to next shard clockwise. Example: User 123: hash(123) = 30% → Next shard clockwise = Shard 1 (at 50%). User 456: hash(456) = 60% → Next shard clockwise = Shard 2 (at 75%). User 789: hash(789) = 85% → Next shard clockwise = Shard 3 (at 100%). ADDING SHARD 5 WITH CONSISTENT HASHING: Place Shard 4 at 40% on ring. Before: Data from 25% to 50% → Shard 1. After: Data from 25% to 40% → Shard 4 (NEW). Data from 40% to 50% → Shard 1 (unchanged). Result: Only data in range 25%-40% moves (1/4 of Shard 1's data). COMPARISON: Simple hash: ~80% of ALL data moves. Consistent hash: ~20% of ONE shard's data moves (1/20 = 5% of total). Reduction: 16× less data movement! VIRTUAL NODES OPTIMIZATION: Problem: 4 physical shards on ring might not distribute evenly. Solution: Each physical shard appears at multiple positions (virtual nodes). Example: Shard 0: appears at 10%, 35%, 60%, 85% (4 virtual nodes). Shard 1: appears at 15%, 40%, 65%, 90% (4 virtual nodes). Result: More uniform distribution, even better rebalancing. IMPLEMENTATION: Use consistent hashing library: Python: hash_ring package, Java: Ketama, Go: stathat/consistent. Configure virtual nodes: typically 150-500 per physical shard. MIGRATION PROCESS WITH CONSISTENT HASHING: (1) Add Shard 4 to ring. (2) Identify affected data range (e.g., 25%-40%). (3) Dual-write: New writes go to both old and new shard. (4) Backfill: Copy existing data from Shard 1 to Shard 4. (5) Switch reads: Start reading from Shard 4 for that range. (6) Stop dual-write: Delete data from Shard 1. Result: No downtime, gradual migration. FINAL RECOMMENDATION: Never use simple hash (hash % N) for sharding in production. Always use consistent hashing for systems that will scale. Accept upfront complexity for long-term operability. REAL-WORLD USAGE: Cassandra: Consistent hashing with virtual nodes. DynamoDB: Consistent hashing. Redis Cluster: Hash slots (variant of consistent hashing). Chord DHT: Consistent hashing for P2P systems.",
    keyPoints: [
      'Simple hash (hash % N): adding shard requires ~80% of data to move',
      'Consistent hashing: only ~5-10% of data moves when adding shard',
      'Consistent hashing uses ring structure: data assigned to next shard clockwise',
      'Virtual nodes: each physical shard appears multiple times on ring for uniform distribution',
      'Production systems (Cassandra, DynamoDB, Redis) use consistent hashing',
    ],
  },
  {
    id: 'q2',
    question:
      "You're designing a social media platform. Users create posts, and other users like/comment on posts. You need to shard the data. Walk through your sharding strategy: what partition keys would you use for users, posts, likes, and comments? Explain trade-offs.",
    sampleAnswer:
      "SHARDING STRATEGY FOR SOCIAL MEDIA PLATFORM: ENTITIES TO SHARD: (1) Users (profiles, settings). (2) Posts (content, metadata). (3) Likes (user_id, post_id pairs). (4) Comments (user_id, post_id, comment text). KEY QUERIES TO OPTIMIZE: (1) Get user profile: by user_id. (2) Get user's posts: by user_id. (3) Get post with likes and comments: by post_id. (4) Get user's feed: posts from followed users. OPTION 1: SHARD EVERYTHING BY USER_ID. Strategy: All user data, their posts, their likes, their comments on same shard. Partition key: user_id. Shards: Shard 1: Users 1-25M + their posts/likes/comments. Shard 2: Users 25M-50M + their posts/likes/comments. Shard 3: Users 50M-75M + their posts/likes/comments. PROS: (1) User profile query: Single shard (fast). (2) Get user's posts: Single shard (fast). (3) Data locality: All user data together. CONS: (1) Get post with likes/comments: Post on Shard 1, but likes from users on all shards → Need to query ALL shards (slow!). (2) Hotspot: Celebrity user with millions of posts overwhelms one shard. (3) Uneven distribution: Some users very active (many posts), others inactive. OPTION 2: SHARD EVERYTHING BY POST_ID. Strategy: Posts, likes, and comments for each post on same shard. Partition key: post_id. Shards: Shard 1: Posts 1-25M + their likes/comments. Shard 2: Posts 25M-50M + their likes/comments. Shard 3: Posts 50M-75M + their likes/comments. Users: Separate table, sharded by user_id. PROS: (1) Get post with likes/comments: Single shard (fast). (2) Even distribution: Posts relatively uniform size. CONS: (1) Get user's posts: User\'s posts scattered across all shards → Query ALL shards (slow). (2) User profile + posts: Need 2 separate queries (user shard + multiple post shards). RECOMMENDED: HYBRID SHARDING (SEPARATE PARTITION KEYS). Strategy: Shard different entities by their dominant access pattern. USERS TABLE: Partition key: user_id. Sharding: Hash-based (uniform distribution). Query: Get user by user_id → Single shard. POSTS TABLE: Partition key: user_id (NOT post_id!). Why: Most common query: \"Get user's posts\". Sharding: Posts by same user colocated on same shard as user. Example: User 123 on Shard 2 → All posts by User 123 also on Shard 2. Query: Get User 123's posts → Single shard. LIKES TABLE: Partition key: post_id. Why: Most common query: \"Get all likes for post X\". Sharding: All likes for a post on same shard. Schema: (post_id, user_id, timestamp). Example: Post 456 on Shard 3 → All likes for Post 456 on Shard 3. Query: Get likes for Post 456 → Single shard. COMMENTS TABLE: Partition key: post_id. Why: Most common query: \"Get all comments for post X\". Sharding: All comments for a post on same shard as its likes. Schema: (post_id, user_id, comment_text, timestamp). Query: Get comments for Post 456 → Single shard. FEED GENERATION (COMPLEX QUERY): Query: \"Get feed for User 123\" (posts from followed users). Challenge: Followed users scattered across all shards. SOLUTION 1: FAN-OUT ON WRITE (PUSH MODEL): When user posts: (1) User 123 posts → Identify User 123's followers. (2) Write post_id to each follower's feed table. (3) Feed table sharded by user_id (colocated with user). Result: Get feed for User 789 → Single shard (fast read). Trade-off: Slow write (if user has 1M followers, write 1M times). Use case: Read-heavy, users have moderate followers. SOLUTION 2: FAN-OUT ON READ (PULL MODEL): When user requests feed: (1) Get User 789's followed users (e.g., 200 users). (2) Query posts from each followed user (scatter to multiple shards). (3) Merge and sort by timestamp. Result: Fast write (single write), slower read (query multiple shards). Use case: Write-heavy, users follow many people. HYBRID (TWITTER APPROACH): Regular users: Fan-out on write. Celebrities: Fan-out on read (don't push to millions of timelines). Feed query: Merge both sources. DENORMALIZATION TO AVOID CROSS-SHARD JOINS: Problem: Post on Shard 1, likes on Shard 2 (if sharded differently). Solution: Denormalize: Store like count WITH post (no need to query likes table). Update: When user likes post: (1) Write to Likes table. (2) Increment like_count in Posts table (eventually consistent OK). Result: Get post with like count → Single query. HANDLING HOTSPOTS: Problem: Viral post gets millions of likes → Likes table shard overloaded. Solutions: (1) Cache hot posts in Redis. (2) Rate limit likes (e.g., max 1000 likes/sec per post). (3) Write-back caching: Batch writes to likes table. (4) Replicate hot post's shard (more read replicas). SUMMARY TABLE: Entity / Partition Key / Reason: Users / user_id / Get user profile, Hash-based for uniform distribution. Posts / user_id / Get user's posts (colocate with user). Likes / post_id / Get all likes for a post. Comments / post_id / Get all comments for a post. Feeds / user_id / Get user's feed (fan-out on write). TRADE-OFFS ACCEPTED: (1) Cross-shard queries: Getting post + likes requires 2 shards (posts shard + likes shard) → Mitigate with denormalization (store like count with post). (2) Feed generation: Either slow writes (fan-out on write) or slow reads (fan-out on read) → Hybrid approach for celebrities. (3) Eventual consistency: Like count might lag slightly → Acceptable for social media. REAL-WORLD EXAMPLES: Instagram: Shards photos by user_id, likes by post_id. Twitter: Shards tweets by user_id, fans out to followers' feeds. Facebook: Complex sharding with TAO (social graph cache). FINAL RECOMMENDATION: Shard by dominant access pattern. Users/Posts by user_id, Likes/Comments by post_id. Denormalize to avoid cross-shard joins (store counts). Use hybrid fan-out for feed generation.",
    keyPoints: [
      'Shard by dominant access pattern: Users/Posts by user_id, Likes/Comments by post_id',
      'Denormalize to avoid cross-shard joins: store like_count with post',
      'Feed generation: hybrid approach (fan-out on write for regular users, on read for celebrities)',
      'Hotspots: cache viral posts, rate limit, batch writes',
      'Accept trade-off: some cross-shard queries for better performance on common queries',
    ],
  },
  {
    id: 'q3',
    question:
      'Explain the difference between sharding and replication. When would you use each? Can you use both together? Give a real-world example.',
    sampleAnswer:
      "SHARDING VS REPLICATION: SHARDING (HORIZONTAL PARTITIONING): Definition: Splitting data across multiple machines. Each machine holds DIFFERENT subset of data. Goal: Increase capacity (storage, throughput, parallelism). Example: 100M users sharded across 10 servers: Shard 1: Users 1-10M, Shard 2: Users 10M-20M, ..., Shard 10: Users 90M-100M. Each shard has unique data (no overlap). Query: Get User ID 5M → Query Shard 1 only. Benefit: Storage: Single DB max 10M users → Sharding allows 100M users. Throughput: 10 shards × 10K writes/sec each = 100K writes/sec total. Trade-offs: Complexity: Cross-shard queries harder. No redundancy: If Shard 1 fails, Users 1-10M unavailable. REPLICATION: Definition: Copying SAME data to multiple machines. Each machine holds IDENTICAL data. Goal: Increase availability, fault tolerance, and read scalability. Example: Primary database + 2 replicas: Primary: Users 1-100M (handles writes). Replica 1: Copy of Users 1-100M (handles reads). Replica 2: Copy of Users 1-100M (handles reads). Query: Read User ID 5M → Can query Primary, Replica 1, OR Replica 2. Benefit: Availability: If Primary fails, promote Replica 1 to Primary (no data loss). Read scaling: Distribute read queries across 3 servers (3× read throughput). Fault tolerance: Data redundancy protects against hardware failure. Trade-offs: Storage cost: 3× storage (same data copied 3 times). Write complexity: Writes go to Primary, must replicate to Replicas (replication lag). COMPARISON TABLE: Aspect / Sharding / Replication: Data distribution: Different data per machine / Same data per machine. Goal: Capacity & throughput / Availability & read scaling. Storage: Total capacity = sum of shards / Total capacity = single machine (redundant). Writes: Distributed across shards / All writes to primary, then replicated. Reads: Query specific shard / Distribute across replicas. Fault tolerance: No (shard failure = data loss) / Yes (replicas have backup). Complexity: High (cross-shard queries) / Low (replicas interchangeable). WHEN TO USE SHARDING: (1) Data doesn't fit on single machine (>1TB). (2) Write throughput exceeds single machine capacity (>10K writes/sec). (3) Need horizontal scalability (add more machines as data grows). (4) Read patterns can be isolated (e.g., users don't need to query all shards). Examples: Social media (billions of users/posts). E-commerce (millions of products/orders). Analytics (petabytes of logs). WHEN TO USE REPLICATION: (1) Need high availability (system must stay up even if server fails). (2) Read-heavy workload (10× more reads than writes). (3) Geographic distribution (replicas in different regions for low latency). (4) Disaster recovery (backup in case of data loss). Examples: E-commerce product catalog (read-heavy). Banking (availability critical). Content websites (read-heavy, low writes). USING BOTH TOGETHER (COMMON!): Strategy: Shard for capacity, replicate each shard for availability. Example: 100M users, 10 shards, 3 replicas per shard: Shard 1: Users 1-10M, Shard 1 Primary + Replica1a + Replica1b. Shard 2: Users 10M-20M, Shard 2 Primary + Replica2a + Replica2b. ..., Shard 10: Users 90M-100M, Shard 10 Primary + Replica10a + Replica10b. Total: 30 database instances (10 primaries + 20 replicas). Benefits: Capacity: 10 shards → 100M users (single DB can't hold this). Availability: If Shard 1 Primary fails, promote Replica1a to Primary (no downtime). Read scaling: Each shard has 3 instances → 3× read throughput per shard. Fault tolerance: Data redundancy within each shard. Queries: Write User 5M: Route to Shard 1 Primary. Read User 5M: Route to Shard 1 (any of Primary, Replica1a, Replica1b). REAL-WORLD EXAMPLE: INSTAGRAM. Scale: Billions of photos, petabytes of data. Architecture: Photos sharded by photo_id across thousands of shards. Each shard replicated 3× (primary + 2 replicas) for availability. Photo storage on Amazon S3 (itself sharded and replicated). Implementation: Cassandra database (built-in sharding + replication). Shard key: photo_id (consistent hashing). Replication factor: 3 (RF=3). Queries: Post photo: Shard by photo_id, write to 3 replicas. Get photo: Read from nearest replica for low latency. User feed: Fan-out to multiple shards (user's followed users). Benefits: Capacity: Petabytes of photos (single DB can't handle). Availability: 99.99% uptime (replica failover). Read scaling: Billions of photo views/day. Fault tolerance: Hardware failures don't cause data loss. Cost: Thousands of database instances, but necessary at scale. ANOTHER EXAMPLE: MONGODB SHARDED CLUSTER. Setup: Data sharded across multiple shards (e.g., 5 shards). Each shard is a replica set (primary + 2 replicas). Config servers (3 instances, replicated) store metadata. Mongos routers (query routers) direct queries to appropriate shards. Architecture: Shard 1: Replica set (Primary + 2 Replicas). Shard 2: Replica set (Primary + 2 Replicas). ..., Shard 5: Replica set (Primary + 2 Replicas). Total: 15 data instances + 3 config servers + N routers. Benefits: Sharding: Horizontal scaling (add more shards as data grows). Replication: High availability (automatic failover within replica sets). Operations: Add shard: MongoDB rebalances data automatically (consistent hashing). Shard failure: Replica promoted to Primary, no downtime. WHEN NOT TO USE SHARDING: (1) Data fits comfortably on single machine (<100GB). (2) Low traffic (<1000 QPS). (3) Team lacks expertise to manage sharding complexity. Alternative: Scale vertically (bigger machine), add replication for availability. SUMMARY: Sharding: For capacity and write throughput. Splits data across machines (different data). Replication: For availability and read scaling. Copies data to machines (same data). Together: Shard for capacity, replicate each shard for availability. Real-world: Most large-scale systems use both (Instagram, Facebook, Twitter). Rule of thumb: Start with replication, add sharding when single machine can't handle load.",
    keyPoints: [
      'Sharding: different data per machine, for capacity and write throughput',
      'Replication: same data per machine, for availability and read scaling',
      'Use both together: shard for capacity, replicate each shard for availability',
      'Real-world: Instagram shards photos, replicates each shard 3× for availability',
      "Start with replication, add sharding when single machine can't handle load",
    ],
  },
];
