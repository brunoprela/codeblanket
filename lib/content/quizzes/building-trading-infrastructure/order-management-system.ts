export const orderManagementSystemQuiz = [
    {
        id: 'order-management-system-q-1',
        question:
            'Design an "order lifecycle management system" that handles: (1) Order state transitions with validation (NEW → PENDING_RISK → ACCEPTED → PARTIALLY_FILLED → FILLED), (2) Concurrent fill processing (multiple fills arriving simultaneously), (3) Order amendments (replace order with new price/quantity), (4) Average fill price calculation, (5) Audit trail for regulatory compliance, (6) Explain how to handle edge cases (duplicate fills, out-of-order fills, overfills).',
        sampleAnswer:
            'Order Lifecycle Management System: **State Machine**: Define valid transitions: NEW → PENDING_RISK (submitted for risk check), PENDING_RISK → ACCEPTED (passed) or RISK_REJECTED, ACCEPTED → PARTIALLY_FILLED (first fill), PARTIALLY_FILLED → FILLED (complete) or CANCELLED, Terminal states: FILLED, CANCELLED, REJECTED, EXPIRED. Validation: Use enum for states, validate transition before applying (e.g., can\'t fill CANCELLED order). **Concurrent Fill Processing**: Problem: Two fills arrive simultaneously for same order → race condition updating filled_quantity. Solution: Use database row-level locking (SELECT FOR UPDATE), or atomic operations (Redis INCR), or message queue (serialized processing). Example: Order 100 shares, Fill A (50 shares) and Fill B (50 shares) arrive together. Without lock: Both read filled_qty=0, both write filled_qty=50 (wrong!). With lock: Fill A processes first (0→50), Fill B waits, then processes (50→100) (correct). **Average Fill Price Calculation**: Formula: avg_price = (Σ fill_qty × fill_price) / total_filled_qty. Example: Fill 1: 50 @ $100 = $5,000, Fill 2: 30 @ $101 = $3,030, Fill 3: 20 @ $99 = $1,980. Total: 100 shares, $10,010 → avg = $100.10. Implementation: Maintain running total: old_total = old_filled_qty × old_avg_price, new_total = old_total + (fill_qty × fill_price), new_avg = new_total / new_filled_qty. **Order Amendments**: Replace pattern (industry standard): Original order: BUY 100 @ $50 LIMIT, Amendment: BUY 100 @ $51 LIMIT. Process: Cancel original order (state → CANCELLED, reason="replaced"), Create new order (parent_order_id = original_id), Link in audit trail. Why replace? Most exchanges don\'t support in-place modification. Alternative: Some venues support modify (faster), but not guaranteed. **Audit Trail**: Requirements (SEC Rule 17a-4): Every order event must be logged immutably, include: timestamp (microsecond precision), user/system that triggered event, old state → new state, reason for action. Storage: Append-only log (cannot edit), PostgreSQL with event_log table, retention: 7 years minimum. Example events: ORDER_CREATED, ORDER_SUBMITTED, RISK_APPROVED, ORDER_ACCEPTED, ORDER_FILL (for each fill), ORDER_CANCELLED, ORDER_REJECTED. **Edge Case: Duplicate Fills**: Problem: Exchange sends same fill twice (network retry). Solution: Fill deduplication by execution_id (exchange-provided unique ID). Check: Before processing fill, query if execution_id already processed. If yes, ignore (idempotent). **Edge Case: Out-of-Order Fills**: Problem: Fill B arrives before Fill A (network latency). Example: Fill A @ 10:00:00.100, Fill B @ 10:00:00.050 (earlier timestamp). Solution: Buffering with timestamp ordering: Buffer fills for 100ms, sort by timestamp, process in order. Alternative: Process as received (timestamp for audit, but sequence by receipt). **Edge Case: Overfill**: Problem: Filled quantity exceeds order quantity (exchange error). Example: Order 100 shares, receive fills totaling 105 shares. Solution: Accept up to order quantity (100), reject excess (5 shares), alert operations team, file dispute with exchange (DK - Don\'t Know trade). **Implementation**: Python example: class OMSEngine: def process_fill(order_id, fill): with transaction(): order = get_order_for_update(order_id), if fill.execution_id in processed_fills: return "DUPLICATE", validate_fillable_state(order), update_filled_qty(order, fill.quantity), recalculate_avg_price(order, fill), log_event("ORDER_FILL", fill), if order.filled_qty >= order.quantity: order.state = FILLED, commit().',
        keyPoints: [
            'State transitions: Use state machine with validation; terminal states (FILLED, CANCELLED, REJECTED) cannot transition',
            'Concurrent fills: Row-level locking (SELECT FOR UPDATE) or atomic ops to prevent race conditions; process serially',
            'Average price: Maintain running total: new_avg = (old_total + fill_qty × fill_price) / new_filled_qty',
            'Amendments: Cancel-replace pattern (industry standard); new order links to original via parent_order_id',
            'Edge cases: Dedup fills by execution_id, buffer/sort out-of-order fills, reject overfills and alert ops team',
        ],
    },
    {
        id: 'order-management-system-q-2',
        question:
            'You need to build an OMS that handles 50,000 orders per day with peak load of 500 orders per minute. Design the "database schema and indexing strategy" including: (1) Orders table schema, (2) Fills table schema, (3) Index strategy for fast queries (get open orders, get orders by symbol), (4) Partitioning strategy for historical data, (5) Read/write patterns and optimization, (6) Calculate database requirements (storage, IOPS).',
        sampleAnswer:
            'OMS Database Design: **Orders Table Schema**: orders ( order_id VARCHAR(36) PRIMARY KEY, client_order_id VARCHAR(50) UNIQUE NOT NULL, symbol VARCHAR(20) NOT NULL, side ENUM("BUY","SELL") NOT NULL, order_type ENUM("MARKET","LIMIT","STOP") NOT NULL, quantity DECIMAL(18,8) NOT NULL, price DECIMAL(18,8), state ENUM("NEW","ACCEPTED","FILLED","CANCELLED"...) NOT NULL, filled_quantity DECIMAL(18,8) DEFAULT 0, remaining_quantity DECIMAL(18,8), avg_fill_price DECIMAL(18,8), account VARCHAR(50) NOT NULL, strategy VARCHAR(50), created_time TIMESTAMP(6) NOT NULL, submitted_time TIMESTAMP(6), completed_time TIMESTAMP(6), INDEX idx_state (state), INDEX idx_symbol_state (symbol, state), INDEX idx_account_state (account, state), INDEX idx_created (created_time), INDEX idx_symbol_created (symbol, created_time) ). Rationale: TIMESTAMP(6) for microsecond precision (regulatory requirement), DECIMAL(18,8) for precision (avoid float rounding errors), Composite indexes for common query patterns. **Fills Table Schema**: fills ( fill_id VARCHAR(36) PRIMARY KEY, order_id VARCHAR(36) NOT NULL, execution_id VARCHAR(50) UNIQUE NOT NULL, symbol VARCHAR(20) NOT NULL, side ENUM("BUY","SELL") NOT NULL, quantity DECIMAL(18,8) NOT NULL, price DECIMAL(18,8) NOT NULL, timestamp TIMESTAMP(6) NOT NULL, exchange VARCHAR(20) NOT NULL, commission DECIMAL(18,8) DEFAULT 0, FOREIGN KEY (order_id) REFERENCES orders(order_id), INDEX idx_order_id (order_id), INDEX idx_execution_id (execution_id), INDEX idx_symbol_timestamp (symbol, timestamp), INDEX idx_timestamp (timestamp) ). Rationale: execution_id UNIQUE prevents duplicate fills, Foreign key maintains referential integrity, Index on order_id for fast fill lookup per order. **Index Strategy**: Query 1: Get open orders (most frequent): SELECT * FROM orders WHERE state IN ("ACCEPTED","PARTIALLY_FILLED"). Use index: idx_state. Performance: <1ms (index scan). Query 2: Get orders by symbol: SELECT * FROM orders WHERE symbol = "AAPL" AND state != "FILLED" ORDER BY created_time. Use index: idx_symbol_state (covers symbol and state), covers both filter and sort. Performance: <5ms. Query 3: Get account orders: SELECT * FROM orders WHERE account = "ACC-001" AND state != "FILLED". Use index: idx_account_state. Performance: <5ms. Query 4: Get order fills: SELECT * FROM fills WHERE order_id = "...". Use index: idx_order_id. Performance: <1ms (usually 1-5 fills per order). **Partitioning Strategy**: Problem: 50K orders/day × 365 days = 18M orders/year → table too large. Solution: Partition by created_time (monthly): orders_2024_01, orders_2024_02, ... Partition strategy: RANGE partitioning on created_time. Old partitions (> 1 year): Archive to cold storage (S3), keep index in PostgreSQL (metadata only). Query impact: Active orders (last 30 days): Query single partition (fast), historical queries: Query multiple partitions (slower, acceptable). **Read/Write Patterns**: Writes: 50K orders/day = 0.58 orders/sec (avg), 500 orders/min (peak) = 8.3 orders/sec. Each order: 1 INSERT (orders), 1-5 UPDATEs (state changes), 2-10 INSERTs (fills). Total: ~100 writes/sec (peak). Optimization: Batch INSERT fills (every 100ms), use UPSERT for fills (idempotent). Reads: Open orders query (every 1 sec) = 1 query/sec, Symbol orders (per strategy, 100 strategies) = 100 queries/sec, Order detail (per fill, 10 fills/sec) = 10 queries/sec. Total: ~200 reads/sec. Optimization: Cache open orders in Redis (invalidate on state change), use read replicas for reporting queries. **Database Requirements**: Storage: Orders: 50K/day × 500 bytes/row × 365 days = 9 GB/year, Fills: 50K orders × 3 fills avg × 200 bytes = 30 GB/year. Total: ~40 GB/year. With indexes (2×): 80 GB/year. 5-year retention: 400 GB. IOPS: Writes: 100 writes/sec × 3 (order + fill + index) = 300 IOPS, Reads: 200 reads/sec = 200 IOPS. Total: 500 IOPS (easily handled by SSD). Database spec: PostgreSQL 14+, 4 vCPU, 16 GB RAM, 500 GB SSD (5-year capacity), 1000 IOPS (2× headroom). Cost: ~$300/month (AWS RDS). **Performance Targets**: Order creation: <10ms (INSERT + risk check), Fill processing: <5ms (UPDATE + avg price calc), Open orders query: <1ms (indexed), Historical query: <100ms (partition scan). Achieved with proper indexing and partitioning.',
        keyPoints: [
            'Schema: orders table (order_id PK, state, filled_qty, avg_price), fills table (fill_id PK, order_id FK, execution_id UNIQUE)',
            'Indexes: Composite indexes for common queries (symbol+state, account+state); idx_state for open orders (<1ms)',
            'Partitioning: Monthly RANGE partitions on created_time; archive old partitions (>1 year) to cold storage',
            'Read/write: 100 writes/sec peak, 200 reads/sec; batch inserts, cache open orders in Redis, use read replicas',
            'Requirements: 400 GB storage (5 years), 500 IOPS, 4 vCPU/16GB RAM PostgreSQL; ~$300/month cost',
        ],
    },
    {
        id: 'order-management-system-q-3',
        question:
            'Design an "order routing rules engine" that determines the best venue (exchange) to route orders. Include: (1) Routing rules (liquidity, price, latency, fees), (2) Smart order routing logic, (3) Multi-venue support (route large order to multiple venues), (4) Regulatory requirements (Reg NMS best execution), (5) Performance metrics (fill rate, effective spread, latency), (6) A/B testing different routing strategies.',
        sampleAnswer:
            'Order Routing Rules Engine: **Routing Rules**: Rule 1: Liquidity (most important for large orders): Query each venue for order book depth (bid/ask sizes). Choose venue with deepest liquidity at NBBO (National Best Bid Offer). Example: AAPL bid, NYSE: $150.00 (5000 shares), NASDAQ: $150.00 (3000 shares), BATS: $149.99 (2000 shares). For buy order, choose NYSE (best price + deepest). Rule 2: Price (regulatory requirement): Must route to venue with best price (NBBO). Reg NMS: Can\'t trade through better price at another venue. Example: NBBO bid $150.00, venue offers $149.99 → route to $150.00 venue. Rule 3: Latency: Measure venue latency (order ack time): NYSE: 2ms, NASDAQ: 1.5ms, BATS: 3ms. For small orders where price same, choose lowest latency (NASDAQ). Rule 4: Fees: Maker/taker fee model: Maker fee (add liquidity): -$0.0015/share (rebate), Taker fee (remove liquidity): +$0.0030/share (pay). Limit orders often "make" (rebate), market orders always "take" (pay). Example: Limit order, choose venue with highest maker rebate. **Smart Order Routing (SOR) Logic**: Input: Order (symbol, side, quantity, type). Step 1: Query NBBO from all venues (SIP feed): Get best bid/ask across all exchanges. Step 2: Get order book depth per venue: Request Level 2 data (10 levels deep). Step 3: Calculate routing score per venue: score = (price_improvement × 100) + (liquidity / 1000) - (latency_ms × 10) - (fee × 1000). Normalize and rank venues. Step 4: Route to highest score venue: For limit orders: Route to venue with best maker rebate + liquidity. For market orders: Route to venue with best price + deepest book. Step 5: Monitor execution: Track fill rate, slippage, latency per venue. Feedback loop: Adjust routing scores based on historical performance. **Multi-Venue Routing (Large Orders)**: Problem: Order 10,000 shares, largest venue only has 3,000 at NBBO. Solution: Split order across venues: Venue A: 3,000 shares (max at NBBO), Venue B: 2,500 shares (next best), Venue C: 2,000 shares, Venue D: 2,500 shares. Algorithm: Reserve-based routing: Calculate quantity available at each venue (reserve quantity). Route proportionally to reserves. Minimize market impact (don\'t exhaust single venue). Example code: def route_large_order(symbol, side, total_qty): venues = get_venues_with_liquidity(symbol, side), available = {v: get_available_qty(v, symbol, side) for v in venues}, routes = {}, for venue in sorted(venues, key=lambda v: available[v], reverse=True): if total_qty <= 0: break, route_qty = min(total_qty, available[venue]), routes[venue] = route_qty, total_qty -= route_qty, return routes. **Regulatory Compliance (Reg NMS)**: Requirement 1: Order Protection Rule (Rule 611): Must not trade through better price at another venue. Must route to venue with NBBO (or improve price). Violation penalty: $10K+ per violation. Requirement 2: Best Execution: Must seek best price + execution quality for customer. Document routing logic (why venue X chosen). Annual review and reporting. Requirement 3: Market Access Rule (Rule 15c3-5): Pre-trade risk checks before routing. Prevent erroneous orders (fat finger). Example: Order $150M (should be $150K) → reject. **Performance Metrics**: Fill Rate: filled_qty / total_qty × 100. Target: >98% for limit orders, 100% for market orders. By venue: NYSE 99.2%, NASDAQ 98.5%, BATS 97.8%. Effective Spread: effective_spread = |fill_price - mid_price| × 2. Measures price improvement. Target: <0.5 bps (basis points). Example: Mid $150.00, fill $150.01 → 1 bp spread. Latency: Time from order submission to ack. Target: <2ms. By venue: NASDAQ 1.5ms (best), NYSE 2.0ms, BATS 2.5ms. Rebates Earned: Total maker rebates - taker fees. Target: Net positive (earn more than pay). Example: $10K rebates - $5K fees = $5K net (good). **A/B Testing Routing Strategies**: Setup: Route 50% orders with Strategy A (price-first), 50% with Strategy B (liquidity-first). Metrics: Track fill rate, effective spread, latency, rebates for each strategy. Duration: Run for 1 month (significant sample). Analysis: Strategy A: Fill rate 98.5%, spread 0.4 bps, latency 2.0ms, rebates +$2K. Strategy B: Fill rate 99.2%, spread 0.5 bps, latency 1.8ms, rebates +$1.5K. Winner: Strategy B (higher fill rate, lower latency) despite slightly higher spread. Rollout: Deploy Strategy B to 100% of orders. **Implementation**: class OrderRouter: def __init__(self): self.venues = ["NYSE", "NASDAQ", "BATS", "IEX"], self.latency = {}, self.fill_rates = {}, def route_order(self, order): nbbo = get_nbbo(order.symbol), venues_at_nbbo = get_venues_at_price(order.symbol, order.side, nbbo), scores = {v: self.calculate_score(v, order) for v in venues_at_nbbo}, best_venue = max(scores, key=scores.get), return best_venue, def calculate_score(self, venue, order): liquidity = get_liquidity(venue, order.symbol), latency = self.latency.get(venue, 999), fee = get_fee(venue, order.type), score = (liquidity / 1000) - (latency × 10) - (fee × 1000), return score.',
        keyPoints: [
            'Routing rules: Liquidity (order book depth), price (NBBO compliance), latency (venue ack time <2ms), fees (maker/taker)',
            'Smart routing: Query NBBO, get Level 2 depth, score venues (price + liquidity - latency - fees), route to highest score',
            'Multi-venue: Split large orders across venues proportional to available liquidity; prevent exhausting single venue',
            'Reg NMS: Order Protection (don\'t trade through NBBO), best execution (document logic), market access (pre-trade risk)',
            'Metrics: Fill rate >98%, effective spread <0.5 bps, latency <2ms; A/B test strategies (price-first vs liquidity-first)',
        ],
    },
];

