export const highFrequencyTradingArchitectureQuiz = [
  {
    id: 'hfta-q-1',
    question:
      'Compare FPGA-based trading systems vs kernel-bypass software (DPDK) systems. For each: (1) explain the architecture and latency characteristics, (2) discuss development complexity and cost, (3) identify appropriate use cases, (4) analyze when to choose each approach. What are the practical limits of latency reduction in software vs hardware?',
    sampleAnswer:
      "FPGA vs Kernel-Bypass comparison: (1) FPGA Architecture: Hardware logic programmed in Verilog/VHDL. Fully parallel processing—multiple operations simultaneously. Market data parsing, strategy evaluation, order generation all in hardware gates. Latency: 100-900ns end-to-end (tick to order). Breakdown: Parsing ~100ns, Strategy ~300ns, Order gen ~100ns, Network ~400ns. Jitter: <10ns (extremely deterministic). No OS, no CPU scheduling, no cache misses. DPDK Architecture: Userspace packet processing. Poll network card directly, bypassing kernel. Process packets in tight loop with zero-copy. CPU executes instructions sequentially (even with pipelining). Latency: 2-10μs end-to-end. Breakdown: Receive ~1μs, Strategy ~3μs, Send ~2μs, Network ~4μs. Jitter: ~100ns (more variable than FPGA). Subject to CPU effects (cache misses, branch misprediction). (2) Development: FPGA complexity: Very high. HDL programming fundamentally different from software. Think in circuits and clock cycles, not sequential steps. Dev time: 6-12 months for production strategy. Team: Hardware engineers (\$200K+ salary). Debugging: Extremely difficult (waveform analysis, simulation). Iteration cycle: 2-8 hours (synthesis/place-route). Difficult to modify in production. Cost: $50K-500K per FPGA card, $1-2M development. DPDK complexity: Moderate. Still C/C++ but requires deep networking knowledge. Careful memory management (pools, zero-copy). Lock-free data structures. Dev time: 2-4 months. Team: Senior C++ developers (\$150K+ salary). Debugging: Standard tools (gdb), still challenging. Iteration cycle: Minutes (recompile). Can modify strategy in production. Cost: $10K-50K hardware (NICs), $200K-500K development. (3) Use cases: FPGA best for: Simple, latency-critical strategies (arbitrage, market making). Strategies needing <1μs execution. High message rate (100K+ msgs/sec). Deterministic latency critical (no jitter tolerance). Examples: Cross-exchange arbitrage (price sync <1μs), Quote stuffing defense, Ultra-fast market making. DPDK best for: More complex strategies requiring flexibility. Strategies with tolerable 5-10μs latency. Need frequent strategy updates. Budget-constrained (\$500K vs $2M). Examples: Statistical arbitrage (more compute), Smart order routing with multiple factors, Adaptive market making. (4) When to choose: Choose FPGA if: Latency advantage worth $millions annually (competitive market). Strategy stable (won't change weekly). Budget >$2M. Team has hardware expertise. Winning at nanosecond scale critical. Choose DPDK if: 5-10μs latency competitive enough. Strategy evolves frequently (ML models, new factors). Budget $200K-500K. Team has C++ expertise. Want flexibility to A/B test strategies. Hybrid approach: FPGA for critical path (order routing), Software for strategy logic (more flexible). Example: FPGA handles market data parsing and order generation (<1μs), sends signals to CPU for complex decision-making (5μs). (5) Practical latency limits: FPGA floor: ~100ns (dominated by network serialization). Speed of light: 100m @ ~300,000 km/s = 0.3μs. FPGA processing: 50ns. Minimum: ~400ns achievable. DPDK floor: ~1μs. Memory access: ~100ns. Instruction execution: ~500ns. Network handling: ~400ns. Minimum: ~1μs achievable even with perfect code. Below these limits: Need specialized ASICs (Application-Specific Integrated Circuits) or move closer to exchange (co-location within meters). Reality: Most strategies competitive at 5-20μs. Sub-microsecond only needed for most competitive markets (SPY, futures). Diminishing returns: Going from 20μs to 10μs might gain 10% edge. Going from 1μs to 0.5μs gains <1% (other factors dominate). Key insight: Latency is arms race. Today\'s 1μs advantage is table stakes tomorrow. Focus on strategy alpha, not just speed.",
    keyPoints: [
      'FPGA: 100-900ns, parallel hardware, 6-12mo dev, $1-2M cost, for simple latency-critical strategies',
      'DPDK: 2-10μs, sequential software, 2-4mo dev, $200-500K cost, for complex flexible strategies',
      'FPGA floor ~400ns (network limited), DPDK floor ~1μs (CPU limited), physics limits apply',
      'Choose FPGA for: <1μs needed, stable strategy, high budget; DPDK for: flexibility, <$500K, frequent updates',
      'Hybrid approach: FPGA for critical path, software for strategy logic—best of both worlds',
    ],
  },
  {
    id: 'hfta-q-2',
    question:
      'Design a memory management system for ultra-low-latency trading that eliminates garbage collection pauses. Address: (1) object pool implementation for zero-allocation trading, (2) lock-free data structures for thread communication, (3) huge pages and memory alignment, (4) avoiding dynamic memory allocation during trading, (5) measuring and profiling memory latency. How do you test that there are truly zero GC pauses?',
    sampleAnswer:
      'Memory management for zero-GC latency: (1) Object pool: Pre-allocate all objects at startup. Never use malloc/new during trading. Implementation: template<typename T, size_t PoolSize> class ObjectPool { T pool[PoolSize]; std::bitset<PoolSize> free_mask; std::atomic<size_t> next_free; }. Acquire: O(1) lock-free operation. Scan free_mask for available slot, CAS to claim. Return pointer to pre-allocated object. No allocation, no syscall, ~10-20ns. Release: Mark slot as free. Call destructor to reset state. O(1) operation, ~10ns. Pool sizing: Calculate max simultaneous orders/positions. Add 50% buffer. Example: Max 1000 orders in-flight → allocate 1500 slots. At startup: Allocate all memory, touch all pages (force physical allocation), lock memory (mlock) to prevent swapping. Result: Zero allocation during trading, deterministic latency. (2) Lock-free data structures: Producer-consumer communication without locks. Single-Producer Single-Consumer Queue (fastest): Ring buffer with atomic head/tail pointers. Producer writes to tail, atomically increments. Consumer reads from head, atomically increments. No locks, no waiting, ~20-50ns per operation. Multi-Producer Multi-Consumer: More complex (hazard pointers, epoch-based reclamation). Or use separate queues per producer-consumer pair. Memory ordering: Use std::memory_order_acquire/release for consistency without full barriers. Reduces latency 20-30% vs sequential consistency. Why lock-free: Locks can cause 1-10μs delays (if contended). Priority inversion: Low-priority thread holds lock, blocks high-priority. Lock-free guarantees progress: At least one thread always makes progress. (3) Huge pages and alignment: Standard pages: 4KB. TLB (Translation Lookaside Buffer) holds ~64 entries. Working set: 64 × 4KB = 256KB. Larger data → TLB misses (50-100ns penalty). Huge pages: 2MB. TLB coverage: 64 × 2MB = 128MB. Allocate huge pages: mmap(..., MAP_HUGETLB). Configure: echo 1024 > /proc/sys/vm/nr_hugepages. Result: 30% latency reduction for memory-intensive operations. Cache line alignment: CPU cache line = 64 bytes. False sharing: Two threads modify different variables on same cache line → cache thrashing. Alignment: struct alignas(64) Order { ... }. Ensures each object starts on cache line boundary. Padding: Pad structures to cache line size. Result: Eliminate false sharing, 2-3x throughput improvement. (4) Avoiding dynamic allocation: Never use during trading: new/delete (C++), malloc/free (C), Standard containers (std::vector, std::map) that allocate. Exceptions (allocate stack frames). Use instead: Object pools (pre-allocated), Static arrays (fixed size, stack allocated), boost::static_vector (vector-like, no heap), Custom allocators (if must use std::vector). Stack vs heap: Stack: ~1-5ns allocation (just move stack pointer). Heap: ~100-500ns (find free block, bookkeeping). Prefer stack for small, short-lived objects. Init-time allocation: Allocate all memory at startup: Market data buffers, Order pools, Position tracking, Message queues. Lock memory: mlock (addr, size) prevents swapping. Touch all pages: Force OS to commit physical memory. Test: Run for hours without memory growth (should be flat). (5) Measuring memory latency: Tools: perf: CPU performance counters. cachegrind: Cache simulation. Intel VTune: Detailed profiling. Metrics: L1 cache hit rate (should be >99%), L2/L3 hit rates, TLB miss rate (should be <0.1%), Page faults (should be zero during trading). Testing for zero GC: Instrumentation: Record timestamp before and after each critical operation. Histogram of latencies. 99.99th percentile should be <100μs. GC detection: Monitor for pauses >1ms (indicates GC). Java: -Xlog:gc to log all GC events. Python: Use gc.disable() (not recommended but proves point). C++: No GC, but watch for malloc/free (can fragment heap). Stress test: Run for 24+ hours under max load. Record max latency every second. Plot: Should see no spikes >2× median. Example: Median 5μs, max should be <10μs. If see 10ms spike → likely GC or swapping. Continuous monitoring: Production monitoring of latency percentiles. Alert if p99.9 > threshold (indicates memory issue). Memory leak detection: Valgrind with massif (heap profiler). Memory should be constant after initialization. Leak → eventually triggers OOM and system malloc (slow). Test: Run for 1 week. Memory usage should be flat. Result: With proper memory management: Zero allocation during trading, zero GC pauses, deterministic <10μs latency, flat memory usage profile.',
    keyPoints: [
      'Object pools: pre-allocate at startup, acquire/release in ~10-20ns, no malloc/new during trading',
      'Lock-free: SPSC queue ~20-50ns, avoid locks (1-10μs delays), use atomic operations',
      'Huge pages (2MB): 30% latency reduction, TLB coverage 128MB vs 256KB, cache alignment (64B)',
      'No dynamic allocation: use pools, static arrays, stack allocations, mlock memory, touch pages',
      'Testing: perf/cachegrind, monitor for >1ms pauses, 24hr stress test, p99.9 <100μs, flat memory',
    ],
  },
  {
    id: 'hfta-q-3',
    question:
      'Explain the physical and economic constraints of high-frequency trading. Address: (1) speed of light limitations and co-location strategy, (2) diminishing returns of latency improvements, (3) arms race dynamics and sustainability, (4) infrastructure costs vs revenue potential, (5) when HFT makes sense vs other trading strategies. Is sub-microsecond trading economically viable for most firms?',
    sampleAnswer:
      "Physical and economic constraints of HFT: (1) Speed of light limitations: Light in fiber: ~200,000 km/s (2/3 speed in vacuum due to refractive index). Distance examples: Chicago to New York: 1,200 km = 6ms minimum one-way. London to Frankfurt: 500 km = 2.5ms minimum. Physical limit: Cannot beat speed of light. Even with perfect systems, distance dominates at scale. Co-location strategy: Place servers in same building as exchange matching engine. Distance: 10-100 meters = 0.05-0.5μs. Co-location racks: Next to exchange servers = ~10μs total (network + processing). Cost: $10K-50K/month per rack. Multiple locations: Need presence at every major exchange. NYSE (New York), CME (Chicago), LSE (London), Eurex (Frankfurt). Total cost: $50K-200K/month just for co-location. Cross-market arbitrage: Limited by distance. Example: S&P futures (Chicago) vs SPY ETF (New York). Latency: 6ms minimum → arbitrage opportunity must persist 10ms+ to be capturable. Microwave: Faster than fiber for long distances (straight line). Chicago-NY via microwave: 4ms vs 6ms fiber (33% faster). Cost: $millions for microwave network. Only for most competitive strategies. (2) Diminishing returns: Latency vs advantage: 10ms → 1ms: Huge advantage (10× faster). Captures ~90% of opportunities. Value: $10M-100M/year. 1ms → 100μs: Significant advantage. Captures ~70% of remaining. Value: $1M-10M/year. 100μs → 10μs: Moderate advantage. Captures ~50% of remaining. Value: $500K-5M/year. 10μs → 1μs: Small advantage. Captures ~30% of remaining. Value: $100K-1M/year. 1μs → 100ns: Minimal advantage. Captures ~10% of remaining. Value: $50K-500K/year. Beyond 100ns: Dominated by exchange matching engine latency (500ns-5μs). Gains negligible. Why diminishing: Market microstructure noise dominates. At sub-microsecond, order queue position more important than speed. Other factors matter more: Strategy quality, market impact, risk management. (3) Arms race dynamics: HFT is zero-sum: If you gain 1μs, you win order vs competitor. Competitor must match or lose business. Continuous investment: Your 1μs advantage lasts 6-12 months. Then competitors catch up. Must invest again to maintain edge. Like running up down escalator. Example: 2010: 100μs competitive, 2015: 10μs competitive, 2020: 1μs competitive, 2025: 100ns competitive. Sustainability: Only largest firms can compete long-term (Virtu, Citadel, Jump Trading). Budget: $10M-100M/year for infrastructure + development. Smaller firms: Pushed to less competitive markets (emerging markets, smaller stocks, crypto). Or pivot to different strategies (not latency-sensitive). (4) Infrastructure costs: Hardware: FPGA cards: $200K-500K, High-frequency NICs: $50K, Servers: $50K, Co-location: $200K/year (multiple sites). Total: $500K-1M upfront, $200K-500K/year recurring. Development: Hardware engineers: $200K-300K salary (2-3 needed), Software engineers: $150K-250K salary (5-10 needed), Researchers: $200K-400K salary (2-5 needed). Total: $2M-5M/year. Data and connectivity: Market data fees: $50K-200K/year, Direct exchange connections: $50K-100K/year, Microwave (optional): $1M-5M/year. Total infrastructure: $3M-10M/year. Revenue potential: Trade volume: 100K-1M orders/day, Profit per trade: $0.01-$0.10 (tiny margins), Daily profit: $1K-100K, Annual: $250K-25M. Break-even: Need $3M-10M revenue to cover costs. Requires capturing significant market share. Only top 20-30 firms profitable in HFT globally. (5) When HFT makes sense: Makes sense if: Liquid, high-volume markets (SPY, ES futures, FX majors), Latency-sensitive opportunities (arbitrage, market making), Budget $5M+ annually, Team of 10+ engineers (hardware + software), Sustainable competitive advantage (proprietary tech). Doesn't make sense if: Illiquid markets (low-volume stocks, exotic options), Fundamental strategies (value, momentum over days/weeks), Budget <$1M (can't compete on latency), Team <5 people (too small to build infrastructure), No hardware expertise (FPGA required for <1μs). Alternative strategies: Medium-frequency: 1-100ms latency (statistical arbitrage), Low-frequency: Minutes-hours (quantitative strategies), Fundamental: Days-months (value investing, trend following). These can be profitable with $100K-1M budgets vs $5M-10M for HFT. Economic viability: For most firms: No. HFT requires $5M+ annual investment. Only ~50 firms globally can compete profitably. Concentration: Top 5 firms control 50%+ of HFT volume. Barriers: Technology, capital, talent, market access. Trend: Consolidation. Small HFT firms acquired or shut down. Viable alternatives: Crypto HFT (less competitive, can start with $500K), Options market making (less speed-sensitive), Cross-border arbitrage (fewer competitors). Conclusion: Sub-microsecond HFT is arms race for elite firms with $10M+ budgets. Not economically viable for most. Better ROI from medium-frequency quant strategies (\$500K-2M budget, Sharpe 1-2 achievable).",
    keyPoints: [
      'Speed of light: fiber 200K km/s, Chicago-NY 6ms minimum, co-location 10-100m = 0.05-0.5μs, $10-50K/mo/rack',
      'Diminishing returns: 10ms→1ms huge ($10-100M), 1μs→100ns minimal ($50-500K), beyond 100ns negligible',
      'Arms race: 1μs advantage lasts 6-12 months, continuous $10M+/yr investment, only top 20-30 firms profitable',
      'Costs: $500K-1M upfront, $3-10M/yr ongoing; Revenue: $250K-25M/yr (requires high volume capture)',
      'Viable for: liquid markets, $5M+ budget, 10+ engineers, hardware expertise; Not viable: <$1M budget, small teams',
    ],
  },
];
