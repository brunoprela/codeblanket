export const regulatoryComplianceSystemsQuiz = [
  {
    id: 'rcs-q-1',
    question:
      'Design an immutable audit trail system that can withstand regulatory audits. Address: (1) data structure with blockchain-style integrity verification, (2) ensuring no tampering or deletion is possible, (3) storage strategy for 7-10 years of data, (4) query performance for regulatory investigations, (5) proving completeness (no gaps in sequence). How would you handle a scenario where regulators question the integrity of your audit trail?',
    sampleAnswer:
      'Immutable audit trail design: (1) Data structure: Blockchain-style linked hash chain. Each entry contains: timestamp (PTP-synchronized μs precision), event_type, order details, sequence_number (monotonically increasing), previous_hash (hash of previous entry), entry_hash (SHA-256 of current entry including previous_hash). Chain: Entry 1 (hash: abc123) → Entry 2 (prev_hash: abc123, hash: def456) → Entry 3 (prev_hash: def456, hash: ghi789). Any modification breaks chain (previous_hash won\'t match). Verification: Recalculate hash of each entry, verify matches stored hash, verify previous_hash links form unbroken chain. Code: entry_hash = SHA256(timestamp + event_type + order_id + ... + previous_hash). (2) Preventing tampering/deletion: Database level: Append-only tables (INSERT only, no UPDATE/DELETE permissions), PostgreSQL with row-level security, Separate compliance_admin role (only they can read, nobody can modify). Application level: Write-only API (no delete/update endpoints), Every write logs to two independent systems (primary + backup), Cross-verify between systems daily. Hardware level: Write-Once-Read-Many (WORM) storage (legally recognized for compliance), Immutable S3 buckets (Object Lock with governance/compliance mode). Monitoring: Hash verification job runs hourly, Alert if any hash mismatch detected, Track all database connections (log who accessed what). (3) Storage for 7-10 years: Tiered approach: Hot (0-90 days): PostgreSQL on SSD, query latency <10ms, cost $1000/mo. Warm (90 days - 2 years): ClickHouse or Parquet on SSD, query latency ~100ms, cost $300/mo. Cold (2-7 years): S3 Standard with compression, query latency 1-5s, cost $50/mo. Archival (7-10 years): S3 Glacier Deep Archive, retrieval 12 hours, cost $5/mo. Lifecycle policies: Auto-move data between tiers, Compression: Parquet columnar format (10:1 compression), Deduplication: Remove duplicate metadata. Example: 1M orders/day × 1KB/order = 1GB/day. 10 years = 3.65TB uncompressed, ~400GB compressed. Cost: Hot $1K + Warm $300 + Cold $50 + Archive $5 = $1,355/mo total. (4) Query performance: Indexes: Create indexes on: timestamp, user_id, account_id, symbol, order_id. B-tree indexes for range queries (timestamp), Hash indexes for exact match (order_id). Partitioning: Partition by date (daily or monthly partitions), Query only relevant partitions (date range). Materialized views: Pre-compute common queries (orders by user, daily volumes). Refresh nightly. Caching: Cache recent frequent queries (Redis), 1-hour TTL. Query optimization: Use EXPLAIN ANALYZE, optimize slow queries, Consider denormalization for common joins. Performance targets: Recent data (0-90 days): <100ms, Historical (90 days - 2 years): <1s, Archival (2+ years): <10s (acceptable for investigations). (5) Proving completeness: Sequence numbers: Monotonically increasing (1, 2, 3, ..., no gaps). Daily verification: Check no gaps in sequence. Alert if gap detected (indicates missing entry). Checkpoints: End-of-day checkpoint with: Last sequence number, Count of entries that day, Hash of last entry. Next day starts: sequence = yesterday_last + 1. Gap detection: SELECT sequence_number FROM audit WHERE sequence_number NOT IN (SELECT generate_series(1, (SELECT MAX(sequence_number) FROM audit))). If returns rows → gaps exist. Reconciliation: Cross-check with: Exchange confirmations (all fills accounted for), OMS order count (matches audit trail count), Daily trading reports (volumes match). Independent verification: Third-party auditor reviews quarterly, Provide hash chain + checksums, They verify integrity independently. Proving to regulators: Scenario: Regulator questions: "How do we know you didn\'t delete orders?" Response: (a) Show hash chain verification: Run verification script in front of regulator, Demonstrate any modification breaks chain. (b) Provide independent verification: Third-party quarterly audit reports, Cross-reference with exchange records (exchanges have their own audit trail). (c) Show write-only architecture: Database permissions (nobody has DELETE), WORM storage certificates (legally recognized), Application code review (no delete endpoints). (d) Provide checksums: Daily checksums of audit trail (stored separately), Checksums match → no modification. (e) Demonstrate completeness: Sequence numbers with no gaps, Reconciliation reports (matches exchange volumes), Count matches: OMS says 10,000 orders → audit has 10,000 entries. Additional evidence: Logs of all database access (who queried when), Backup tapes (immutable, stored off-site), Blockchain notarization (optional: publish daily hash to public blockchain for timestamp proof). Result: Regulators satisfied if: Audit trail has unbroken hash chain, sequence numbers complete, cross-references match external sources (exchange), no evidence of tampering capability. Key: Design system where tampering is technically impossible, not just policy-prohibited.',
    keyPoints: [
      'Hash chain: Each entry links to previous via SHA-256, any modification breaks chain, hourly verification',
      'Immutability: append-only tables, write-only API, WORM storage, no UPDATE/DELETE permissions',
      'Storage tiers: Hot (PostgreSQL <10ms), Warm (ClickHouse ~100ms), Cold (S3 1-5s), Archive (Glacier 12hr)',
      'Completeness: sequence numbers with no gaps, daily checkpoint, reconcile with exchange records',
      'Proving to regulators: demonstrate hash chain verification, WORM storage, independent third-party audits, sequence completeness',
    ],
  },
  {
    id: 'rcs-q-2',
    question:
      "Design a trade surveillance system that detects market manipulation (wash trading, layering, spoofing). For each pattern: (1) explain the manipulation technique and why it's illegal, (2) design detection algorithm with specific thresholds, (3) minimize false positives while catching true violations, (4) integrate with compliance workflow. How do you balance automated detection with human review?",
    sampleAnswer:
      "Trade surveillance system: (1) Wash Trading: Technique: Trader buys and sells same security to create artificial volume. Purpose: Inflate volume to attract other traders (looks like liquidity), manipulate closing price, create false activity. Why illegal: Deceptive practice, misleads market participants. Detection algorithm: Pattern: User buys and sells same symbol within short window (10-60 seconds). Same account or related accounts (family members, same firm). Similar quantities (buy 100, sell 95-105). Thresholds: Time window: 60 seconds, quantity match: ±10%, minimum occurrences: 3+ times in day (isolated incident may be legitimate). Code: for symbol in user_orders.symbols: buys = [o for o in orders if o.side == BUY and o.symbol == symbol]. sells = [o for o in orders if o.side == SELL and o.symbol == symbol]. for buy in buys: for sell in sells: if abs (buy.timestamp - sell.timestamp) < 60 seconds and abs (buy.quantity - sell.quantity) < buy.quantity * 0.1 and match_count >= 3: ALERT. False positives: Legitimate scenario: User changes mind (buy, then sell minutes later). Mitigation: Require 3+ occurrences (pattern, not isolated), check for external factors (news event triggered sell), flag for review, not automatic block. (2) Layering: Technique: Place large orders on one side to move market, small order on opposite side executes, cancel large orders. Example: Place 10K buy orders at $100.01-$100.05 (looks like demand), Place 100 sell order at $100.10 (actual intent), Market sees demand, price rises to $100.10, Sell order fills, Cancel 10K buy orders. Purpose: Manipulate price to fill desired order. Why illegal: Creates false impression of supply/demand. Detection: Pattern: Large orders on one side (10:1 ratio or higher), Small order on opposite side, Large orders canceled shortly after small order fills. Thresholds: Imbalance ratio: 10:1, cancellation window: Within 60 seconds of fill, minimum order size: 1000+ shares (small retail orders excluded). Code: for symbol in active_orders: buy_qty = sum (o.quantity for o in orders if o.side == BUY). sell_qty = sum (o.quantity for o in orders if o.side == SELL). if buy_qty > 10 * sell_qty: # Check if small sell fills, then large buys canceled. if small_order_filled and large_orders_canceled_within_60s: ALERT. False positives: Legitimate: Market maker providing liquidity (large orders both sides). Mitigation: Whitelist registered market makers, check for sustained activity (market makers keep orders active), require pattern repetition (3+ occurrences). (3) Spoofing: Technique: Place large order with no intent to execute, create false impression, cancel before execution. Example: Place 5K buy order at $100 (looks like demand), Price rises as others follow, Cancel order before it fills, Profit on separate position. Why illegal: Deceptive, manipulates price discovery. Detection: Pattern: Large order placed, order canceled before execution (repeatedly), user profits from opposite position. Thresholds: Order size: 1000+ shares, cancel rate: >80% of large orders canceled, timing: Cancel within seconds of approaching fill, repetition: 3+ times per day. Code: user_large_orders = [o for o in orders if o.quantity > 1000]. canceled = [o for o in user_large_orders if o.status == CANCELED]. cancel_rate = len (canceled) / len (user_large_orders). if cancel_rate > 0.8 and repetition >= 3: ALERT. False positives: Legitimate: Changed trading strategy (market conditions changed), iceberg orders (legitimate large order management). Mitigation: Check for opposite-side activity (did user profit?), analyze intent (does user have history of this pattern?), threshold tuning (require 80%+ cancel rate, not 50%). (4) Integration with compliance workflow: Automated detection (real-time): Surveillance algorithms run continuously, generate alerts scored by severity (LOW/MEDIUM/HIGH). Queue for review: Alerts sent to compliance dashboard, HIGH severity: Immediate review (within 1 hour), MEDIUM: Review within 1 day, LOW: Batch review weekly. Human review: Compliance analyst reviews alert, context: User history (first-time vs repeat offender), market conditions (volatile day?), profit amount (small error vs large gain?). Decision: False positive: Dismiss with notes, True violation: Escalate to management, Block user: Temporarily suspend trading, Report: File SAR (Suspicious Activity Report) with regulator. Feedback loop: Analysts mark alerts as true/false positive, tune thresholds based on false positive rate (target <5%), retrain ML models if used. Balance automation vs human review: Automated detection: Good for: Pattern recognition (identifies candidates), scale (monitor millions of orders), speed (real-time alerts). Bad for: Context (doesn't understand intent), false positives (rigid rules), edge cases (novel manipulation). Human review: Good for: Context (understands intent), judgment (distinguishes legitimate from manipulation), final decision (legal liability). Bad for: Scale (can't review all orders), speed (hours/days lag), cost ($50-100K salary per analyst). Optimal balance: Automation: Screen 100% of orders, filter to top 1% suspicious (ML or rules), score by severity. Human: Review top 1% flagged (manageable volume), investigate HIGH severity within 1 hour, approve/dismiss with reasoning. Result: 99% of orders auto-cleared, 1% reviewed by humans, <0.01% escalated as violations. Compliance SLA: Detection: Within 1 minute of suspicious activity, review: HIGH within 1 hour, reporting: SAR within 30 days of detection. Cost: 10 compliance analysts @ $80K = $800K/year, vs cost of violation: $millions fine + license suspension. Example: Detect 100 suspicious patterns/day, 5% true violations (5/day), 95% false positives (95/day dismissed quickly). Annual: 1,825 true violations detected and prevented (saves firm from regulatory action). Key: Automated detection casts wide net, human review applies judgment, continuous tuning reduces false positives.",
    keyPoints: [
      'Wash trading: buy and sell same symbol within 60s, ±10% quantity, 3+ occurrences, check related accounts',
      'Layering: 10:1 order imbalance, small opposite order, large orders canceled within 60s of fill',
      'Spoofing: large order with >80% cancel rate, 3+ times/day, check for opposite-side profit',
      'Workflow: automated detection (screen 100%), score severity, human review top 1%, escalate <0.01%',
      'Balance: automation for scale/speed, humans for context/judgment, tune to <5% false positive rate',
    ],
  },
  {
    id: 'rcs-q-3',
    question:
      'Design a regulatory reporting system for multiple jurisdictions (US CAT, Europe MiFID II, Asia local requirements). Address: (1) data format requirements per jurisdiction, (2) submission timing and deadlines, (3) handling late or failed submissions, (4) data privacy compliance (GDPR), (5) cost optimization for reporting infrastructure. How do you ensure 100% reporting compliance?',
    sampleAnswer:
      "Multi-jurisdiction reporting system: (1) Data format requirements: US CAT (Consolidated Audit Trail): Format: JSON, fields: firmDesignatedID, eventTimestamp, symbol, eventType, side, quantity, price, accountHolderType (encoded for privacy). Encoding: Customer IDs hashed (irreversible), internal IDs for linkage. Scope: All US equity orders (NYSE, NASDAQ, BATS). MiFID II (Europe): Format: XML (FIX 5.0 dialect), fields: transactionReferenceNumber, tradingDateTime, buyerID, sellerID, instrument, quantity, price, venue. Encoding: LEI (Legal Entity Identifier) for counterparties, ISO 20022 message format. Scope: All EU trades (stocks, bonds, derivatives). Asia (varies by country): Japan FSA: Proprietary format, TSV files, JIS encoding. Hong Kong SFC: CSV format, daily trade reports. Normalization layer: Store internal format (comprehensive), transform to jurisdiction-specific format on submission. Code: class ReportGenerator: def generate_cat (self, orders): return [self.to_cat_format (o) for o in orders]. def generate_mifid (self, orders): return [self.to_mifid_format (o) for o in orders]. def to_cat_format (self, order): return {firmDesignatedID: order.id, eventTimestamp: order.timestamp, ...}. (2) Submission timing: US CAT: Deadline: 8am EST next business day, frequency: Daily, penalty: $1,000+ per day late. MiFID II: Deadline: End of next business day (T+1), frequency: Daily, penalty: €5,000+ per violation. Japan FSA: Deadline: Monthly by 15th of next month, frequency: Monthly. Automation: Scheduled jobs: CAT job runs at 6am EST (2 hours before deadline for buffer), MiFID job runs at 10pm CET (2 hours before midnight). Monitoring: Alert if job fails, page on-call engineer. Retry logic: If submission fails, retry 3 times with exponential backoff, if still fails, escalate to compliance team. Buffer: Generate reports 2-6 hours before deadline (gives time to fix issues). (3) Handling late/failed submissions: Detection: Job monitoring (expected completion time), alert if not completed by deadline - 1 hour. Automatic remediation: Retry with fresh data pull (may have been transient DB issue), submit to backup endpoint if primary down. Manual escalation: If auto-retry fails, page compliance manager, gather: error logs, data snapshot, root cause. Late submission protocol: File with regulator immediately (even if late), provide explanation letter, fix root cause to prevent recurrence. Penalties: US CAT: $1,000/day late (compounds), Europe: €5,000 per violation. Prevention worth investment. Backup plan: Pre-generate reports hourly (not just daily), if main system fails, submit from backup. Post-incident: Root cause analysis (RCA), update runbook, add monitoring to prevent recurrence. Testing: Monthly chaos drill (deliberately fail reporting job), verify alerts fire, verify team responds correctly, measure MTTR (mean time to resolve). (4) GDPR data privacy: Challenge: CAT requires customer data, GDPR prohibits transferring EU resident data to US. Solution: Data minimization: Only report what's required (order details, not full customer profile). Pseudonymization: Hash customer IDs (one-way function), consistent hashing (same customer = same hash for linkage). Territorial: EU customer orders only reported to MiFID II (not CAT), US customer orders reported to CAT, Separate data stores per region. Legal basis: Article 6(1)(c): Compliance with legal obligation (CAT/MiFID reporting required by law). Data residency: EU data stays in EU data center, US data stays in US, cross-border transfers: Use standard contractual clauses (SCC) if needed. Audit: GDPR audit annually, verify minimal data in reports, verify hashes irreversible. (5) Cost optimization: Reporting costs: Data storage: $1,000/mo (7 years retention), compute: $500/mo (daily jobs), API fees: $200/mo (CAT submission fees), staff: $80K/year compliance engineer. Optimization: Incremental updates: Don't re-process all historical data daily, only new orders since last run. Compression: Parquet format (10:1 compression), S3 Intelligent Tiering (auto-move to cheaper storage). Batch processing: Process in bulk (not per-order), use Spark for large data sets (parallel processing). Caching: Cache common lookups (symbol reference data), avoid redundant DB queries. Monitoring: Track costs monthly, alert if spike (indicates inefficiency). Total cost: $30K-50K/year for multi-jurisdiction reporting (small compared to fine risk). Ensuring 100% compliance: Redundancy: Dual systems (primary + backup), both generate reports independently, cross-verify (should match), submit from primary, backup on standby. Verification: Pre-submission checks: Record count matches OMS (all orders included), no schema errors (validate against XSD/JSON schema), no missing required fields. Post-submission: Exchange acknowledgment (verify regulator received), daily reconciliation (submitted count = actual order count). Monitoring: Real-time dashboards: Submission status per jurisdiction, success rate (target: 100%), alert on any failure. Audit trail: Log every submission attempt (timestamp, record count, success/failure, response), maintain for 7 years. Testing: Quarterly: Submit test reports to regulator test environment, verify accepted. Annually: Full end-to-end test (generate reports for full year), verify all formats correct. Change management: Any code change to reporting: Requires compliance approval, test on sandbox first, parallel run (new + old system) for 1 week. Result: With redundancy + verification + monitoring → 99.9%+ compliance rate. Miss 1-2 deadlines per year max (vs 365 daily submissions). Cost of compliance: $50K/year. Cost of non-compliance: $millions fines + license suspension. ROI obvious.",
    keyPoints: [
      'Formats: CAT (JSON), MiFID II (XML/FIX 5.0), Asia varies, normalize internal then transform per jurisdiction',
      'Timing: CAT 8am EST (2hr buffer), MiFID T+1 (2hr buffer), automated jobs with retry logic',
      'Failures: auto-retry 3x, escalate to compliance, backup system, monthly chaos drills, late submission protocol',
      'GDPR: pseudonymize customer IDs (hash), data minimization, territorial separation (EU data in EU)',
      'Compliance: dual systems (primary + backup), pre/post checks, 99.9%+ success rate, $50K/yr cost vs $millions fine risk',
    ],
  },
];
