export const realTimePlatformProjectQuiz = [
  {
    id: 'real-time-platform-project-q-1',
    question:
      'Design the complete architecture for a real-time market data platform supporting 500 symbols at 100 ticks/second each (50K ticks/sec total). Specify: (1) Infrastructure components (Kafka, TimescaleDB, Redis), (2) Scaling strategy, (3) Latency budget breakdown, (4) Cost analysis at AWS. Provide deployment architecture and configuration.',
    sampleAnswer:
      'Complete platform architecture:\n\n**Infrastructure Components**:\n\n1. **Kafka Cluster** (Distribution layer)\n   - 3 brokers (high availability)\n   - Topic: market-data-quotes, 50 partitions\n   - Replication factor: 3\n   - Retention: 7 days\n   - AWS: 3× m5.large ($0.096/hr) = $208/mo\n\n2. **TimescaleDB** (Storage layer)\n   - PostgreSQL 15 + TimescaleDB extension\n   - Instance: db.r5.2xlarge (8 vCPU, 64GB RAM)\n   - Storage: 5 TB EBS gp3 (compressed from 25 TB raw)\n   - AWS: $1,200/mo (instance) + $500/mo (storage) = $1,700/mo\n\n3. **Redis Cluster** (Caching)\n   - 3 nodes for redundancy\n   - cache.r5.large (13GB RAM each)\n   - AWS: 3× $0.126/hr = $270/mo\n\n4. **Application Servers** (Data ingestion + normalization)\n   - 5× c5.xlarge (4 vCPU, 8GB RAM)\n   - Each handles 10K ticks/sec\n   - AWS: 5× $0.17/hr = $612/mo\n\n**Total Cost**: $2,790/mo for 50K ticks/sec platform\n\n**Latency Budget** (Target: < 10ms end-to-end)\n- Data ingestion (WebSocket): 2ms\n- Normalization + validation: 1ms\n- Kafka publish: 2ms\n- Network: 2ms\n- Kafka consume: 2ms\n- Strategy processing: 1ms\n**Total: 10ms** ✓\n\n**Scaling Strategy**:\n- Horizontal: Add app servers (10K ticks/sec each)\n- Kafka: Increase partitions (currently 50, can go to 200)\n- TimescaleDB: Read replicas for queries\n- At 500K ticks/sec (10× scale): $15K/mo',
    keyPoints: [
      'Infrastructure: 3 Kafka brokers, 1 TimescaleDB (r5.2xlarge), 3 Redis nodes, 5 app servers',
      'Cost: $2,790/mo for 50K ticks/sec ($208 Kafka + $1,700 TimescaleDB + $270 Redis + $612 apps)',
      'Latency: 10ms total (2ms ingestion + 1ms normalization + 2ms Kafka pub + 2ms network + 2ms consume + 1ms strategy)',
      'Scaling: Horizontal app servers (10K ticks/sec each), increase Kafka partitions (50 → 200)',
      'At 10× scale (500K ticks/sec): $15K/mo, linear scaling achieved',
    ],
  },
  {
    id: 'real-time-platform-project-q-2',
    question:
      'Implement monitoring and alerting for the platform using Prometheus + Grafana. Define: (1) Critical metrics to track, (2) Alert thresholds, (3) Escalation procedures, (4) SLA targets (99.9% uptime = 8.76 hrs downtime/year). Provide Prometheus config and alert rules.',
    sampleAnswer:
      "Monitoring and alerting implementation:\n\n**Critical Metrics**:\n\n1. **Throughput**\n   - `quotes_received_per_second` (target: 50K)\n   - `quotes_processed_per_second`\n   - `quotes_rejected_per_second` (< 1% acceptable)\n\n2. **Latency**\n   - `processing_latency_p50` (target: < 5ms)\n   - `processing_latency_p99` (target: < 10ms)\n   - `kafka_produce_latency`\n   - `kafka_consumer_lag` (< 1000 messages)\n\n3. **Error Rates**\n   - `validation_error_rate` (< 1%)\n   - `kafka_connection_errors`\n   - `database_write_errors`\n\n4. **System Health**\n   - `cpu_usage` (< 80%)\n   - `memory_usage` (< 85%)\n   - `disk_usage` (< 90%)\n\n**Prometheus Config**:\n```yaml\n# prometheus.yml\nglobal:\n  scrape_interval: 10s\n  evaluation_interval: 10s\n\nscrape_configs:\n  - job_name: 'market-data-platform'\n    static_configs:\n      - targets:\n        - 'app-server-1:8000'\n        - 'app-server-2:8000'\n        - 'app-server-3:8000'\n\nalerting:\n  alertmanagers:\n    - static_configs:\n        - targets: ['alertmanager:9093']\n\nrule_files:\n  - 'alerts.yml'\n```\n\n**Alert Rules**:\n```yaml\n# alerts.yml\ngroups:\n  - name: market_data_alerts\n    interval: 30s\n    rules:\n      # Critical: System down\n      - alert: SystemDown\n        expr: up == 0\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Platform down\"\n          description: \"{{ $labels.instance }} has been down for 1 minute\"\n      \n      # Critical: High latency\n      - alert: HighLatency\n        expr: histogram_quantile(0.99, processing_latency_seconds) > 0.010\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"P99 latency > 10ms\"\n      \n      # Warning: Throughput drop\n      - alert: ThroughputDrop\n        expr: rate(quotes_received_total[1m]) < 40000\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"Throughput dropped below 40K/sec\"\n      \n      # Critical: High error rate\n      - alert: HighErrorRate\n        expr: rate(quotes_rejected_total[5m]) / rate(quotes_received_total[5m]) > 0.01\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Error rate > 1%\"\n```\n\n**Escalation Procedures**:\n\n1. **Warning** (yellow)\n   - Slack notification to #market-data-ops\n   - Ops team investigates within 30 minutes\n\n2. **Critical** (red)\n   - PagerDuty alert to on-call engineer\n   - Slack notification to #market-data-critical\n   - Response required within 5 minutes\n   - Auto-escalate to manager if no ack in 15 minutes\n\n3. **SLA Breach** (99.9% uptime)\n   - Immediate executive notification\n   - Post-mortem required within 24 hours\n\n**SLA Tracking**:\n```python\n# Calculate uptime\ntotal_time = 365 * 24 * 60  # minutes/year\ndowntime_minutes = sum(incident_durations)\nuptime_pct = ((total_time - downtime_minutes) / total_time) * 100\n\nif uptime_pct < 99.9:\n    alert_sla_breach()\n# 99.9% = 525.6 minutes downtime allowed/year\n```",
    keyPoints: [
      'Metrics: Throughput (50K ticks/sec target), latency (P99 < 10ms), error rate (< 1%), system health',
      'Prometheus: 10s scrape interval, alert evaluation every 30s, multi-server monitoring',
      'Alerts: SystemDown (critical, 1min), HighLatency (critical, P99 > 10ms), ThroughputDrop (warning, < 40K/sec)',
      'Escalation: Warning → Slack (30min response), Critical → PagerDuty (5min response), SLA breach → executive alert',
      'SLA: 99.9% uptime = 525.6 minutes downtime allowed/year (8.76 hours), track monthly',
    ],
  },
  {
    id: 'real-time-platform-project-q-3',
    question:
      'Perform load testing on the platform. Test: (1) Peak load (100K ticks/sec, 2× normal), (2) Sustained load (50K ticks/sec for 6 hours), (3) Failure recovery (kill Kafka broker mid-test). Measure latency, throughput, error rate. Provide load test implementation and results analysis.',
    sampleAnswer:
      "Load testing implementation:\n\n**Load Test Setup**:\n```python\n# load_test.py\nimport asyncio\nimport time\nimport random\nfrom aiokafka import AIOKafkaProducer\n\nclass LoadTester:\n    def __init__(self, target_tps: int):\n        self.target_tps = target_tps  # Ticks per second\n        self.producer = AIOKafkaProducer(\n            bootstrap_servers='localhost:9092'\n        )\n        \n        # Metrics\n        self.sent = 0\n        self.errors = 0\n        self.latencies = []\n    \n    async def generate_tick(self):\n        \"\"\"Generate realistic market data tick\"\"\"\n        return {\n            'symbol': random.choice(['AAPL', 'GOOGL', 'MSFT'] * 100),  # 300 symbols\n            'bid': round(150 + random.uniform(-1, 1), 2),\n            'ask': round(150.02 + random.uniform(-1, 1), 2),\n            'timestamp': time.time()\n        }\n    \n    async def run_load_test(self, duration_seconds: int):\n        \"\"\"Run load test for specified duration\"\"\"\n        await self.producer.start()\n        \n        start_time = time.time()\n        interval = 1.0 / self.target_tps  # Time between ticks\n        \n        while time.time() - start_time < duration_seconds:\n            tick_start = time.perf_counter()\n            \n            tick = await self.generate_tick()\n            \n            try:\n                await self.producer.send('market-data-quotes', value=tick)\n                self.sent += 1\n                \n                # Measure latency\n                latency = (time.perf_counter() - tick_start) * 1000\n                self.latencies.append(latency)\n            \n            except Exception as e:\n                self.errors += 1\n            \n            # Rate limiting\n            await asyncio.sleep(max(0, interval - (time.perf_counter() - tick_start)))\n        \n        await self.producer.stop()\n        \n        return self.get_stats()\n    \n    def get_stats(self):\n        import numpy as np\n        \n        return {\n            'total_sent': self.sent,\n            'total_errors': self.errors,\n            'error_rate': self.errors / self.sent if self.sent > 0 else 0,\n            'avg_latency_ms': np.mean(self.latencies),\n            'p50_latency_ms': np.percentile(self.latencies, 50),\n            'p99_latency_ms': np.percentile(self.latencies, 99),\n            'p999_latency_ms': np.percentile(self.latencies, 99.9)\n        }\n\n# Test 1: Peak Load\nprint(\"Test 1: Peak Load (100K ticks/sec for 5 min)\")\ntester = LoadTester(target_tps=100000)\nresults = await tester.run_load_test(duration_seconds=300)\n\n# Test 2: Sustained Load\nprint(\"Test 2: Sustained Load (50K ticks/sec for 6 hours)\")  \ntester = LoadTester(target_tps=50000)\nresults = await tester.run_load_test(duration_seconds=6*3600)\n\n# Test 3: Failure Recovery\nprint(\"Test 3: Failure Recovery\")\ntester = LoadTester(target_tps=50000)\n# Kill Kafka broker after 2 minutes\nasync def kill_broker():\n    await asyncio.sleep(120)\n    os.system('docker stop kafka-broker-2')\n    await asyncio.sleep(60)\n    os.system('docker start kafka-broker-2')\n\nasyncio.create_task(kill_broker())\nresults = await tester.run_load_test(duration_seconds=300)\n```\n\n**Test Results**:\n\n**Test 1: Peak Load (100K ticks/sec)**\n```\nDuration: 5 minutes\nTotal sent: 30,000,000 ticks\nErrors: 15,234 (0.05%)\nAverage latency: 8.2ms\nP50 latency: 5.1ms\nP99 latency: 18.5ms\nP99.9 latency: 45.2ms\nThroughput: 100,000 ticks/sec ✓\n```\nConclusion: System handles 2× peak load with acceptable latency.\n\n**Test 2: Sustained Load (50K ticks/sec, 6 hours)**\n```\nDuration: 6 hours\nTotal sent: 1,080,000,000 ticks\nErrors: 542 (0.00005%)\nAverage latency: 4.5ms\nP99 latency: 9.8ms ✓\nCPU usage: 65% (stable)\nMemory: 45% (no leaks)\n```\nConclusion: No degradation over time, memory stable.\n\n**Test 3: Failure Recovery**\n```\nBefore failure (0-2 min): \n  Latency P99: 9.5ms\n  Error rate: 0.01%\n\nDuring failure (2-3 min):\n  Latency P99: 125ms (degraded)\n  Error rate: 2.5% (higher)\n  \nAfter recovery (3-5 min):\n  Latency P99: 11.2ms (recovered)\n  Error rate: 0.02%\n  \nRecovery time: 45 seconds\n```\nConclusion: Kafka replication works, auto-recovery successful.\n\n**Overall Assessment**: Platform passes all load tests ✓",
    keyPoints: [
      'Peak load: 100K ticks/sec (2× normal), 8.2ms avg latency, 18.5ms P99, 0.05% error rate - passes',
      'Sustained: 50K ticks/sec for 6 hours (1.08B ticks), 4.5ms avg, 9.8ms P99, no memory leaks - passes',
      'Failure recovery: Broker killed at 2min, latency spikes to 125ms, recovers in 45sec - passes',
      'Results: System handles 2× peak load, sustains 6 hours without degradation, auto-recovers from failures',
      'Implementation: Async load generator, realistic tick data, rate limiting, comprehensive metrics collection',
    ],
  },
];
