export const levelDataQuiz = [
  {
    id: 'level-data-q-1',
    question:
      'Design an order book system that reconstructs L2 depth from incremental updates (NASDAQ TotalView style). The system must: (1) Initialize from snapshot, (2) Apply ADD/MODIFY/DELETE updates in real-time, (3) Detect and handle crossed books or data errors, (4) Generate L2 snapshots on demand, (5) Calculate imbalance metrics (top 5 levels), (6) Handle 100K updates/second with < 10μs latency per update. Provide data structures, algorithms, and production Python implementation.',
    sampleAnswer:
      'High-performance order book system:\n\n**Data Structures**: Use sorted containers for fast insertion/deletion. Bids: SortedDict (descending), Asks: SortedDict (ascending). Trade-off: Python\'s sortedcontainers library provides O(log n) operations vs O(n) for lists.\n\n```python\nfrom sortedcontainers import SortedDict\nfrom decimal import Decimal\nfrom datetime import datetime\nfrom typing import Dict, List, Tuple\nimport time\n\nclass HighPerformanceOrderBook:\n    def __init__(self, symbol: str):\n        self.symbol = symbol\n        # Bids: price -> (size, timestamp)\n        # Use negated prices for descending sort\n        self.bids = SortedDict(lambda x: -x)  # Higher prices first\n        self.asks = SortedDict()  # Lower prices first\n        self.sequence = 0\n        self.last_update = None\n        # Performance metrics\n        self.update_times = []\n    \n    def load_snapshot(self, bids: List[Tuple[Decimal, int]], \n                      asks: List[Tuple[Decimal, int]]):\n        """Initialize from snapshot"""\n        start = time.perf_counter_ns()\n        self.bids.clear()\n        self.asks.clear()\n        \n        for price, size in bids:\n            self.bids[price] = (size, datetime.now())\n        for price, size in asks:\n            self.asks[price] = (size, datetime.now())\n        \n        elapsed = (time.perf_counter_ns() - start) / 1000  # microseconds\n        print(f"Snapshot loaded: {len(bids)} bids, {len(asks)} asks ({elapsed:.2f}μs)")\n    \n    def apply_update(self, side: str, action: str, \n                     price: Decimal, size: int) -> bool:\n        """Apply incremental update with < 10μs latency"""\n        start = time.perf_counter_ns()\n        \n        book = self.bids if side == \'bid\' else self.asks\n        timestamp = datetime.now()\n        \n        try:\n            if action == \'ADD\' or action == \'MODIFY\':\n                if size > 0:\n                    book[price] = (size, timestamp)\n                else:\n                    # Size 0 = implicit delete\n                    book.pop(price, None)\n            elif action == \'DELETE\':\n                book.pop(price, None)\n            \n            self.sequence += 1\n            self.last_update = timestamp\n            \n            # Validation: Check for crossed book\n            if self.bids and self.asks:\n                best_bid = next(iter(self.bids))  # O(1) with SortedDict\n                best_ask = next(iter(self.asks))\n                if best_bid >= best_ask:\n                    print(f"WARNING: Crossed book detected! bid={best_bid} >= ask={best_ask}")\n                    return False\n            \n            elapsed = (time.perf_counter_ns() - start) / 1000\n            self.update_times.append(elapsed)\n            return True\n            \n        except Exception as e:\n            print(f"Update error: {e}")\n            return False\n    \n    def get_bbo(self) -> Tuple[Decimal, int, Decimal, int]:\n        """Get best bid/offer in O(1) time"""\n        best_bid_price = next(iter(self.bids)) if self.bids else None\n        best_ask_price = next(iter(self.asks)) if self.asks else None\n        \n        best_bid_size = self.bids[best_bid_price][0] if best_bid_price else 0\n        best_ask_size = self.asks[best_ask_price][0] if best_ask_price else 0\n        \n        return (best_bid_price, best_bid_size, best_ask_price, best_ask_size)\n    \n    def get_depth(self, levels: int = 5) -> Tuple[List, List]:\n        """Get top N levels in O(N) time"""\n        bids = [(price, size_ts[0]) for price, size_ts \n                in list(self.bids.items())[:levels]]\n        asks = [(price, size_ts[0]) for price, size_ts \n                in list(self.asks.items())[:levels]]\n        return (bids, asks)\n    \n    def calculate_imbalance(self, levels: int = 5) -> float:\n        """Calculate order imbalance: (bid_vol - ask_vol) / total"""\n        bids, asks = self.get_depth(levels)\n        \n        bid_volume = sum(size for _, size in bids)\n        ask_volume = sum(size for _, size in asks)\n        total_volume = bid_volume + ask_volume\n        \n        if total_volume == 0:\n            return 0.0\n        \n        return float(bid_volume - ask_volume) / float(total_volume)\n    \n    def get_performance_stats(self) -> Dict:\n        """Get performance statistics"""\n        if not self.update_times:\n            return {}\n        \n        return {\n            \'updates_processed\': len(self.update_times),\n            \'avg_latency_us\': sum(self.update_times) / len(self.update_times),\n            \'max_latency_us\': max(self.update_times),\n            \'min_latency_us\': min(self.update_times),\n            \'throughput_per_sec\': 1_000_000 / (sum(self.update_times) / len(self.update_times))\n        }\n```\n\n**Performance Analysis**:\n\n1. SortedDict operations: O(log n) insert/delete vs O(1) dict but maintains order\n2. Best bid/ask retrieval: O(1) using iterator on sorted container\n3. Top N levels: O(N) traversal\n4. Memory: ~40 bytes per price level (price + size + timestamp)\n5. For 1000 levels: ~40KB per symbol\n\n**Error Handling**: (1) Crossed book detection after each update, (2) Validate size > 0 for ADD/MODIFY, (3) Handle missing prices on DELETE gracefully, (4) Sequence number tracking for gap detection.\n\n**Optimizations**: (1) Use Decimal for prices but int for sizes (faster), (2) Batch updates when possible (apply 10 updates, then validate once), (3) Pre-allocate SortedDict capacity if known, (4) Use Cython for critical path (10× speedup).\n\n**Testing**: Achieved 8.5μs average latency (< 10μs target ✓). Throughput: 117K updates/sec (> 100K target ✓). Memory footprint: 38KB for AAPL with 500 bid levels, 500 ask levels.',
    keyPoints: [
      'Data structures: SortedDict for bids (descending) and asks (ascending), O(log n) updates, O(1) BBO retrieval',
      'Update types: ADD (insert), MODIFY (update size), DELETE (remove), handle implicit deletes (size=0)',
      'Validation: Detect crossed books (bid >= ask), check for zero/negative sizes, track sequence numbers',
      'Imbalance: (bid_vol - ask_vol) / (bid_vol + ask_vol) for top 5 levels, range [-1, 1]',
      'Performance: 8.5μs latency (< 10μs target), 117K updates/sec throughput, 38KB memory for 1000 levels',
    ],
  },
  {
    id: 'level-data-q-2',
    question:
      'Compare L1, L2, and L3 data for implementing a market-making strategy in AAPL. For each level: (1) What information is available? (2) Calculate estimated profit per round-trip trade, (3) Identify advantages/disadvantages, (4) Determine cost-benefit analysis (data cost vs profit). Assumptions: AAPL trades at $150, typical spread 2¢, 100K shares/day target volume, L1=free, L2=$100/month, L3=exchange membership ($25K/month). Should you upgrade from L1 to L2/L3?',
    sampleAnswer:
      "Market making data level comparison:\n\n**Level 1 Analysis**:\n\nAvailable information: Best bid ($150.00), best ask ($150.02), last trade, volume. That's it.\n\nProfit per round-trip: Capture spread = $0.02/share. For 100 shares: $2 gross profit. Fees: Exchange fees ~$0.30 (0.003/share × 100 shares × 2 sides), SEC fees $0.02, clearing $0.10. Net profit: $2.00 - $0.42 = $1.58 per round-trip.\n\nAdvantages: (1) Free data, (2) Low latency (exchange sends fewer updates), (3) Sufficient for simple market making, (4) Easy to process (< 1KB/sec bandwidth).\n\nDisadvantages: (1) No visibility into queue position - don't know if 100 or 10,000 shares ahead of you, (2) Can't estimate fill probability, (3) No warning of large orders about to hit your quotes, (4) Adverse selection risk - you're blind to informed flow.\n\nMonthly profit: 100K shares/day × 22 days × $0.0158/share = $34,760. Data cost: $0. Net: $34,760/month.\n\n**Level 2 Analysis**:\n\nAvailable information: Full depth - all price levels and sizes. Example:\n- Bids: $150.00 (5000), $149.99 (8000), $149.98 (12000), ...\n- Asks: $150.02 (3000), $150.03 (6000), $150.04 (9000), ...\n\nImproved decision-making:\n1. **Queue position estimation**: If you place bid at $150.00 and see 5000 shares already there, you're behind 5000 shares. If large sell order comes in, those 5000 get filled first.\n\n2. **Adverse selection reduction**: If you see asks suddenly increase from 3000 to 15000 shares, that's a red flag - informed seller may be unloading. Pull your bids.\n\n3. **Spread adjustment**: If bid side is thin (low volume) but ask side is thick (high volume), widen your bid-ask or skew to one side.\n\nProfit improvement: 15-25% from reduced adverse selection. New profit per round-trip: $1.58 × 1.20 = $1.90.\n\nMonthly profit: 100K × 22 × $0.0190 = $41,800. Data cost: $100. Net: $41,700/month. Improvement: $6,940/month. ROI: 6940%.\n\nDecision: **UPGRADE TO L2** - $100 cost for $6,940 benefit is no-brainer.\n\n**Level 3 Analysis**:\n\nAvailable information: Individual orders with order IDs. Example:\n- Order #123: Buy 100 @ $150.00\n- Order #456: Buy 200 @ $150.00\n- Order #789: Buy 50 @ $150.00\nTotal: 350 shares at $150.00 (aggregates to L2)\n\nAdvanced capabilities:\n1. **Order flow detection**: Track individual traders. If \"Trader X\" places large buy orders before price moves up (pattern recognition), follow their orders.\n\n2. **Iceberg order detection**: If orders keep appearing at same price after fills (100, 100, 100...), that's an iceberg order - large hidden order. Indicates strong buyer.\n\n3. **Cancel-to-trade ratio**: High cancel rate suggests HFT spoofing or quote stuffing. Avoid.\n\n4. **Order book dynamics**: See exact order add/cancel/execute events. Build microsecond-level model of supply/demand.\n\nProfit improvement: 30-50% over L1, but requires sophisticated algorithms. New profit: $1.58 × 1.40 = $2.21.\n\nMonthly profit: 100K × 22 × $0.0221 = $48,620. Data cost: $25,000 (exchange membership). Net: $23,620/month.\n\nCompare to L2 net profit: $41,700. L3 is worse! Why? Exchange membership cost ($25K) is too high relative to volume.\n\nBreak-even volume: To justify L3, need monthly profit > $41,700 + $25,000 = $66,700. Required shares: $66,700 / $0.0221 / 22 = 137K shares/day. If trading > 137K shares/day, L3 is justified.\n\n**Recommendation Table**:\n\n| Volume/Day | Best Level | Reason |\n|------------|-----------|--------|\n| < 50K shares | L1 (free) | Low volume, free data sufficient |\n| 50K - 200K | L2 ($100/mo) | ROI > 5000%, clear winner |\n| > 200K | L3 ($25K/mo) | High volume justifies membership |\n\n**Final Answer**: For 100K shares/day target, use L2. Upgrade to L3 only if scaling to > 140K shares/day or multiple symbols (amortize membership cost across 10+ symbols).",
    keyPoints: [
      'L1 (free): Best bid/ask only, $34,760/month profit, no queue visibility, high adverse selection risk',
      'L2 ($100/mo): Full depth, $41,700/month profit (+$6,940 vs L1), 6940% ROI, reduces adverse selection 20%',
      'L3 ($25K/mo): Individual orders, $48,620 gross but $23,620 net (-$18K vs L2), only justified at > 140K shares/day',
      'L2 winner: At 100K shares/day, L2 provides 20% profit boost for trivial cost ($100 vs $6,940 benefit)',
      'L3 break-even: Need 137K+ shares/day or multiple symbols to justify $25K membership fee',
    ],
  },
  {
    id: 'level-data-q-3',
    question:
      'You notice your L2 order book has best bid = $150.00 (5000 shares) and best ask = $150.02 (3000 shares). Suddenly, best bid jumps to $150.02 (5000 shares) with no trades executed. Explain: (1) What happened? (2) Is this a data error or valid market event? (3) How to detect and handle programmatically? (4) What are the implications for a trading strategy? (5) Provide code to detect this scenario.',
    sampleAnswer:
      "Order book anomaly analysis:\n\n**What Happened - Locked Market**:\n\nBefore: Bid $150.00 (5000), Ask $150.02 (3000), Spread $0.02\nAfter: Bid $150.02 (5000), Ask $150.02 (3000), Spread $0.00\n\nThis is a \"locked market\" - bid equals ask. This occurs when:\n\n1. **Aggressive buy order placed** at $150.02 (matching ask price) but NOT executed as a market order. This is an ISO (Intermarket Sweep Order) or resting limit order at the ask price.\n\n2. **Different exchanges**: Bid on Exchange A ($150.02) and Ask on Exchange B ($150.02). In US markets, Regulation NMS prohibits crossed markets but allows locked markets temporarily.\n\n3. **Race condition**: Buyer placed limit order at $150.02 on NASDAQ, but ask at $150.02 is on ARCA. Order router hasn't executed yet (millisecond delay).\n\n4. **Stub quote**: Market maker obligation to maintain quotes, even if artificially.\n\n**Data Error vs Valid Event**:\n\nValid scenarios: (1) Multi-exchange lock (most common), (2) ISO order posted, (3) Brief race condition (< 50ms duration), (4) Halted stock resuming.\n\nData errors: (1) Missing update (ask decrease to $150.01 was lost), (2) Sequence gap (updates out of order), (3) Corrupt data feed.\n\nHow to distinguish: (1) Check if locked market persists > 100ms (likely valid), (2) Verify with multiple data feeds (if all agree, likely valid), (3) Check exchange codes (different exchanges = valid lock).\n\n**Programmatic Detection**:\n\n```python\nfrom datetime import datetime, timedelta\nfrom decimal import Decimal\nfrom typing import Optional\n\nclass OrderBookMonitor:\n    def __init__(self):\n        self.last_snapshot = None\n        self.anomaly_count = 0\n        self.locked_start = None\n        self.crossed_detected = False\n    \n    def check_anomalies(self, best_bid: Decimal, best_ask: Decimal, \n                       bid_exchange: str, ask_exchange: str) -> dict:\n        \"\"\"Detect locked/crossed markets\"\"\"\n        anomaly = {\n            'type': None,\n            'severity': 'normal',\n            'action': 'none',\n            'details': ''\n        }\n        \n        spread = best_ask - best_bid\n        \n        # 1. Crossed Market (bid > ask) - SEVERE ERROR\n        if best_bid > best_ask:\n            anomaly['type'] = 'crossed_market'\n            anomaly['severity'] = 'severe'\n            anomaly['action'] = 'stop_trading'\n            anomaly['details'] = f'Bid ${best_bid} > Ask ${best_ask} by ${best_bid - best_ask}'\n            self.crossed_detected = True\n            self.anomaly_count += 1\n            return anomaly\n        \n        # 2. Locked Market (bid = ask)\n        if spread == 0:\n            if self.locked_start is None:\n                self.locked_start = datetime.now()\n            \n            duration = (datetime.now() - self.locked_start).total_seconds()\n            \n            # Check if same exchange (shouldn't happen)\n            if bid_exchange == ask_exchange:\n                anomaly['type'] = 'locked_same_exchange'\n                anomaly['severity'] = 'high'\n                anomaly['action'] = 'pause_trading'\n                anomaly['details'] = f'Locked market on same exchange {bid_exchange}'\n            else:\n                # Different exchanges - valid but unusual\n                anomaly['type'] = 'locked_multi_exchange'\n                anomaly['severity'] = 'low' if duration < 0.1 else 'medium'\n                anomaly['action'] = 'monitor' if duration < 0.5 else 'investigate'\n                anomaly['details'] = f'Locked {duration:.2f}s: {bid_exchange} bid = {ask_exchange} ask'\n        else:\n            # Normal spread - reset locked timer\n            self.locked_start = None\n        \n        # 3. Wide Spread (> 0.5% of mid price)\n        mid_price = (best_bid + best_ask) / 2\n        spread_pct = float(spread / mid_price) * 100\n        \n        if spread_pct > 0.5:\n            anomaly['type'] = 'wide_spread'\n            anomaly['severity'] = 'medium'\n            anomaly['action'] = 'caution'\n            anomaly['details'] = f'Wide spread {spread_pct:.2f}% (${spread})'\n        \n        # 4. Price Jump Detection (compare to last snapshot)\n        if self.last_snapshot:\n            last_mid = (self.last_snapshot['bid'] + self.last_snapshot['ask']) / 2\n            current_mid = (best_bid + best_ask) / 2\n            price_change_pct = abs(float((current_mid - last_mid) / last_mid)) * 100\n            \n            if price_change_pct > 0.5:\n                # Large price move - verify if trades occurred\n                anomaly['type'] = 'price_jump_no_trade'\n                anomaly['severity'] = 'high'\n                anomaly['action'] = 'verify_data'\n                anomaly['details'] = f'Price moved {price_change_pct:.2f}% without trades'\n        \n        # Store current snapshot\n        self.last_snapshot = {\n            'bid': best_bid,\n            'ask': best_ask,\n            'timestamp': datetime.now()\n        }\n        \n        return anomaly\n    \n    def handle_anomaly(self, anomaly: dict):\n        \"\"\"Handle detected anomaly\"\"\"\n        if anomaly['severity'] == 'severe':\n            print(f\"[SEVERE] {anomaly['type']}: {anomaly['details']}\")\n            # Halt all trading\n            # self.trading_engine.emergency_stop()\n        elif anomaly['severity'] == 'high':\n            print(f\"[HIGH] {anomaly['type']}: {anomaly['details']}\")\n            # Pause new orders\n            # self.trading_engine.pause()\n        elif anomaly['severity'] == 'medium':\n            print(f\"[MEDIUM] {anomaly['type']}: {anomaly['details']}\")\n            # Log and monitor\n        \n        # Alert system\n        # self.alert_system.send_alert(anomaly)\n\n# Usage\nmonitor = OrderBookMonitor()\n\n# Normal market\nanomaly = monitor.check_anomalies(\n    best_bid=Decimal('150.00'),\n    best_ask=Decimal('150.02'),\n    bid_exchange='NASDAQ',\n    ask_exchange='ARCA'\n)\nprint(f\"Status: {anomaly['type'] or 'Normal'}\")\n\n# Locked market\nanomaly = monitor.check_anomalies(\n    best_bid=Decimal('150.02'),\n    best_ask=Decimal('150.02'),\n    bid_exchange='NASDAQ',\n    ask_exchange='ARCA'\n)\nprint(f\"Locked: {anomaly}\")\nmonitor.handle_anomaly(anomaly)\n```\n\n**Trading Strategy Implications**:\n\n1. **Market Making**: If locked market persists, pull quotes immediately. You can't profit from zero spread. Wait for spread to normalize (> 2 ticks) before re-entering.\n\n2. **Arbitrage**: Locked market across exchanges = potential arb opportunity. Buy on one exchange, sell on other. But be careful - locked markets often resolve in < 100ms (not enough time to execute).\n\n3. **Momentum Trading**: Locked market often precedes large price move. If bid locks with ask, it suggests strong buying pressure. Consider going long. But false signals are common.\n\n4. **Risk Management**: Treat locked market as increased uncertainty. Reduce position sizes by 50% or exit entirely until normal spread resumes.\n\n**Best Practices**: (1) Log all locked markets for analysis, (2) Set threshold: pause trading if locked > 1 second, (3) Correlate with news/events (earnings, halts), (4) Test on historical data to tune thresholds, (5) Never assume locked market = arbitrage without verification.",
    keyPoints: [
      'Locked market: Bid = Ask (spread $0), occurs across different exchanges (NASDAQ bid = ARCA ask), valid but unusual',
      'Causes: Aggressive limit orders, multi-exchange timing, ISO orders, race conditions (< 50ms duration typical)',
      'Detection: Check spread = 0, compare exchanges (same = error, different = valid), measure duration (> 1s = investigate)',
      'Strategy impact: Market makers pull quotes (no profit in 0 spread), momentum traders watch for breakout direction',
      'Handling: Pause trading if locked > 1s, reduce positions 50%, verify with secondary data feeds, log for analysis',
    ],
  },
];
