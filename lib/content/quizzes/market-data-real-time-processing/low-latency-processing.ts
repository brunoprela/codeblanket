export const lowLatencyProcessingQuiz = [
  {
    id: 'low-latency-processing-q-1',
    question:
      'Your Python order book update function takes 50μs (too slow for HFT). Optimize using Cython to achieve < 10μs. Provide: (1) Performance bottleneck analysis, (2) Cython implementation with type annotations, (3) Memory optimization, (4) Benchmarking results showing 5× speedup.',
    sampleAnswer:
      'Cython optimization for order book:\n\n**Bottleneck Analysis**:\nPure Python (50μs breakdown):\n- Dict lookup: 5μs\n- Price comparisons: 10μs\n- List operations: 15μs\n- Object creation: 20μs\nTotal: 50μs\n\n**Cython Implementation**:\n```cython\n# orderbook_fast.pyx\nimport numpy as np\ncimport numpy as cnp\nfrom libc.stdlib cimport malloc, free\n\ncdef struct PriceLevel:\n    double price\n    int size\n    int order_count\n\ncdef class FastOrderBook:\n    cdef PriceLevel* bids  # Pre-allocated C array\n    cdef PriceLevel* asks\n    cdef int bid_count\n    cdef int ask_count\n    cdef int max_levels\n    \n    def __init__(self, int max_levels=1000):\n        self.max_levels = max_levels\n        self.bids = <PriceLevel*>malloc(max_levels * sizeof(PriceLevel))\n        self.asks = <PriceLevel*>malloc(max_levels * sizeof(PriceLevel))\n        self.bid_count = 0\n        self.ask_count = 0\n    \n    cdef void update_bid_fast(self, double price, int size) nogil:\n        # Binary search (O(log n))\n        cdef int idx = self._binary_search_bid(price)\n        \n        if idx < self.bid_count and self.bids[idx].price == price:\n            # Update existing level\n            if size == 0:\n                # Delete\n                self._remove_bid(idx)\n            else:\n                self.bids[idx].size = size\n        else:\n            # Insert new level\n            self._insert_bid(idx, price, size)\n    \n    cdef int _binary_search_bid(self, double price) nogil:\n        cdef int left = 0\n        cdef int right = self.bid_count\n        cdef int mid\n        \n        while left < right:\n            mid = (left + right) // 2\n            if self.bids[mid].price > price:\n                left = mid + 1\n            else:\n                right = mid\n        return left\n    \n    def __dealloc__(self):\n        free(self.bids)\n        free(self.asks)\n```\n\n**Memory Optimization**:\n- Use C structs (24 bytes) vs Python objects (56 bytes) = 57% reduction\n- Pre-allocate arrays (no malloc in hot path)\n- Stack allocation for local variables\n- nogil for true parallelism\n\n**Benchmark Results**:\nPython: 50μs\nCython with types: 20μs (2.5× faster)\nCython + C structs: 12μs (4.2× faster)\nCython + nogil: 9μs (5.6× faster) ✓\n\n**Compilation**:\n```python\n# setup.py\nfrom setuptools import setup\nfrom Cython.Build import cythonize\nimport numpy\n\nsetup(\n    ext_modules=cythonize("orderbook_fast.pyx"),\n    include_dirs=[numpy.get_include()]\n)\n# Build: python setup.py build_ext --inplace\n```\n\nAchieved < 10μs target with 5.6× speedup!',
    keyPoints: [
      'Bottleneck: Object creation (20μs), list ops (15μs), comparisons (10μs) in pure Python (50μs total)',
      'Cython optimization: C structs (24 bytes vs 56), type annotations, nogil for parallelism',
      'Implementation: Pre-allocated C arrays, binary search (O(log n)), no malloc in hot path',
      'Results: Python 50μs → Cython 9μs (5.6× speedup), achieved < 10μs target',
      'Memory: 57% reduction using C structs vs Python objects, stack allocation for locals',
    ],
  },
  {
    id: 'low-latency-processing-q-2',
    question:
      'Compare latency of dict vs SortedDict vs NumPy array for order book storage (1000 price levels). Measure: (1) Insert time, (2) Best bid/ask lookup, (3) Memory footprint. Which data structure for HFT?',
    sampleAnswer:
      'Data structure comparison for order book:\n\n**Dict (unordered)**:\n- Insert: O(1) = 50ns\n- Best bid/ask: O(n) = 5,000ns (scan all 1000 levels)\n- Memory: 1000 levels × 200 bytes/entry = 200 KB\n- Pros: Fastest insert\n- Cons: Can\'t find best bid/ask efficiently\n\n**SortedDict (sortedcontainers)**:\n- Insert: O(log n) = 200ns\n- Best bid/ask: O(1) = 10ns (iterator to first element)\n- Memory: 1000 levels × 220 bytes = 220 KB\n- Pros: Fast lookup, maintains order\n- Cons: Slower insert than dict\n\n**NumPy Pre-allocated Array**:\n- Insert: O(n) = 2,000ns (shift elements for insertion)\n- Best bid/ask: O(1) = 5ns (index[0])\n- Memory: 1000 levels × 16 bytes = 16 KB (13× less!)\n- Pros: Minimal memory, fast lookup, cache-friendly\n- Cons: Slow insertion\n\n**Benchmark Code**:\n```python\nimport time\nimport numpy as np\nfrom sortedcontainers import SortedDict\n\n# Dict test\nd = {}\nstart = time.perf_counter_ns()\nfor i in range(1000):\n    d[150.0 + i*0.01] = 100\ndict_insert = (time.perf_counter_ns() - start) / 1000  # Per insert\n\n# Best bid (must scan all)\nstart = time.perf_counter_ns()\nbest = max(d.keys())\ndict_lookup = time.perf_counter_ns() - start\n\nprint(f"Dict: Insert {dict_insert}ns, Lookup {dict_lookup}ns")\n# Dict: Insert 50ns, Lookup 5000ns\n\n# SortedDict test\nsd = SortedDict()\nstart = time.perf_counter_ns()\nfor i in range(1000):\n    sd[150.0 + i*0.01] = 100\nsorted_insert = (time.perf_counter_ns() - start) / 1000\n\nstart = time.perf_counter_ns()\nbest = sd.iloc[-1]  # Last element (highest key)\nsorted_lookup = time.perf_counter_ns() - start\n\nprint(f"SortedDict: Insert {sorted_insert}ns, Lookup {sorted_lookup}ns")\n# SortedDict: Insert 200ns, Lookup 10ns\n```\n\n**Recommendation for HFT**:\n\n*If updates frequent (> 1000/sec)*: **SortedDict**\n- Balanced: 200ns insert, 10ns lookup\n- Best bid/ask in O(1)\n- Good for market making (constant updates)\n\n*If memory critical*: **NumPy Array**\n- 13× less memory (16 KB vs 220 KB)\n- 5ns lookup (fastest)\n- Use if updates rare (< 100/sec)\n\n*Never use dict for order book* - O(n) lookup is unacceptable\n\n**Winner**: **SortedDict** for HFT (balanced performance, O(1) best bid/ask)',
    keyPoints: [
      'Dict: 50ns insert (fast), 5000ns lookup (slow - O(n) scan), 200 KB memory',
      'SortedDict: 200ns insert, 10ns lookup (O(1) iterator), 220 KB memory - BEST for HFT',
      'NumPy: 2000ns insert (slow - shifts), 5ns lookup (fastest), 16 KB memory (13× less)',
      'Recommendation: SortedDict wins for HFT (balanced 200ns insert + 10ns O(1) best bid/ask)',
      'Dict unusable: O(n) lookup unacceptable for finding best bid/ask in order book',
    ],
  },
  {
    id: 'low-latency-processing-q-3',
    question:
      'Your trading system CPU usage spikes to 100% during market open (9:30-9:35 AM) causing 50ms latency (normally 5ms). Diagnose and fix: (1) Profile CPU usage, (2) Identify hot spots, (3) Optimize critical paths, (4) Validate fix reduces latency to < 10ms.',
    sampleAnswer:
      "CPU spike diagnosis and optimization:\n\n**Profiling**:\n```python\nimport cProfile\nimport pstats\n\n# Profile 5 minutes of trading\nprofiler = cProfile.Profile()\nprofiler.enable()\n\n# Run trading system\ntrade_for_5_minutes()\n\nprofiler.disable()\nstats = pstats.Stats(profiler)\nstats.sort_stats('cumulative')\nstats.print_stats(20)  # Top 20 functions\n```\n\n**Profile Results**:\n```\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n   50000   120.5s    2.4ms   120.5s    2.4ms   strategy.py:45(calculate_signals)\n   50000    45.2s    0.9ms    45.2s    0.9ms   orderbook.py:100(update_book)\n   50000    30.1s    0.6ms    30.1s    0.6ms   indicators.py:20(calculate_rsi)\n```\n\n**Hot Spots Identified**:\n1. `calculate_signals()`: 2.4ms per call (too slow!)\n2. `update_book()`: 0.9ms (acceptable but can improve)\n3. `calculate_rsi()`: 0.6ms (recalculating every tick)\n\n**Optimization 1: Cache RSI**\n```python\n# Before: Calculate RSI every tick (0.6ms × 50K = 30s CPU)\nfor tick in ticks:\n    rsi = calculate_rsi(prices)  # Expensive\n    if rsi > 70:\n        sell()\n\n# After: Incremental RSI (0.01ms × 50K = 0.5s CPU)\nclass IncrementalRSI:\n    def __init__(self):\n        self.avg_gain = 0\n        self.avg_loss = 0\n    \n    def update(self, price_change):\n        # O(1) update, not O(n) recalculation\n        if price_change > 0:\n            self.avg_gain = (self.avg_gain * 13 + price_change) / 14\n        else:\n            self.avg_loss = (self.avg_loss * 13 - price_change) / 14\n        \n        rs = self.avg_gain / self.avg_loss if self.avg_loss > 0 else 0\n        return 100 - (100 / (1 + rs))\n\n# Savings: 30s → 0.5s (60× faster)\n```\n\n**Optimization 2: Vectorize calculate_signals**\n```python\n# Before: Python loops (2.4ms)\ndef calculate_signals(prices):\n    signals = []\n    for i in range(len(prices)):\n        if prices[i] > ma[i]:\n            signals.append(1)\n        else:\n            signals.append(0)\n    return signals\n\n# After: NumPy vectorized (0.05ms)\ndef calculate_signals_fast(prices, ma):\n    return (prices > ma).astype(int)\n\n# Savings: 2.4ms → 0.05ms (48× faster)\n```\n\n**Optimization 3: Order book with SortedDict**\n```python\n# Replace list-based order book (O(n) operations)\n# With SortedDict (O(log n) operations)\n# Savings: 0.9ms → 0.2ms (4.5× faster)\n```\n\n**Validation**:\n```python\n# Before optimization:\nAvg latency: 50ms\nCPU usage: 100%\n\n# After optimization:\nAvg latency: 4ms (12.5× improvement) ✓\nCPU usage: 35%\n\n# Target achieved: < 10ms ✓\n```\n\n**Root Cause**: Recalculating expensive indicators (RSI, MA) every tick instead of incremental updates. Python loops instead of vectorized NumPy operations.",
    keyPoints: [
      'Profiling identified: calculate_signals (2.4ms), RSI calculation (0.6ms), order book (0.9ms)',
      'Optimization 1: Incremental RSI (O(1) update vs O(n) recalc) = 60× faster (30s → 0.5s)',
      'Optimization 2: NumPy vectorization for signals = 48× faster (2.4ms → 0.05ms)',
      'Optimization 3: SortedDict order book = 4.5× faster (0.9ms → 0.2ms)',
      'Result: 50ms → 4ms latency (12.5× improvement), CPU 100% → 35%, < 10ms target achieved',
    ],
  },
];
