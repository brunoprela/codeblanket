export const marketResearchAutomationQuiz = {
  title: 'Market Research Automation Discussion',
  id: 'market-research-automation-quiz',
  sectionId: 'market-research-automation',
  questions: [
    {
      id: 1,
      question:
        'How can LLMs help identify emerging competitive threats from non-traditional sources (e.g., tech companies entering finance, or DTC brands disrupting retail)? What data sources and analytical approaches are most effective for spotting disruption before it becomes obvious?',
      expectedAnswer: `Should discuss: traditional competitive analysis focuses on known competitors in same industry, missing threats from adjacent or unrelated sectors until too late. LLM advantages: analyze broader information sources beyond industry reports (tech blogs, startup funding announcements, patent filings, job postings, social media trends), identify pattern of "company from sector X developing capabilities in sector Y," connect dots between seemingly unrelated developments, and detect language signals of strategic intention before explicit announcements. Data sources: job postings revealing skill building (e.g., bank hiring game designers signals metaverse strategy), patent applications showing technology development direction, VC funding patterns into potential disruptors, developer community activity suggesting platform emergence, and regulatory filings hinting at new business model exploration. Analytical approaches: entity relationship tracking (who is hiring whom from where), capability gap analysis (what capabilities is company acquiring that don\'t fit current business), strategic narrative analysis (changes in how company describes itself), and peer group expansion (company starting to cite or compare to different competitors). Challenges: high noise-to-signal ratio generates many false positives, long time horizons make validation difficult, and distinguishing real threats from failed experiments. Most effective: combine quantitative signals (funding, hiring, patents) with qualitative LLM analysis of strategic intent, focus on capabilities + market access + intent triangle, and track confidence evolution over time rather than binary threat/not-threat.`,
    },
    {
      id: 2,
      question:
        'What are the limitations of LLM-generated industry forecasts compared to expert analyst forecasts? In what situations might LLMs actually produce superior forecasts, and when should human expertise take priority?',
      expectedAnswer: `Should cover: LLMs synthesize historical patterns and consensus views but lack forward-looking proprietary insight, deep domain expertise, and personal relationships that inform expert forecasts. Limitations: cannot predict paradigm shifts that break historical patterns, miss subtle industry-specific nuances not well-represented in training data, struggle with highly technical domains requiring specialized knowledge, and overweight consensus views while underweighting contrarian but informed perspectives. LLM advantages: better at synthesizing vast information without cognitive biases, no anchoring to previous forecasts, can identify base rate patterns human experts ignore due to compelling narratives, better at probabilistic thinking than point estimates, and faster updating when new information emerges. LLMs superior when: processing large standardized data sets, identifying patterns across multiple industries simultaneously, aggregating diverse viewpoints systematically, removing emotional biases from forecast, and producing rapid initial assessments. Human expertise prioritized when: deep domain knowledge essential, primary research and company access critical, paradigm shifts or unprecedented situations, judgment calls on ambiguous information required, and accountability and trust important (humans more trustworthy as final decision makers). Optimal: LLMs generate baseline forecast and alternative scenarios, humans provide adjustment based on proprietary knowledge, qualitative judgment, and relationship-based insights. Hybrid: LLM handles breadth, human handles depth; LLM processes data, human provides wisdom.`,
    },
    {
      id: 3,
      question:
        'How should due diligence systems use LLMs to identify potential red flags in target companies while avoiding the bias of looking for problems and finding them everywhere? Discuss the balance between healthy skepticism and confirmation bias.',
      expectedAnswer: `Should analyze: due diligence requires skeptical mindset to uncover hidden problems, but pure skepticism finds problems everywhere (no deal would ever pass). LLMs can amplify confirmation bias by finding language supporting whatever thesis they are prompted for. Challenges: instructing LLM to "find red flags" creates incentive to interpret ambiguous information negatively, negative findings are more memorable and influential than positive findings (asymmetric weighting), and accumulating lists of concerns without context makes every company look risky. Balancing approaches: structure due diligence as hypothesis testing not flag huntingâ€”generate specific testable concerns rather than open-ended problem search, require affirmative evidence of problems not just absence of positive signals, compare target to peer baseline (do these "red flags" appear in comparable successful companies?), weight findings by materiality and probability not just presence/absence, use LLM for both positive and negative due diligence (identify strengths and differentiation not just weaknesses), implement devil\'s advocate + advocate structure where different LLM prompts argue both sides, and calibrate flag severity against historical deals. Red flag framework: critical (deal breakers), significant (material concerns requiring mitigation), and monitoring (worth tracking but not deal-impacting). Track false positives: if raising flags that don\'t predict poor outcomes, system needs recalibration. Healthy skepticism: verify claims, seek disconfirming evidence, and understand risks. Confirmation bias: interpreting neutral information negatively, ignoring countervailing evidence, and finding problems because you looked for them. Mitigation: structure process, explicit positive case requirement, peer comparison, and human judgment on flag significance.`,
    },
  ],
};
