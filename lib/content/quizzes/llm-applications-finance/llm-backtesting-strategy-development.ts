export const llmBacktestingStrategyDevelopmentQuiz = {
  title: 'LLM-Powered Backtesting & Strategy Development Discussion',
  id: 'llm-backtesting-strategy-development-quiz',
  sectionId: 'llm-backtesting-strategy-development',
  questions: [
    {
      id: 1,
      question:
        'How can LLM-generated strategy code introduce subtle bugs or logical errors that pass initial testing but fail in production? Discuss the types of errors most likely to occur and validation approaches beyond simple backtesting.',
      expectedAnswer: `Should discuss: LLMs can generate syntactically correct code with logical errors that produce plausible but wrong results. Common errors: off-by-one errors in lookback periods (using yesterday\'s close instead of today\'s), lookahead bias where future information leaks into past decisions, incorrect order of operations in signal calculations, edge cases not handled (first day of data, missing data, divide by zero), portfolio accounting errors (not tracking cash correctly, double-counting positions), and indicator calculations slightly wrong but close enough to seem correct. Dangerous: bugs that consistently bias results positive during backtest (survivor bias baked into code, overstating returns by using close-to-close when actual fills worse, ignoring transaction costs or slippage). Validation approaches beyond backtest: unit tests for each component function with known correct outputs, comparison against reference implementations of standard indicators, paper trading period before production capital, code review by experienced quant developers, stress testing with edge case data (gaps, halts, extreme volatility), walk-forward analysis to detect if results degrade out-of-sample, statistical analysis of trade distribution (should make sense given strategy logic), and monitoring in production for divergence from backtest behavior. Specific checks: verify no lookahead bias by ensuring only past data accessed, confirm portfolio accounting matches expected (trades sum to positions), validate indicator calculations match published formulas, and test strategy with multiple random seeds to ensure stability. LLM-specific risk: code may work for specific data used in development but fail with different tickers or date ranges—need robust testing across different market conditions and securities.`,
    },
    {
      id: 2,
      question:
        'What are the risks of using LLMs to iterate and optimize trading strategies based on backtest results? How can this process lead to overfitting, and what safeguards prevent the creation of strategies that work on historical data but fail in live trading?',
      expectedAnswer: `Should cover: LLM iteration on strategies based on backtest results is optimization loop prone to severe overfitting—finding parameters that fit noise not signal. Process: initial strategy underperforms, LLM suggests modifications, new version tested, if better the improvement might be curve-fitting. Risks: LLM may add complexity (more parameters/rules) that improves backtest but reduces generalization, create rules specific to historical events that won\'t recur, optimize for metrics that don\'t reflect true trading (high Sharpe in backtest but relies on fills that wouldn\'t occur in reality), and generate many variants where lucky ones selected. Overfitting signatures: strategy performs dramatically better on training data than test data, many parameters with precise optimal values, rules highly specific to historical events, performance sensitive to small parameter changes, and strategy stops working as soon as deployed. Safeguards: reserved holdout data never seen by LLM during development, walk-forward analysis with multiple periods, parameter stability testing (do small changes destroy performance?), simplicity preference (fewer parameters better), out-of-sample testing on different time periods and securities, paper trading before real capital, and economic logic requirement (why should this strategy work?). Process discipline: set maximum optimization iterations, require improvement on holdout data not just training data, penalize complexity in strategy evaluation, maintain strategy development log tracking all iterations (prevents selecting best by luck), and implement "degradation monitoring" where declining performance in paper trading stops development. Best practice: LLM suggests strategy concepts, human ensures economic logic, limited automated testing, and explicit guardrails against overfitting. Accept: many strategies won\'t work, resistance to over-optimization more important than maximizing backtest returns.`,
    },
    {
      id: 3,
      question:
        'How should traders interpret and act on LLM explanations of strategy performance, especially when the explanation sounds plausible but may be post-hoc rationalization? Discuss the difference between actual strategy logic and explained strategy logic.',
      expectedAnswer: `Should analyze: LLMs excel at generating convincing narratives explaining any data pattern, but explanation believability doesn\'t mean it\'s correct cause. Challenge: strategy makes money in backtest, LLM explains why in compelling terms, but explanation may be rationalization of random success not true mechanism. Examples: strategy happens to overweight tech during tech boom, LLM explains sophisticated logic about innovation cycles (really just luck of timing), momentum strategy works during trending period, LLM attributes to behavioral factors (really just market regime), or statistical arbitrage profits during specific market conditions, LLM creates elegant theory (really non-repeatable coincidence). Dangers: acting on false explanation causes wrong adjustments (optimizing for wrong reasons), deploying in situations where explanation suggests it should work but actual mechanism different, and overconfidence from having "understanding" that\'s actually wrong. Difference between actual and explained logic: actual logic is what code does (buy when RSI < 30), explained logic is why LLM says it works (exploiting oversold bounce behavioral bias). Explanation may be wrong even if strategy works, or right for wrong reasons. Validation approaches: test specific claims in explanation (if explanation says strategy exploits week-of-month effect, verify this pattern exists independently), check if explanation predicts when strategy should struggle (and verify), compare to null hypothesis (would random strategy of similar structure work?), and recognize that LLM generates most plausible explanation not necessarily correct one. Proper use: treat LLM explanations as hypotheses to test not facts, require empirical validation of causal claims, maintain skepticism especially for spectacular results, and remember that "I don\'t know why it works" is often more honest than convincing but wrong story. Focus on robust empirical testing and out-of-sample validation over narrative coherence.`,
    },
  ],
};
