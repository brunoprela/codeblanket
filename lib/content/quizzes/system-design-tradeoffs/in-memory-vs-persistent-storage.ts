/**
 * Quiz questions for In-Memory vs Persistent Storage section
 */

export const inmemoryvspersistentstorageQuiz = [
  {
    id: 'q1',
    question:
      'You are designing a high-traffic e-commerce site. Product details are queried millions of times per day, but only updated once per hour. How would you design the storage layer?',
    sampleAnswer:
      'E-commerce product storage - Hybrid approach: PRIMARY STORAGE (PostgreSQL): Store all product data: products table: id, name, description, price, inventory, images. Source of truth: All updates written here first. Durability: Must not lose product data. ACID transactions: Ensure inventory updates are consistent. CACHING LAYER (Redis): Cache product details in Redis (key-value). Key: product:123. Value: JSON with product details. TTL: 5 minutes (products updated hourly, but allow fresher data). ARCHITECTURE: Read path: 1. Application checks Redis: GET product:123. 2. If cache HIT → Return immediately (1ms). 3. If cache MISS → Query PostgreSQL (50ms). 4. Store in Redis: SET product:123 <data> EX 300 (5 min TTL). 5. Return to user. 6. Next request: Cache hit (1ms). Write path: 1. Update PostgreSQL: UPDATE products SET price = 99.99 WHERE id = 123. 2. Invalidate cache: DEL product:123 (or update cache immediately). 3. Next read: Cache miss → Fetch from DB → Cache fresh data. PERFORMANCE CALCULATION: Without cache: 10M requests/day → All hit database. Database load: 10M × 50ms = 500,000 seconds = 139 hours of DB time! Requires 139 database connections (impossible!). With cache (90% hit rate): Cache hits: 9M requests × 1ms = 9,000 seconds = 2.5 hours. Database hits: 1M requests × 50ms = 50,000 seconds = 14 hours. Total: 16.5 hours (vs 139 hours). Result: 8.4x reduction in load! Can handle with 14 database connections. CACHE SIZING: 10,000 products × 10KB each = 100MB (tiny!). Redis can easily handle this in memory. CACHE HIT RATE OPTIMIZATION: Popular products (top 20%): Always in cache (accessed frequently). Long-tail products (80%): Cache miss occasionally (acceptable). Target hit rate: 90%+. CACHE INVALIDATION: Price update: Delete from cache immediately (DEL product:123). Inventory update: Delete from cache (next read fetches fresh data). Bulk updates: Delete all (FLUSHDB) and let cache rebuild naturally. BENEFITS: 90% of requests: 1ms latency (excellent UX). Database load: Reduced by 10x (saves money). Cost: Redis (256GB): $100/month. Saves database instances: -$500/month. Net savings: $400/month. ALTERNATIVE (without cache): Scale database horizontally (read replicas). 10 read replicas × $200/month = $2,000/month. Still slower (50ms) vs 1ms with cache. Result: Cache is clear winner (faster AND cheaper).',
    keyPoints: [
      'Persistent storage (PostgreSQL) as source of truth',
      'In-memory cache (Redis) for hot data (90% hit rate)',
      'Cache-aside pattern: Check cache, fall back to database',
      'TTL of 5 minutes (balance freshness vs cache efficiency)',
      'Result: 10x database load reduction, 50x faster reads',
    ],
  },
  {
    id: 'q2',
    question:
      'Should you cache account balances in a banking application? Why or why not?',
    sampleAnswer:
      'Banking account balances - Should NOT cache (or extreme caution): ANSWER: Generally NO, do NOT cache account balances. REASONING: (1) Strong Consistency Required: Account balance must be 100% accurate at all times. User withdraws $100 → Balance must immediately reflect. Cached balance = stale balance = wrong balance. Example problem: Balance in database: $50. Balance in cache: $100 (stale). User tries to withdraw $75 → Allowed (cache shows $100) → Overdraft! Critical error. (2) Regulatory/Legal Requirements: Financial data must be accurate and auditable. Stale cached data = compliance violation. Could lose banking license. (3) Race Conditions: Two simultaneous withdrawals. Without cache: Both check database (with locks) → One succeeds, one fails. With cache: Both check cache ($100) → Both think sufficient → Both withdraw → Account overdrawn! ACID transactions essential (not possible with cache). (4) Cache Invalidation Complexity: Transfer $100 from Account A to Account B. Must invalidate both caches atomically. If cache A updated but cache B fails → Inconsistency. Too risky for financial data. EXCEPTIONS (When caching might be acceptable): (1) Display Balance (with disclaimers): Show approximate balance for UI display only. TTL: 1 second (very short). Disclaimer: "Balance updated every second". Any transaction: Re-fetch from database (NOT cache). (2) Read-Only Views: Historical balance (past months). This data doesn\'t change → Safe to cache.Example: "Account balance on Jan 1: $1,234.56". (3) Non- Critical Balances: Loyalty points, reward balance.Not financial, less critical.Cache with 1 - minute TTL acceptable.RECOMMENDED APPROACH(Without cache): Use persistent storage ONLY(PostgreSQL): SELECT balance FROM accounts WHERE id = 123 FOR UPDATE; (lock).Check if sufficient funds.If yes: UPDATE accounts SET balance = balance - 100 WHERE id = 123; COMMIT.Latency: 10 - 50ms (acceptable for banking).Correctness > Speed.OPTIMIZATION(If speed needed): Database read replicas: Reduce load on primary.Connection pooling: Reuse connections (reduce connection overhead).Indexed queries: Ensure queries use indexes (fast lookups).Result: 5 - 10ms latency (acceptable, correct).SCALE: Large banks handle millions of transactions / day with databases only.Example: Bank of America: PostgreSQL / Oracle with replication.No account balance caching.Performance: 10 - 20ms per transaction (acceptable).CACHE ALTERNATIVE(Event Sourcing): Store all transactions (append - only log).Balance = SUM(transactions).Cache computed balance with version number.On read: Check if cache version matches latest transaction.If yes: Use cache.If no: Recompute from transactions.This provides caching with strong consistency guarantees.CONCLUSION: Account balances should NOT be cached in traditional cache - aside pattern.Use persistent storage with ACID transactions.If caching absolutely necessary: Use very short TTL(1 second), read - only, with strong consistency checks.',
    keyPoints: [
      'Account balances should NOT be cached (strong consistency required)',
      'Cached balance = stale balance = overdraft risk',
      'Race conditions: Two withdrawals checking same cached balance',
      'Regulatory/legal requirements: Financial data must be accurate',
      'Use persistent storage ONLY with ACID transactions',
    ],
  },
  {
    id: 'q3',
    question:
      'Explain the trade-offs between Redis RDB (snapshotting) and AOF (append-only file) persistence.',
    sampleAnswer:
      'Redis persistence: RDB vs AOF trade-offs. REDIS IN-MEMORY (Volatile): By default, Redis stores data in RAM only. On restart: All data lost. Problem for production systems. SOLUTION: Enable persistence (write to disk). RDB (SNAPSHOTTING): How it works: Periodically save snapshot of entire dataset to disk. Example config: save 900 1 (save if 1 key changed in 15 min). save 300 10 (save if 10 keys changed in 5 min). save 60 10000 (save if 10,000 keys changed in 1 min). On restart: Load snapshot from disk (fast). ADVANTAGES: ✅ Fast: Single compact file, efficient. ✅ Small file size: Compressed snapshot. ✅ Fast restart: Load entire dataset quickly. ✅ Minimal performance impact: Background process. ✅ Good for backups: Single file to copy. DISADVANTAGES: ❌ Data loss: Lose data between snapshots. Example: Snapshot every 5 minutes → Crash at 4:30 → Lose 4.5 minutes of data. ❌ Blocking: Large datasets (GB) can block server during snapshot. ❌ Predictable loss: Always lose last N minutes of data. USE CASES FOR RDB: Cache: Data loss acceptable (can rebuild from database). Session storage: Losing 5 minutes of sessions acceptable. Non-critical data: Leaderboards, analytics (approximate is fine). AOF (APPEND-ONLY FILE): How it works: Log EVERY write operation to file. Example config: appendonly yes. appendfsync everysec (sync to disk every second). On restart: Replay all operations from log. ADVANTAGES: ✅ Minimal data loss: Lose at most 1 second of data (with everysec). ✅ No blocking: Append-only operations, non-blocking. ✅ Durable: More reliable than RDB. ✅ Human-readable: Can inspect/edit log file. DISADVANTAGES: ❌ Larger files: Every operation logged (not compressed). ❌ Slower restart: Must replay all operations (can take minutes). ❌ Slower performance: Disk I/O on every write (if fsync always). ❌ File growth: AOF file grows continuously (need rewrite). USE CASES FOR AOF: Persistent queues: Cannot lose messages. Important caches: Data expensive to recompute. Session storage: Cannot lose user sessions. AOF REWRITE: Problem: AOF file grows forever. Solution: Background rewrite (compact log). Example: 1000 operations → Single snapshot + recent operations. Automatic: Redis triggers rewrite at 100% size increase. HYBRID (RDB + AOF) - RECOMMENDED: Enable both: save 900 1 (RDB every 15 min). appendonly yes (AOF every second). On restart: Redis uses AOF (more up-to-date). Fallback: If AOF corrupted, use RDB. ADVANTAGES: ✅ Fast backups: RDB snapshots for copying. ✅ Minimal data loss: AOF for durability (1 second loss max). ✅ Best of both worlds: RDB speed + AOF durability. CONFIGURATION RECOMMENDATION: For cache (data loss acceptable): RDB only, snapshot every 15 minutes. save 900 1. For sessions (important, but can tolerate 1 second loss): AOF with everysec. appendonly yes, appendfsync everysec. For critical data (cannot lose): AOF with always (slow!). appendonly yes, appendfsync always (fsync on every write). For production (general): Hybrid (RDB + AOF). save 900 1, appendonly yes, appendfsync everysec. PERFORMANCE COMPARISON: No persistence: 100,000 ops/sec. RDB: 95,000 ops/sec (5% overhead, background). AOF everysec: 80,000 ops/sec (20% overhead, disk I/O). AOF always: 10,000 ops/sec (90% overhead, fsync every write). TRADE-OFF SUMMARY: RDB: Fast, small files, data loss (minutes) → Good for cache. AOF: Durable, larger files, minimal data loss (seconds) → Good for critical data. Hybrid: Best of both → Recommended for production.',
    keyPoints: [
      'RDB: Periodic snapshots, fast, but data loss between snapshots (minutes)',
      'AOF: Log every write, minimal data loss (1 second), but slower restarts',
      'Hybrid (RDB + AOF): Best of both, recommended for production',
      'For cache: RDB sufficient (data loss acceptable)',
      'For critical data: AOF with everysec (balance performance and durability)',
    ],
  },
];
