export const dependencyInjectionSystemQuiz = [
  {
    id: 'fastapi-di-q-1',
    question:
      'Design a production authentication system using FastAPI dependency injection with JWT tokens, refresh tokens, role-based access control, and rate limiting. Address: (1) dependency hierarchy (token extraction → verification → user fetching → role checking), (2) implementing token refresh logic as a dependency, (3) role-based dependencies (require_admin, require_premium), (4) combining with rate limiting per user, (5) testing strategy with dependency overrides. Provide complete code with nested dependencies.',
    sampleAnswer:
      'Production auth system with DI: (1) Dependency hierarchy: # Level 1: Token extraction; from fastapi import Depends, HTTPException, Header; from jose import JWTError, jwt; from datetime import datetime, timedelta. def get_token_from_header(authorization: str = Header(...)) → str: try: scheme, token = authorization.split(); if scheme.lower() != "bearer": raise HTTPException(401, "Invalid auth scheme"); return token; except ValueError: raise HTTPException(401, "Invalid auth header"). # Level 2: Verify access token; def verify_access_token(token: str = Depends(get_token_from_header)) → dict: try: payload = jwt.decode(token, SECRET_KEY, algorithms=["HS256"]); exp = payload.get("exp"); if not exp or datetime.utcnow().timestamp() > exp: raise HTTPException(401, "Token expired"); user_id = payload.get("sub"); token_type = payload.get("type"); if token_type != "access": raise HTTPException(401, "Invalid token type"); return {"user_id": user_id, "exp": exp}; except JWTError: raise HTTPException(401, "Invalid token"). # Level 3: Database session; def get_db(): db = SessionLocal(); try: yield db; finally: db.close(). # Level 4: Fetch current user; async def get_current_user(token_data: dict = Depends(verify_access_token), db: Session = Depends(get_db)) → User: user = db.query(User).filter(User.id == token_data["user_id"]).first(); if not user: raise HTTPException(404, "User not found"); if not user.is_active: raise HTTPException(403, "User inactive"); return user. # Level 5: Check active user; async def get_current_active_user(current_user: User = Depends(get_current_user)) → User: if not current_user.is_active: raise HTTPException(403, "User inactive"); return current_user. # Level 6: Role-based; async def require_admin(current_user: User = Depends(get_current_active_user)) → User: if "admin" not in current_user.roles: raise HTTPException(403, "Admin required"); return current_user. async def require_premium(current_user: User = Depends(get_current_active_user)) → User: if not current_user.is_premium: raise HTTPException(403, "Premium subscription required"); return current_user. (2) Token refresh dependency: def get_refresh_token(refresh_token: str = Header(...)) → str: return refresh_token. def verify_refresh_token(token: str = Depends(get_refresh_token)) → dict: try: payload = jwt.decode(token, SECRET_KEY, algorithms=["HS256"]); if payload.get("type") != "refresh": raise HTTPException(401, "Invalid token type"); return {"user_id": payload["sub"]}; except JWTError: raise HTTPException(401, "Invalid refresh token"). @app.post("/auth/refresh") async def refresh_access_token(token_data: dict = Depends(verify_refresh_token), db: Session = Depends(get_db)): user = db.query(User).filter(User.id == token_data["user_id"]).first(); if not user or not user.is_active: raise HTTPException(401, "Invalid user"); # Generate new access token; access_token = create_access_token(user.id, expires_delta=timedelta(minutes=15)); return {"access_token": access_token, "token_type": "bearer"}. (3) Role-based dependencies: class RoleChecker: def __init__(self, allowed_roles: List[str]): self.allowed_roles = allowed_roles; def __call__(self, current_user: User = Depends(get_current_active_user)) → User: if not any(role in current_user.roles for role in self.allowed_roles): raise HTTPException(403, f"Roles required: {self.allowed_roles}"); return current_user. # Create role checkers; require_admin = RoleChecker(["admin"]); require_moderator = RoleChecker(["admin", "moderator"]); require_premium = RoleChecker(["premium", "admin"]). # Use in endpoints; @app.delete("/users/{user_id}") async def delete_user(user_id: int, admin: User = Depends(require_admin), db: Session = Depends(get_db)): pass. @app.post("/posts/{post_id}/moderate") async def moderate_post(post_id: int, moderator: User = Depends(require_moderator)): pass. (4) Rate limiting per user: from fastapi_limiter.depends import RateLimiter. class UserRateLimiter: def __init__(self, times: int, seconds: int): self.times = times; self.seconds = seconds; async def __call__(self, current_user: User = Depends(get_current_active_user), cache: Redis = Depends(get_redis)): key = f"rate_limit:{current_user.id}"; count = await cache.incr(key); if count == 1: await cache.expire(key, self.seconds); if count > self.times: retry_after = await cache.ttl(key); raise HTTPException(429, f"Rate limit exceeded. Retry after {retry_after}s"); return current_user. # Apply to endpoints; rate_limit = UserRateLimiter(times=100, seconds=60); @app.get("/api/data") async def get_data(user: User = Depends(rate_limit)): # Max 100 requests per minute per user; pass. (5) Testing strategy: # Mock dependencies; def mock_get_current_user(): return User(id=1, username="testuser", roles=["user"], is_active=True, is_premium=False). def mock_get_current_admin(): return User(id=2, username="admin", roles=["admin"], is_active=True, is_premium=True). def mock_get_db(): return MockDB(). # Test setup; import pytest; from fastapi.testclient import TestClient. @pytest.fixture def client(): app.dependency_overrides[get_current_user] = mock_get_current_user; app.dependency_overrides[get_db] = mock_get_db; with TestClient(app) as c: yield c; app.dependency_overrides.clear(). # Tests; def test_user_endpoint(client): response = client.get("/users/me"); assert response.status_code == 200; assert response.json()["username"] == "testuser". def test_admin_endpoint_forbidden(client): # Regular user cannot access admin endpoint; response = client.delete("/users/99"); assert response.status_code == 403; assert "Admin required" in response.json()["detail"]. def test_admin_endpoint_allowed(client): # Override with admin; app.dependency_overrides[get_current_user] = mock_get_current_admin; response = client.delete("/users/99"); assert response.status_code == 200. def test_premium_endpoint(client): response = client.get("/premium/feature"); assert response.status_code == 403; # Not premium. # Override with premium user; app.dependency_overrides[get_current_user] = lambda: User(id=1, is_premium=True, roles=["user"], is_active=True); response = client.get("/premium/feature"); assert response.status_code == 200. Production benefits: Clear dependency chain (token → user → role → rate limit), reusable dependencies (same auth for all endpoints), testable (override any level), type-safe (mypy validates entire chain), performant (user fetched once per request, cached), secure (centralized auth logic, no duplication), composable (combine auth + rate limiting + permissions), maintainable (change auth logic in one place).',
    keyPoints: [
      'Hierarchy: token extraction → verification → DB fetch → user validation → role checking (6 levels deep)',
      'Refresh tokens: Separate dependency for refresh token verification, generates new access token',
      'Role-based: RoleChecker callable class, reusable (require_admin, require_moderator, require_premium)',
      'Rate limiting: UserRateLimiter class, Redis-based, per-user limits, clear error messages with retry-after',
      'Testing: dependency_overrides for mocking auth, test each permission level, pytest fixtures for clean setup/teardown',
    ],
  },
  {
    id: 'fastapi-di-q-2',
    question:
      'Implement a repository pattern with dependency injection for a multi-tenant SaaS application. Address: (1) tenant isolation via dependencies, (2) repository classes injected with DB session and tenant context, (3) service layer pattern combining multiple repositories, (4) transaction management across repositories, (5) caching strategies with injected Redis client. Include complete code showing dependency composition.',
    sampleAnswer:
      'Multi-tenant repository pattern with DI: (1) Tenant isolation dependency: from fastapi import Depends, HTTPException, Request. async def get_tenant_from_subdomain(request: Request) → Tenant: subdomain = request.url.hostname.split(".")[0]; if subdomain in ["www", "api"]: raise HTTPException(400, "Invalid subdomain"); tenant = await Tenant.get_by_subdomain(subdomain); if not tenant or not tenant.is_active: raise HTTPException(403, "Invalid or inactive tenant"); return tenant. async def get_tenant_from_header(x_tenant_id: str = Header(...)) → Tenant: tenant = await Tenant.get_by_id(x_tenant_id); if not tenant: raise HTTPException(403, "Invalid tenant"); return tenant. # Use one based on deployment; get_tenant = get_tenant_from_subdomain # or get_tenant_from_header. (2) Repository classes with DI: from typing import List, Optional. class BaseRepository: def __init__(self, db: Session = Depends(get_db), tenant: Tenant = Depends(get_tenant)): self.db = db; self.tenant = tenant; def _apply_tenant_filter(self, query): return query.filter_by(tenant_id=self.tenant.id). class UserRepository(BaseRepository): def get(self, user_id: int) → Optional[User]: query = self.db.query(User).filter_by(id=user_id); query = self._apply_tenant_filter(query); return query.first(); def list(self, skip: int = 0, limit: int = 100) → List[User]: query = self.db.query(User); query = self._apply_tenant_filter(query); return query.offset(skip).limit(limit).all(); def create(self, user: UserCreate) → User: db_user = User(**user.dict(), tenant_id=self.tenant.id); self.db.add(db_user); self.db.flush(); # Don\'t commit yet; return db_user; def update(self, user_id: int, user: UserUpdate) → User: db_user = self.get(user_id); if not db_user: raise HTTPException(404, "User not found"); for key, value in user.dict(exclude_unset=True).items(): setattr(db_user, key, value); self.db.flush(); return db_user. class ProductRepository(BaseRepository): def get(self, product_id: int) → Optional[Product]: query = self.db.query(Product).filter_by(id=product_id); query = self._apply_tenant_filter(query); return query.first(); def list(self, category: Optional[str] = None) → List[Product]: query = self.db.query(Product); query = self._apply_tenant_filter(query); if category: query = query.filter_by(category=category); return query.all(); def decrease_stock(self, product_id: int, quantity: int): product = self.get(product_id); if not product: raise HTTPException(404, "Product not found"); if product.stock < quantity: raise HTTPException(400, "Insufficient stock"); product.stock -= quantity; self.db.flush(). class OrderRepository(BaseRepository): def create(self, order: OrderCreate) → Order: db_order = Order(**order.dict(), tenant_id=self.tenant.id); self.db.add(db_order); self.db.flush(); return db_order; def get_by_user(self, user_id: int) → List[Order]: query = self.db.query(Order).filter_by(user_id=user_id); query = self._apply_tenant_filter(query); return query.all(). (3) Service layer combining repositories: class OrderService: def __init__(self, user_repo: UserRepository = Depends(), product_repo: ProductRepository = Depends(), order_repo: OrderRepository = Depends(), db: Session = Depends(get_db)): self.user_repo = user_repo; self.product_repo = product_repo; self.order_repo = order_repo; self.db = db; async def create_order(self, user_id: int, order_data: OrderCreate) → Order: # Validate user exists; user = self.user_repo.get(user_id); if not user: raise HTTPException(404, "User not found"); # Validate products and check stock; total = Decimal(0); for item in order_data.items: product = self.product_repo.get(item.product_id); if not product: raise HTTPException(404, f"Product {item.product_id} not found"); if product.stock < item.quantity: raise HTTPException(400, f"Insufficient stock for {product.name}"); total += product.price * item.quantity; # Create order; order = self.order_repo.create(OrderCreate(user_id=user_id, items=order_data.items, total=total)); # Decrease stock for each item; for item in order_data.items: self.product_repo.decrease_stock(item.product_id, item.quantity); # Commit transaction; self.db.commit(); self.db.refresh(order); return order. (4) Transaction management: class TransactionalService: def __init__(self, db: Session = Depends(get_db)): self.db = db; async def execute_in_transaction(self, func, *args, **kwargs): try: result = await func(*args, **kwargs); self.db.commit(); return result; except Exception as e: self.db.rollback(); raise HTTPException(400, str(e)). # Use in service; class PaymentService: def __init__(self, order_repo: OrderRepository = Depends(), user_repo: UserRepository = Depends(), db: Session = Depends(get_db)): self.order_repo = order_repo; self.user_repo = user_repo; self.db = db; async def process_payment(self, order_id: int, payment_info: PaymentInfo): try: # Multiple operations in transaction; order = self.order_repo.get(order_id); charge_payment_gateway(payment_info); order.status = "paid"; order.paid_at = datetime.utcnow(); user = self.user_repo.get(order.user_id); user.total_spent += order.total; self.db.commit(); except PaymentError as e: self.db.rollback(); raise HTTPException(400, "Payment failed"); except Exception as e: self.db.rollback(); raise HTTPException(500, "Transaction failed"). (5) Caching with Redis: from redis import Redis. def get_redis() → Redis: return Redis(host="localhost", port=6379, decode_responses=True). class CachedProductRepository(ProductRepository): def __init__(self, db: Session = Depends(get_db), tenant: Tenant = Depends(get_tenant), cache: Redis = Depends(get_redis)): super().__init__(db, tenant); self.cache = cache; async def get(self, product_id: int) → Optional[Product]: # Check cache; cache_key = f"tenant:{self.tenant.id}:product:{product_id}"; cached = await self.cache.get(cache_key); if cached: return Product(**json.loads(cached)); # Fetch from DB; product = super().get(product_id); if product: # Cache for 5 minutes; await self.cache.setex(cache_key, 300, json.dumps(product.dict())); return product; async def invalidate_cache(self, product_id: int): cache_key = f"tenant:{self.tenant.id}:product:{product_id}"; await self.cache.delete(cache_key); def update(self, product_id: int, product: ProductUpdate) → Product: db_product = super().update(product_id, product); # Invalidate cache; await self.invalidate_cache(product_id); return db_product. # Use in endpoints; @app.post("/orders") async def create_order(order: OrderCreate, current_user: User = Depends(get_current_user), order_service: OrderService = Depends()): return await order_service.create_order(current_user.id, order). Production benefits: Tenant isolation automatic (every query filtered), repositories encapsulate data access, services orchestrate business logic, transaction management centralized, caching transparent to business logic, testable (mock repositories, not DB), DI composes everything automatically.',
    keyPoints: [
      'Tenant isolation: get_tenant dependency, BaseRepository._apply_tenant_filter, tenant_id automatic in all queries',
      'Repositories: UserRepository, ProductRepository, OrderRepository with Depends(get_db) + Depends(get_tenant)',
      'Service layer: OrderService combines repositories, coordinates transactions, business logic separate from data access',
      'Transactions: Try/commit/rollback pattern, flush() before commit, automatic rollback on exception',
      'Caching: CachedProductRepository extends ProductRepository, Redis injected, cache invalidation on update, tenant-scoped keys',
    ],
  },
  {
    id: 'fastapi-di-q-3',
    question:
      'Analyze dependency injection performance implications for high-throughput APIs (100K+ req/min). Discuss: (1) per-request dependency resolution overhead, (2) dependency caching mechanism and when it helps/hurts, (3) expensive dependencies (DB connections, external API clients) and optimization strategies, (4) class-based vs function-based dependencies performance, (5) profiling and optimizing dependency chains. Include benchmarks and optimization techniques.',
    sampleAnswer:
      'DI performance analysis for high-throughput: (1) Per-request resolution overhead: FastAPI dependency resolution: Parse parameters from request (~0.01-0.1ms), call dependency functions in order (~0.01ms per dependency), inject into handler (~0.001ms). Total typical overhead: 0.1-0.5ms for 5-10 dependencies. Benchmark: import time. @app.get("/benchmark") async def benchmark(p1 = Depends(dep1), p2 = Depends(dep2), p3 = Depends(dep3)): pass. 10,000 requests: Without dependencies: 50ms total (0.005ms/request), with 3 simple dependencies: 60ms total (0.006ms/request). Overhead: 0.001ms per dependency (negligible). Conclusion: DI overhead is <1% of total request time (network, DB, business logic dominate). (2) Dependency caching: How it works: FastAPI caches dependency results per request. First call: dependency executed, result cached. Subsequent calls: cached result returned immediately. Example: def expensive_dep(): print("Computing..."); return expensive_computation(). @app.get("/test") async def test(d1 = Depends(expensive_dep), d2 = Depends(expensive_dep)): pass. "Computing..." printed once per request! When caching helps: Database session (get_db): called once, reused everywhere (20x speedup). Current user: fetched once, used by multiple dependencies (10x speedup). Configuration: loaded once per request. When caching hurts: Timestamp dependencies: def get_timestamp(): return datetime.utcnow(); cached = same timestamp throughout request (probably fine). Random values: def get_random(): return random.random(); cached = same random value (use use_cache=False if needed). Solution for non-cacheable: @app.get("/") async def root(timestamp = Depends(get_timestamp, use_cache=False)). (3) Expensive dependency optimization: Problem: Creating DB connection pool, initializing clients per request is expensive. Bad (creates new client every request): def get_http_client(): return httpx.AsyncClient(); # New client each request! Good (reuse singleton): from functools import lru_cache. @lru_cache() def get_http_client(): return httpx.AsyncClient(); # Created once, reused. Best (async context manager): from contextlib import asynccontextmanager. @asynccontextmanager; async def lifespan(app: FastAPI): # Startup; client = httpx.AsyncClient(); app.state.http_client = client; yield; # Shutdown; await client.aclose(). def get_http_client(request: Request): return request.app.state.http_client. Database connections: Pool created at startup (not per request): engine = create_engine(DB_URL, pool_size=20, max_overflow=40); SessionLocal = sessionmaker(bind=engine). def get_db(): db = SessionLocal(); # Gets connection from pool (fast ~0.1ms); try: yield db; finally: db.close(); # Returns to pool. Benchmark: New connection per request: ~50ms per request (unacceptable!). Pool: ~0.1ms per request (500x faster). (4) Class-based vs function-based performance: Function-based: def pagination(page: int = 1, size: int = 20): return {"page": page, "size": size}. Class-based: class Pagination: def __init__(self, page: int = 1, size: int = 20): self.page = page; self.size = size. Benchmark (10K requests): Function-based: 100ms total (0.01ms/request). Class-based: 120ms total (0.012ms/request). Difference: 20% slower (0.002ms absolute difference). Reason: Class instantiation overhead (object creation, __init__ call). Verdict: Negligible difference (<1% of total request time). Use classes for maintainability, not performance. (5) Profiling dependency chains: Use FastAPI built-in timing: @app.middleware("http") async def time_dependencies(request: Request, call_next): start = time.time(); response = await call_next(request); total = time.time() - start; response.headers["X-Total-Time"] = str(total); return response. Profile specific dependency: import time. def expensive_dep(): start = time.time(); result = compute(); elapsed = time.time() - start; if elapsed > 0.1: logger.warning(f"Slow dependency: {elapsed:.3f}s"); return result. Use py-spy for production profiling: py-spy top --pid <fastapi-pid>. Optimization techniques: Lazy initialization: class LazyService: _instance = None; @classmethod; def get_instance(cls): if cls._instance is None: cls._instance = ExpensiveService(); return cls._instance. def get_service(): return LazyService.get_instance(). Async dependencies for I/O: # Sync (blocking): def get_config(): return requests.get("config-server").json(); # 100ms blocks thread. # Async (non-blocking): async def get_config(): async with httpx.AsyncClient() as client: return (await client.get("config-server")).json(); # 100ms doesn\'t block. Batch dependencies: Instead of N dependencies each fetching 1 item, 1 dependency fetches N items. Bad: user1 = Depends(get_user(1)); user2 = Depends(get_user(2)) → 2 DB queries. Good: users = Depends(get_users([1, 2])) → 1 DB query. Real-world optimization results: Before: 500ms per request (100 dependencies, no caching, sync HTTP calls). After: 50ms per request (dependency caching, async HTTP, connection pooling, lru_cache). 10x improvement! Dependency chain optimization: Before: get_token → verify_token → get_db → get_user → check_role → get_permissions (6 steps, 50ms). After: get_token → verify_token_with_cached_user (2 steps, 5ms). Cache user + permissions in JWT token payload, skip DB query. Production monitoring: Track dependency execution time: logger.info(f"Dependency {dep_name}: {elapsed}ms"). Alert on slow dependencies (>10ms). Profile regularly with py-spy. Optimize hot paths first (Pareto principle: 20% of dependencies = 80% of time).',
    keyPoints: [
      'Resolution overhead: 0.1-0.5ms for 5-10 dependencies, <1% of total request time (negligible)',
      'Caching: Dependencies cached per request, massive benefit for DB/user fetching (10-20x speedup), use_cache=False when needed',
      'Expensive deps: Use @lru_cache() for singletons, connection pooling (500x faster), lifespan events for startup initialization',
      'Class vs function: 20% slower (0.002ms absolute), negligible impact, choose for maintainability not performance',
      'Optimization: Async for I/O (unblocks threads), batch queries (N→1 DB calls), cache in JWT (skip DB), profile with py-spy, optimize hot paths first',
    ],
  },
];
