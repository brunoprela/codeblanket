export const financialModelingFundamentalsQuiz = [
  {
    id: 'fmf-q-1',
    question:
      'You are tasked with building a financial model for a potential acquisition. The target company operates in three distinct business segments: (1) legacy manufacturing (mature, 3% growth), (2) SaaS division (high growth, 25% annually), and (3) consulting services (cyclical, tied to GDP). Your model must support: scenario analysis, sensitivity testing, segment-level valuation, and Monte Carlo simulation. Design the complete model architecture. Specifically address: (a) How would you structure inputs to enable segment-specific assumptions? (b) What calculations should be modular vs integrated? (c) How would you implement validation checks to prevent errors? (d) Excel vs Python trade-offs for this use case? (e) Documentation strategy for a model that multiple team members will use?',
    sampleAnswer:
      'Comprehensive model architecture design: (a) **Input structure**: Create three-layer hierarchy: (1) Global assumptions (tax rate, WACC components, macro variables), (2) Segment-specific inputs (growth rates, margins, CapEx intensity), (3) Scenario toggles (base/bull/bear selector). Implementation: In Excel, use separate color-coded input sections per segment with data validation dropdown lists. In Python, use nested dataclass structure: class GlobalInputs, class SegmentInputs, class ScenarioManager. This enables changing manufacturing growth (3%) independently from SaaS (25%) while maintaining shared assumptions like tax rate. (b) **Modular vs integrated**: Modular: Each segment has its own P&L, but all segments share: working capital calculation methodology, depreciation schedule logic, tax calculation function. Integrated: Consolidated P&L sums segment revenues/expenses, consolidated balance sheet, consolidated cash flow. Structure: Build segment models first (manufacturing.py, saas.py, consulting.py), then consolidation layer. Benefits: Can value segments separately (sum-of-parts), test individual segment sensitivities, but also see combined entity. (c) **Validation checks**: Implement at three levels: (1) Input validation: assert 0 <= growth_rate <= 1, assert margins in reasonable ranges, check that segment weights sum to 100%. (2) Calculation validation: balance sheet must balance (Assets = L + E), cash flow must tie to balance sheet cash, net income must flow to retained earnings. (3) Output validation: DCF terminal value shouldn\'t exceed 80% of total value, P/E ratios should be in industry range (5x-50x), segment margins should align with comparables. Code: Create ModelValidator class with methods for each check, run after every calculation, raise warnings (not errors) for reasonableness checks. (d) **Excel vs Python trade-off**: For this use case, **hybrid approach optimal**: Python for: (1) Monte Carlo (10,000 simulations infeasible in Excel), (2) Automated data pulls (segment financials from internal systems), (3) Complex consolidation logic, (4) Version control via Git. Excel for: (1) Client presentation (PE firms expect Excel), (2) Ad-hoc scenario testing during live meetings, (3) Visualizations and formatting. Workflow: Build core model in Python (calculations, simulations), export results to formatted Excel template for presentations. (e) **Documentation strategy**: (1) Model memo: 2-3 page document explaining: model purpose, key assumptions, segment definitions, methodology, limitations. (2) Inline documentation: Every assumption has source citation ("SaaS growth: 25% per management guidance, Q3 2024 earnings call"), every calculation has comment explaining logic. (3) Change log: Track all modifications with date, author, description. Use Git commits for Python, Excel compare tool + separate changelog tab for Excel. (4) User guide: Instructions for: changing assumptions, running scenarios, interpreting outputs, updating for new quarters. (5) Assumption book: Separate document with full rationale for each input, sensitivities tested, benchmarking against competitors. For multi-user models, mandatory: (1) Protected sheets/cells in Excel, (2) Code review process for Python changes, (3) Designated "model owner" responsible for integrity. Additional consideration: Consulting segment cyclical nature requires GDP-linked assumptions. Implement correlation between macro variables and consulting revenue using regression on historical data. This ensures scenarios are internally consistent (recession scenario → lower GDP → consulting revenue decline).',
    keyPoints: [
      'Three-layer input hierarchy: global, segment-specific, scenario toggles for flexibility',
      'Modular segment models with integrated consolidation enables sum-of-parts analysis',
      'Multi-level validation: input ranges, calculation ties, output reasonableness checks',
      'Hybrid Python+Excel optimal: Python for computation/simulation, Excel for presentation',
      'Documentation is critical for multi-user models: memo, inline comments, change log, user guide',
    ],
  },
  {
    id: 'fmf-q-2',
    question:
      'A junior analyst on your team built a DCF model in Excel with 300 rows and 50 columns. When you audit it, you discover: (1) hard-coded numbers scattered in formulas, (2) inconsistent time periods (mix of quarters and years), (3) no balance sheet checks, (4) circular reference causing #VALUE errors, and (5) undocumented assumptions. The model is due to the client tomorrow. Outline your systematic approach to: (a) Quickly identify and fix critical errors, (b) Implement validation checks, (c) Add proper documentation, (d) Restructure for future maintainability, (e) Prevent this from happening again. What tools and techniques would you use?',
    sampleAnswer:
      'Systematic model remediation approach (triage → fix → prevent): (a) **Critical error identification (1-2 hours)**: Step 1: Check if balance sheet balances. Formula: =IF(ABS(Assets-(Liabilities+Equity))>1,"DOES NOT BALANCE","OK"). If not balanced, model outputs are unreliable. Step 2: Trace circular reference using Excel "Formulas → Circular References". Common cause: cash depends on debt, debt depends on interest, interest reduces cash. Solution: Enable iterative calculation (File → Options → Formulas → Enable iterative calculation, max iterations 100) OR break circular by making cash a plug (balancing item). Step 3: Use "Formulas → Trace Precedents/Dependents" to identify hard-coded numbers. Look for cells with numbers but no equal sign. Flag these in red. Step 4: Check time period consistency. Look for mismatched labels (Q1 2024 next to 2024, 2025...). If mixing periods, revenue might be quarterly but margins annual - causes 4x overstatement! Quick fix: Insert new row labels with standardized periods, verify all calculations match. Step 5: Validate DCF mechanics: (a) Free cash flow = EBIT(1-tax) + D&A - CapEx - ∆NWC. (b) Terminal value formula correct: FCF×(1+g)/(WACC-g). (c) All cash flows discounted properly: =FCF/(1+WACC)^Year. (b) **Implement validation (30 minutes)**: Add new "Checks" section at top of model with: (1) Balance sheet check: =IF(ABS(Assets-(L+E))<1,"✓","❌ DOES NOT BALANCE"). (2) Cash flow tie: =IF(ABS(CF_EndingCash-BS_Cash)<1,"✓","❌ CASH DOESN\'T TIE"). (3) Revenue growth reasonableness: =IF(AND(Growth>-50%,Growth<100%),"✓","⚠ Check growth"). (4) WACC reasonableness: =IF(AND(WACC>3%,WACC<20%),"✓","⚠ Check WACC"). (5) Terminal value % of total: =IF(TV_PV/TotalValue<80%,"✓","⚠ TV too high"). Use conditional formatting to highlight failures in red. (c) **Add documentation (30 minutes)**: Create "Assumptions" tab with table: | Assumption | Value | Source | Date | Rationale |. Fill in: Revenue growth = 10% | Management guidance | 10/15/2024 | New product launch. WACC = 9.5% | CAPM calc | 10/15/2024 | Beta=1.2, Rf=4.5%, MRP=6%. Add cell comments (right-click → Insert Comment) to key formulas explaining logic. Add text box at top: "Model purpose: DCF valuation for [Company]. Prepared by: [Name], Date: [Date], Version: 1.0." (d) **Restructure for maintainability (if time permits, 1-2 hours)**: Ideal structure: Tab 1: Assumptions (all inputs, color-coded blue). Tab 2: Historical financials (3-5 years). Tab 3: Projections (income statement, balance sheet, cash flow). Tab 4: DCF calculation. Tab 5: Outputs & sensitivity. If tight deadline, at minimum: (1) Move all hard-coded numbers to clearly labeled "Inputs" section at top. (2) Replace hard-coded formulas like =Revenue*0.40 with =Revenue*COGS_Margin (where COGS_Margin is named cell). (3) Add named ranges for key inputs (Ctrl+F3) so formulas are self-documenting: =Revenue*(1+RevenueGrowth) instead of =Revenue*(1+B15). (e) **Prevention strategy**: (1) Model review checklist: Before any model goes to client, verify: Balance sheet balances, Cash flow ties, All assumptions documented, No hard-coded numbers in formulas, Validation checks present and passing, Time periods consistent. (2) Model templates: Create standardized templates with pre-built validation checks, proper structure, color coding. All new models start from template. (3) Pair programming: Junior analyst builds model, senior reviews while it\'s being built (not day before deadline!). Use Excel\'s "Compare Spreadsheets" tool to review changes. (4) Training: Invest in financial modeling training for team. Common mistakes are teachable: input/calculation separation, validation checks, documentation, circular reference handling. (5) Code review culture: Treat Excel models like code. Every model gets reviewed by at least one other person before client delivery. Tools for auditing: (1) Excel Formula Auditing tools (trace precedents/dependents, evaluate formula). (2) Spreadsheet Compare (Microsoft tool) to see what changed. (3) Manual spot-checks: Verify a few key calculations by hand. (4) Reasonableness tests: Do the outputs make sense? If Tesla valued at $10 trillion, something is wrong. Key insight: Most model errors are preventable through structure and process, not just individual skill. A well-designed template with built-in checks prevents 80% of issues.',
    keyPoints: [
      'Triage critical errors first: balance sheet balance, circular references, time period consistency',
      'Implement automated validation checks: balance ties, reasonableness ranges, conditional formatting',
      'Documentation minimum: assumptions table with sources, cell comments on key formulas, model cover page',
      'Quick fixes: move hard-coded numbers to inputs, add named ranges, create validation checks section',
      'Prevention via templates, checklists, pair review, and treating Excel models like code requiring review',
    ],
  },
  {
    id: 'fmf-q-3',
    question:
      "Your firm is deciding whether to standardize on Excel or Python for financial modeling going forward. You've been asked to prepare a recommendation memo. The firm does: (1) M&A advisory for middle-market companies ($50M-$500M), (2) Private equity buy-side modeling, (3) Portfolio company monitoring (tracking 20+ companies quarterly), and (4) Internal financial planning. Client presentation is critical - they expect to receive Excel models they can modify. The team has: 10 analysts (Excel experts, no coding), 3 associates (intermediate Python), 2 VPs (Excel only). Present a detailed recommendation addressing: tool choice, implementation timeline, training requirements, workflow integration, and mitigation of risks.",
    sampleAnswer:
      'Recommendation: **Hybrid approach with phased Python adoption**, not wholesale replacement. Rationale and implementation plan: **Analysis of use cases**: (1) M&A advisory: Client expects editable Excel model with their assumptions. Python-only won\'t work. But Python can accelerate comparable company analysis (scraping 50 comps vs manual entry). Hybrid: Build in Python, export to Excel template. (2) PE buy-side modeling: During deal process, need flexibility to update assumptions in live partner meetings. Excel preferred for live iteration. But Python optimal for pre-deal screening (running LBO model on 100 targets). Hybrid: Python for screening, Excel for finalist due diligence. (3) Portfolio monitoring (20+ companies): Highly repetitive - perfect for Python automation. Pull quarterly data, run standardized analysis, generate reports. Pure Python makes sense here. Excel output for presentation only. (4) Internal FP&A: Excel likely sufficient, but Python can automate consolidation of department budgets. **Recommended approach**: Phase 1 (Months 0-3): Low-risk pilot projects. (1) Portfolio monitoring automation: Have 1 associate build Python script to pull quarterly financials from accounting system, calculate key metrics, export to Excel dashboards. Measure time savings. (2) Comps analysis automation: Build Python tool to scrape financial data for comparable companies from Yahoo Finance, calculate multiples, generate Excel output. Compare to manual process. (3) Success metrics: 50%+ time savings, no accuracy loss, stakeholders happy with outputs. Phase 2 (Months 4-6): Expand to data-intensive tasks. (1) Python for: Comp screening (100+ companies), Historical data analysis, Monte Carlo simulations (deals with high uncertainty), Automated reporting (portfolio companies). (2) Excel for: Client-facing models (M&A, LBO finals), Live meeting adjustments, Presentation and formatting. (3) Integration: Build Python tools that output to Excel templates. Clients see Excel, but analytics are Python-powered. Phase 3 (Months 7-12): Hybrid workflow institutionalized. (1) All new projects start with question: "Is this repetitive/data-intensive?" If yes → Python. "Is this client-facing?" If yes → Excel output required. (2) Build library of reusable Python modules: data_pull.py, comps_analysis.py, dcf_model.py, lbo_model.py. (3) Excel templates with consistent structure for Python exports. **Training requirements**: (1) Associates (3 people, intermediate Python): Advanced training: pandas for financial data, openpyxl for Excel integration, API usage for data pulls. Investment: 40 hours over 3 months (training + practice projects). (2) Analysts (10 people, no coding): Basic Python literacy: What Python does, how to run scripts, how to modify inputs in configuration files. NOT full programming. Investment: 8-10 hours. Goal: Understand tools, provide feedback, eventually some may self-teach. (3) VPs (2 people, Excel only): Training on how to use Python outputs, understanding what Python is doing "under the hood" for confidence. Investment: 4-5 hours overview sessions. **Workflow integration**: (1) Version control: All Python code in Git repository. Models still shareable via Excel. (2) Code review: Associates review each other\'s Python code before production use. (3) Documentation: Every Python script has README explaining: purpose, inputs, outputs, how to run. (4) IT setup: Python environment on shared server so analysts can run scripts without installing Python. Web interface for common tasks. **Risk mitigation**: Risk 1: "Clients reject Python-generated models." Mitigation: Clients receive Excel only (familiar format). Python is internal process optimization. Test with friendly client first. Risk 2: "Team resists change, prefers Excel comfort zone." Mitigation: Voluntary adoption. Show time savings on pilot projects. Associates who adopt get efficiency gains, finish work faster, get better reviews. Organic spread via success stories. Risk 3: "Python scripts break, no one can fix them." Mitigation: (a) Comprehensive documentation and comments. (b) At least 2 people can maintain each critical script. (c) Automated tests to catch breakages. (d) Excel remains backup option. Risk 4: "Python skills leave when associates get promoted or leave firm." Mitigation: (a) Document everything. (b) Build reusable libraries, not one-off scripts. (c) Create "Python champion" role (associate who becomes internal expert, trains others). Risk 5: "Initial investment (training, development time) doesn\'t pay off." Mitigation: Start with high-ROI use cases (portfolio monitoring, comp analysis). If 20+ portfolio companies, automation saves 50 hours/quarter = 200 hours/year = $40K+ (at $200/hour). ROI is clear. **Cost-benefit analysis**: Costs: Training (100 hours × $200/hour = $20K), Development time first 6 months (200 hours × $200/hour = $40K), Software/tools (minimal, Python is free). Total: ~$60K. Benefits: Portfolio monitoring: 50 hours/quarter savings = 200 hours/year = $40K/year. Comp analysis: 20 deals/year × 5 hours savings/deal = 100 hours = $20K/year. Total annual savings: $60K. **Break-even in Year 1**. Years 2+: Pure profit. **Final recommendation**: (1) Adopt hybrid approach: Python for automation/analytics, Excel for client delivery. (2) Phased rollout over 12 months, starting with high-ROI pilots. (3) Train associates in Python, analysts in Python literacy, VPs in oversight. (4) Preserve Excel expertise (still critical for client interaction). (5) Measure and communicate success metrics from pilots to build buy-in. This is not Excel vs Python. This is Excel AND Python, each used for its strengths. Best-in-class firms use both.',
    keyPoints: [
      'Hybrid approach optimal: Python for automation/data-intensive tasks, Excel for client delivery',
      'Phased rollout with low-risk pilots (portfolio monitoring, comps) measuring time savings',
      'Tiered training: Associates (deep Python), Analysts (literacy), VPs (oversight)',
      'Risk mitigation: Start voluntary, document thoroughly, maintain 2+ people per critical script',
      'ROI analysis shows break-even in year 1 with portfolio monitoring and comp analysis automation',
    ],
  },
];
