export const monteCarloValuationQuiz = [
  {
    id: 'mcv-q-1',
    question: 'You run a Monte Carlo DCF simulation with 10,000 iterations and get: P10 = $7B, P50 = $10B, P90 = $14B, Mean = $10.5B, Std Dev = $2.5B. Your CFO asks: "Why is the mean ($10.5B) higher than the median ($10B)? And what does P10 mean for our risk management?" Explain: (a) Why mean > median?, (b) Interpretation of P10/P50/P90, (c) Which metric to use for decision-making?, (d) How does this inform risk management?, (e) Present this to a board unfamiliar with Monte Carlo.',
    sampleAnswer: 'Complete Monte Carlo interpretation and communication: (a) **Why mean > median?** Distribution is right-skewed (positive skew). Explanation: Valuation has asymmetric upside. Downside is bounded (company can\'t be worth negative), but upside is unbounded (could be worth $20B+ in extreme bull case). Math: P10-P50 range = $3B ($10B - $7B), P50-P90 range = $4B ($14B - $10B). Upside range larger than downside = pulls mean higher than median. Visual: Long right tail in distribution (few very high outcomes) drags mean up. This is common in Monte Carlo valuations—extreme positive scenarios (breakthrough product, market dominance) create right skew. (b) **Interpretation of percentiles**: P10 = $7B: "10% probability company is worth LESS than $7B." Downside/stress case. If 10% chance materializes, very bad outcome. P50 = $10B: "50% probability company is worth less/more than $10B." Median = middle outcome. Half simulations above, half below. P90 = $14B: "90% probability company is worth LESS than $14B, or 10% probability worth MORE." Upside/optimistic case. P10-P90 range = $7B-$14B: "80% confidence interval." 8 out of 10 scenarios fall in this range. Only 1 in 10 is below $7B (disaster) or above $14B (home run). (c) **Which metric for decision-making?** Median (P50 = $10B): Best for "most likely" outcome. Not influenced by extreme scenarios. Use for: Base case valuation, negotiations, fairness opinions. Mean ($10.5B): Expected value (probability-weighted average). Use for: Portfolio decisions (allocating capital across multiple investments), Long-term value (averages over many outcomes). Risk-adjusted: P25-P30 ($8-9B): Conservative valuation for risk-averse decisions. Use for: Maximum purchase price (don\'t want to overpay if downside hits), Stress testing (can we survive P10 scenario?). Recommendation: Present median ($10B) as "base case" but show full range ($7B-$14B). Decision-makers need to see downside risk, not just central tendency. (d) **Risk management implications**: Downside risk (P10 = $7B): If we acquire at $11B (above median), 60% chance we overpaid. If disaster scenario (P10), we\'re underwater by $4B. Mitigation: Don\'t pay more than P50 ($10B), Build in contingencies (earnouts, performance triggers), Hedge key risks (customer concentration, supplier dependencies). Stress test: What if P10 materializes? Company worth $7B, we paid $10B → $3B loss. Can we absorb this? Do we have dry powder for rescue capital? Upside potential (P90 = $14B): If we acquire at $10B (median), 10% chance we get $4B+ upside. Expected upside: ($14B - $10B) × 10% = $400M expected gain from upside scenarios. Downside risk: ($10B - $7B) × 10% = $300M expected loss from downside. Risk/reward: $400M upside vs $300M downside = favorable (but only 10% probabilities). Portfolio strategy: If doing many deals, expected value (mean $10.5B) is correct metric—diversification smooths individual deal risk. If single bet-the-company deal, focus on P25-P50 range (downside protection). (e) **Board presentation** (non-technical): "Board, we ran 10,000 simulations of this acquisition to understand the range of outcomes. Think of it like flipping a coin 10,000 times, but instead of heads/tails, we\'re simulating revenue growth, margins, interest rates, etc. Key findings: Most likely outcome (P50): Company is worth $10B. This is the middle of the distribution—half of scenarios are better, half worse. Confidence range (P10-P90): We are 80% confident the company is worth between $7B and $14B. Only 1 in 10 scenarios is outside this range. Downside risk (P10): There\'s a 10% chance the company is worth LESS than $7B. This could happen if: (1) Revenue growth disappoints (competition, market shrinks), (2) Margins compress (pricing pressure), (3) Interest rates spike (WACC increases to 12%+). If this happens, we lose $3B+ if we acquire at $10B. Upside potential (P90): There\'s a 10% chance the company is worth MORE than $14B. This could happen if: (1) Company captures 50%+ market share (winner-take-all), (2) New product line succeeds (expands TAM), (3) Interest rates drop (WACC falls to 7%). If this happens, we gain $4B+ on $10B investment (40% return). Average outcome (Mean): Expected value is $10.5B. Slightly higher than median because extreme upside scenarios (rare but valuable) pull the average up. Recommendation: Willing to pay up to $10B (median). At this price: 50% chance we create value (company worth more than we paid), 10% chance we lose big (downside to $7B), 10% chance we win big (upside to $14B+). Risk/reward is acceptable for strategic importance of this asset. Above $11B, risk/reward becomes unfavorable—more likely to overpay than create value. Contingency: Structure deal with $2B earnout tied to hitting revenue targets. Reduces upfront price to $8B cash (below P50), eliminates overpayment risk while preserving upside participation." Key lesson: Monte Carlo transforms binary question ("buy or not?") into probabilistic decision ("buy at $10B has 50% chance of value creation, 10% downside risk to $7B, 10% upside potential to $14B—is that acceptable?"). Board can now weigh risk/reward explicitly instead of relying on single-point DCF.',
    keyPoints: [
      'Mean > median indicates right-skewed distribution; unbounded upside creates positive skew (extreme bull scenarios)',
      'P10/P50/P90 = 10th/50th/90th percentiles; P10-P90 range is 80% confidence interval for valuation',
      'Use median (P50) for base case, mean for portfolio decisions, P25-P30 for conservative/risk-averse pricing',
      'P10 quantifies downside risk; if acquiring above P50, calculate expected loss if P10 materializes (stress test)',
      'Present to board as range with probabilities: "80% confident worth $7B-$14B, most likely $10B, avoid paying >$11B"',
    ],
  },
  {
    id: 'mcv-q-2',
    question: 'You model revenue growth as Normal(12%, 5%) and EBITDA margin as Normal(25%, 3%) as independent variables. A colleague argues: "These should be correlated—high growth companies usually have expanding margins (operating leverage). Independence assumption understates upside and overstates downside volatility." Build: (a) Correlation argument (why should they correlate?), (b) Impact of independence vs correlation on valuation distribution, (c) How to empirically estimate correlation, (d) Implementation in Python, (e) When is independence assumption acceptable?',
    sampleAnswer: 'Modeling correlated variables in Monte Carlo: (a) **Why revenue growth and EBITDA margin correlate**: Theoretical basis: Operating leverage: High-growth companies spread fixed costs over more revenue → margins expand. Example: SaaS company at $100M revenue with $80M costs (20% margin) grows to $200M revenue. Variable costs: $120M (60% of revenue), Fixed costs: $30M (unchanged). New margin: ($200M - $120M - $30M) / $200M = 25% (margin improved from 20% to 25%!). Scale economies: Larger companies negotiate better vendor rates, optimize operations, have pricing power. Virtuous cycle: High growth → invest in sales/marketing → win customers → scale → improve margins → fund more growth. Empirical evidence: Plot historical revenue growth vs EBITDA margin for comp set—typically positive correlation (0.4-0.7). Implies: In bull scenario (high growth), margins likely expand (both move up together). In bear scenario (low growth), margins likely compress (price competition, underutilized capacity). Independence assumption (current model): Allows scenarios where growth = 20% but margin = 15% (incongruent—high growth with low margin unlikely). Also allows growth = 5% but margin = 35% (also unlikely—low growth doesn\'t generate 35% margins without scale). (b) **Impact on valuation distribution**: Independent variables: P10 = $7B, P50 = $10B, P90 = $14B (example from Q1). Correlated variables (correlation = +0.6): P10 = $7.5B (HIGHER—less extreme downside). P50 = $10B (unchanged—median similar). P90 = $14.5B (HIGHER—more extreme upside). Explanation: Positive correlation reduces variance in middle, increases tail outcomes. Downside (P10): Without correlation, could get low growth (8%) AND low margin (18%) simultaneously—double whammy = $7B. With correlation, low growth (8%) likely paired with medium margin (22%), not low margin. Reduces severity = $7.5B. Upside (P90): Without correlation, could get high growth (18%) but only medium margin (27%). With correlation, high growth (18%) likely paired with high margin (32%)—double benefit = $14.5B. Net effect: Correlated model has fatter tails (more extreme outcomes) but similar median. Coefficient of variation increases (more uncertainty relative to mean). (c) **Empirically estimate correlation**: Data approach: Collect historical data for target company (or comps): Year-by-year revenue growth rates and EBITDA margins for past 10 years. Calculate sample correlation: corr(growth, margin). Use this as correlation parameter in simulation. Example calculation: Year | Revenue Growth | EBITDA Margin 2014 | 8% | 18% 2015 | 12% | 21% 2016 | 15% | 24% 2017 | 18% | 27% 2018 | 20% | 29% 2019 | 14% | 25% 2020 | 5% | 17% (COVID) 2021 | 25% | 31% 2022 | 10% | 22% 2023 | 12% | 24% Correlation = CORREL(growth, margin) ≈ 0.75 (strong positive correlation). Use 0.75 in Monte Carlo simulation. Cross-sectional approach (if limited time series): Collect current growth rates and margins for 30 comparable companies. Calculate correlation across comps. Use as proxy for target company dynamics. Expert judgment: If no data, estimate: Strong operating leverage (SaaS, software) → correlation = 0.6-0.8. Moderate (services, manufacturing) → correlation = 0.3-0.5. Weak (commodity, retail) → correlation = 0.0-0.2. (d) **Python implementation**: See correlation code in main section above using numpy.random.multivariate_normal with covariance matrix. Key: Convert correlation matrix to covariance matrix using standard deviations. (e) **When is independence acceptable?** Independence OK when: (1) Variables truly uncorrelated: Example: Terminal growth rate and CapEx % of revenue—no theoretical link. Terminal growth is macro (GDP, inflation), CapEx is company-specific (capital intensity). (2) Correlation is weak (<0.2): Example: Revenue growth and tax rate—minimal relationship. Tax rate is policy-driven, not company performance. (3) Conservative analysis: If modeling for risk purposes (stress testing, minimum valuation), independence assumption creates fatter tails = more conservative. Errs on side of caution (overstates downside risk). (4) Limited data: If correlation estimate is unreliable (only 3 years of data, high noise), safer to assume independence than use spurious correlation. Independence NOT acceptable when: (1) Strong theoretical correlation: Revenue growth and EBITDA margin (operating leverage), WACC and terminal growth (both driven by interest rates). (2) Empirical correlation >0.4: Data shows material correlation—ignoring it misrepresents distribution. (3) Tail risk analysis: If decision hinges on P5/P95 outcomes, correlation materially affects tails. Must model accurately. Recommendation: "For revenue growth and EBITDA margin, use correlation = 0.6 (based on historical analysis of comps). This increases P90 upside from $14B to $14.5B and reduces P10 downside severity from $7B to $7.5B. More realistic than independence assumption. For other variables (WACC, terminal growth, CapEx), model pairwise correlations: WACC × terminal growth: -0.5 (inverse—rising rates reduce terminal growth). Revenue growth × CapEx: +0.3 (high growth requires more investment). All others: Independence acceptable (weak or no theoretical link)."',
    keyPoints: [
      'Revenue growth and EBITDA margin correlate positively (+0.4 to +0.7) due to operating leverage; scale spreads fixed costs',
      'Positive correlation increases tail outcomes (fatter tails): P10 less severe, P90 more extreme; median unchanged',
      'Estimate correlation empirically from historical data (time series) or comp set (cross-sectional); use if >0.3',
      'Implementation: numpy.random.multivariate_normal with covariance matrix from correlation and std devs',
      'Independence acceptable when correlation <0.2, no theoretical link, or conservative analysis desired; otherwise model correlation',
    ],
  },
  {
    id: 'mcv-q-3',
    question: 'Your VP presents Monte Carlo results to the board: "We ran 10,000 simulations. The company is worth $10.2B ± $2.1B at 95% confidence." A board member challenges: "This looks scientific, but garbage in = garbage out. How confident are you in the input distributions? Did you just make up that revenue growth is Normal(12%, 5%)?" Defend your methodology: (a) How did you derive input distributions?, (b) Sensitivity of outputs to distribution assumptions, (c) Validation techniques, (d) When Monte Carlo adds value vs false precision, (e) How to present credibly.',
    sampleAnswer: 'Defending Monte Carlo methodology and addressing "garbage in, garbage out" critique: (a) **Deriving input distributions** (evidence-based, not arbitrary): Revenue growth: Historical data: Company grew 8%, 12%, 15%, 18%, 10% past 5 years. Mean = 12.6%, Std dev = 3.8%. Analyst estimates: Consensus for next 3 years = 10%, 12%, 14% (mean ~12%). Comparable companies: Industry peers grow 8-16% (mean 12%, std dev 4%). Combined: Use Normal(12%, 5%) where: 12% mean reflects historical + analyst consensus, 5% std dev slightly wider than historical (4%) to account for uncertainty. Validation: 95% of simulations will be 12% ± 10% (2% to 22%), which matches range seen in comps. EBITDA margin: Historical: Company margins 20%, 23%, 25%, 27%, 26% past 5 years (trending up). Mean = 24%, Std dev = 2.8%. Scale analysis: At $1B revenue (today), 25% margin. At $2B revenue (5 years, with scale), project 28-30% margin (operating leverage). Peer analysis: Mature comps at target\'s scale have 26-32% margins (mean 28%, std dev 3%). Use Normal(25%, 3%) for current projections, fading to (28%, 2%) for later years. WACC: Risk-free rate: 4.5% (current 10-year Treasury). Beta: 1.2 (from Bloomberg regression), but range 0.9-1.4 depending on lookback period. Market risk premium: 6-7% (historical average), but could be 5-8% (academic debate). Calculate: Low (Rf 4% + 0.9β × 5% MRP) = 8.5%, High (Rf 5% + 1.4β × 8% MRP) = 16.2%, Base: 9.5%. Use Normal(9.5%, 1.5%) capturing this range. Terminal growth: GDP growth: 2% real + 2% inflation = 4% nominal (long-term average). Company can\'t outgrow economy forever → cap at 4%. Use Normal(2.5%, 0.5%) with floor at 1.5%, ceiling at 4%. Justification: 2.5% is conservative (GDP growth), 0.5% std dev captures uncertainty. (b) **Sensitivity to distribution assumptions**: Test: What if revenue growth is Normal(12%, 8%) instead of Normal(12%, 5%) (wider distribution)? Result: P10 drops from $7B to $6B (-14%), P90 rises from $14B to $16B (+14%), Std dev increases 40%. Interpretation: Output sensitive to input standard deviation—wider input = wider output (mechanical relationship). Test: What if revenue growth is Lognormal(log(1.12), 0.15) instead of Normal(12%, 5%)? Result: P50 unchanged (~$10B), but P90 increases to $15.5B (+11%), Mean increases to $11B (+5%). Interpretation: Lognormal has fatter right tail (more extreme upside scenarios) = higher mean. Test: What if EBITDA margin is Triangular(20%, 25%, 35%) instead of Normal(25%, 3%)? Result: Similar median, but P10/P90 range narrows slightly (triangular has bounded tails vs normal). Conclusion: Choice of distribution type (normal vs lognormal vs triangular) matters for tails (P10/P90), less for median. Parameters (mean, std dev) matter significantly for all statistics. (c) **Validation techniques**: Back-testing: Take 2018 data, run Monte Carlo for 2019-2023. Compare simulated distribution to actual outcomes. If actual 2023 value falls in P25-P75 range of simulation, model calibrated well. If actual is P5 (extreme), either: (1) Model underestimated volatility (need wider distributions), or (2) Rare event occurred (1-in-20 outcome—unlucky but not model failure). Cross-validation with deterministic: Run base/bear/bull scenarios (deterministic). Compare to Monte Carlo P25/P50/P75. Should align—if Monte Carlo P50 = $10B but deterministic base = $12B, one is wrong. Peer benchmarking: Run Monte Carlo for 3 public comps where market cap is observable. If simulated P50 aligns with actual market cap (±20%), model credible. If simulated P50 = $5B but market cap = $10B, model is mis-calibrated (distributions too pessimistic or WACC too high). Stress test: Force inputs to extreme values (P5 growth, P95 WACC) and check output makes sense. If P5 scenario gives $20B valuation (higher than P50!), model has error. Sensitivity to sample size: Run 1,000 simulations, then 10,000, then 100,000. If P10/P90 stable, sufficient sample size. If P10 jumps around, need more simulations. (d) **When Monte Carlo adds value vs false precision**: Monte Carlo ADDS value when: (1) Multiple uncertain inputs: 5+ variables with material uncertainty. Too complex for 3 scenarios to capture all combinations. (2) Tail risk matters: Decision depends on P10 outcome (stress test) or P90 (upside case for option pricing). (3) Regulatory/compliance: Required for certain valuations (insurance reserves, pension liabilities, derivatives). (4) Portfolio context: Aggregating risk across 10+ investments—need probabilistic framework. Monte Carlo is FALSE precision when: (1) Single dominant uncertainty: If 90% of valuation variance comes from one variable (e.g., FDA approval = binary yes/no), Monte Carlo overkill. Just model 2 scenarios: approval vs rejection. (2) Garbage inputs: If distributions are guesses ("I think growth is 10-15%, so I\'ll use Normal(12.5%, 2%)"), output has false confidence. Better to admit "we don\'t know" than pretend precision. (3) Non-technical audience: If board doesn\'t understand P10/P90, Monte Carlo confuses more than clarifies. Use simple scenarios instead. (4) Overfit: Modeling 20 variables with complex distributions based on 5 data points each = overfitting noise. (e) **How to present credibly to board**: Step 1 - Show derivation: "Revenue growth distribution: Historical company data (mean 12.6%, std 3.8%), Analyst consensus (mean 12%), Peer analysis (mean 12%, std 4%). Combined: Normal(12%, 5%)." Don\'t just say "we used Normal(12%, 5%)"—explain WHY. Step 2 - Validation: "We back-tested this model on 2018-2023. Actual 2023 value fell at P40 of our simulated distribution—model is well-calibrated." Step 3 - Sensitivity: "If we\'re wrong about revenue growth volatility (std dev 8% instead of 5%), P10 drops to $6B and P90 rises to $16B. Central case ($10B) unchanged." Shows robustness (or sensitivity) to assumptions. Step 4 - Cross-check: "Deterministic base case: $10.2B. Monte Carlo P50: $10B. LBO analysis: $9.8B. All three methods converge within 5%—high confidence." Triangulation builds credibility. Step 5 - Plain English: "Think of Monte Carlo as 10,000 coin flips, but instead of heads/tails, we\'re flipping revenue growth, margins, interest rates. Most outcomes (80%) fall between $7B-$14B. We\'re confident company is worth $10B give-or-take $3B." Recommendation: "Board member is correct—garbage in = garbage out is valid critique. To address: (1) We derived all input distributions from historical data, analyst estimates, and peer benchmarks (not arbitrary guesses). (2) We validated model through back-testing and cross-checks with deterministic methods. (3) We sensitivity-tested: Changing input volatility by 50% changes output range by 25%, but median stable at $10B. (4) Monte Carlo adds value here because: Multiple uncertain variables (growth, margins, WACC, terminal growth) interact in complex ways, Decision depends on tail risk (we need to know P10 downside for risk management), Provides confidence intervals board requested. (5) We present with humility: This is not \'the answer is $10.2B\'—it\'s \'we\'re 80% confident the answer is $7B-$14B, most likely $10B.\' Uncertainty acknowledged, not hidden."',
    keyPoints: [
      'Derive distributions from historical data + analyst estimates + peer analysis; document sources (not arbitrary assumptions)',
      'Validate via back-testing (actual outcomes fall in P25-P75 range?) and cross-checks with deterministic models',
      'Sensitivity test: vary input std devs ±50%; if output median stable, model robust; if swings wildly, inputs drive output',
      'Monte Carlo adds value when multiple uncertainties, tail risk matters, and stakeholders sophisticated; false precision if garbage inputs',
      'Present credibly: show derivation, validate, sensitivity test, cross-check, and use plain English ("80% confident worth $7B-$14B")',
    ],
  },
];
