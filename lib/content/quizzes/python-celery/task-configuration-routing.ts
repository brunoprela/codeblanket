/**
 * Quiz questions for Task Configuration & Routing section
 */

export const taskConfigurationRoutingQuiz = [
  {
    id: 'q1',
    question:
      'Your system processes 3 types of tasks: (1) Email sending (I/O-heavy, 1000s/min), (2) Video transcoding (CPU-heavy, 10s/min), (3) Database cleanup (low priority, 1/hour). Design a complete queue routing strategy including queue names, worker pools, concurrency settings, and deployment configuration.',
    sampleAnswer:
      'COMPLETE QUEUE ROUTING ARCHITECTURE: **ANALYSIS**: 3 distinct workload types: (1) Emails: I/O-heavy, high volume (1000/min = 16.7/sec), (2) Videos: CPU-heavy, low volume (10/min), (3) Cleanup: Low priority, very low volume (1/hour). **QUEUE DESIGN**: **Queue 1: "emails"** - Purpose: Email sending tasks. - Characteristics: I/O-bound (waiting for SMTP), High throughput. - Worker pool: gevent (lightweight greenlets). - Concurrency: 200 (can handle 200 concurrent SMTP connections). - Workers: 2 processes √ó 200 concurrency = 400 concurrent emails. **Queue 2: "videos"** - Purpose: Video transcoding tasks. - Characteristics: CPU-bound (encoding), Low throughput but slow. - Worker pool: prefork (true parallelism, bypass GIL). - Concurrency: 4 (match CPU cores). - Workers: 3 processes √ó 4 concurrency = 12 concurrent videos (enough for 10/min). **Queue 3: "cleanup"** - Purpose: Database cleanup tasks. - Characteristics: Low priority, infrequent. - Worker pool: prefork (database operations). - Concurrency: 1 (single cleanup at a time). - Workers: 1 process √ó 1 concurrency = 1 cleanup task. **CONFIGURATION**: ```python # celeryconfig.py task_routes = { "tasks.send_email": {"queue": "emails"}, "tasks.send_sms": {"queue": "emails"}, "tasks.transcode_video": {"queue": "videos"}, "tasks.generate_thumbnail": {"queue": "videos"}, "tasks.cleanup_*": {"queue": "cleanup"}, "*": {"queue": "default"} } task_annotations = { "tasks.send_email": {"rate_limit": "100/s"}, "tasks.transcode_video": {"time_limit": 3600, "soft_time_limit": 3000}, "tasks.cleanup_*": {"rate_limit": "1/h"} } ``` **TASK DEFINITIONS**: ```python @app.task (name="tasks.send_email") def send_email (email: str, subject: str, body: str): """Routed to emails queue""" pass @app.task (name="tasks.transcode_video") def transcode_video (video_id: int): """Routed to videos queue""" pass @app.task (name="tasks.cleanup_old_data") def cleanup_old_data(): """Routed to cleanup queue""" pass ``` **DEPLOYMENT**: ```bash # Worker 1: Email queue (gevent for I/O) celery -A tasks worker \\ -Q emails \\ --pool=gevent \\ --concurrency=200 \\ --hostname=email-worker-1@%h \\ --max-tasks-per-child=10000 # Worker 2: Email queue (redundancy) celery -A tasks worker \\ -Q emails \\ --pool=gevent \\ --concurrency=200 \\ --hostname=email-worker-2@%h \\ --max-tasks-per-child=10000 # Worker 3-5: Video queue (prefork for CPU, 3 workers) celery -A tasks worker \\ -Q videos \\ --pool=prefork \\ --concurrency=4 \\ --hostname=video-worker-{1,2,3}@%h \\ --max-tasks-per-child=100 # Worker 6: Cleanup queue (low priority) celery -A tasks worker \\ -Q cleanup \\ --pool=prefork \\ --concurrency=1 \\ --hostname=cleanup-worker@%h ``` **KUBERNETES DEPLOYMENT**: ```yaml # Email workers (auto-scale based on queue depth) apiVersion: apps/v1 kind: Deployment metadata: name: celery-email-workers spec: replicas: 2 # Start with 2, auto-scale to 10 template: spec: containers: - name: celery-worker command: ["celery", "-A", "tasks", "worker", "-Q", "emails", "--pool=gevent", "--concurrency=200"] resources: requests: memory: "512Mi" cpu: "500m" limits: memory: "1Gi" cpu: "1000m" --- # Video workers (GPU instances) apiVersion: apps/v1 kind: Deployment metadata: name: celery-video-workers spec: replicas: 3 template: spec: nodeSelector: instance-type: gpu containers: - name: celery-worker command: ["celery", "-A", "tasks", "worker", "-Q", "videos", "--pool=prefork", "--concurrency=4"] resources: requests: memory: "4Gi" cpu: "4000m" nvidia.com/gpu: 1 --- # Cleanup worker (single instance) apiVersion: apps/v1 kind: Deployment metadata: name: celery-cleanup-worker spec: replicas: 1 template: spec: containers: - name: celery-worker command: ["celery", "-A", "tasks", "worker", "-Q", "cleanup", "--pool=prefork", "--concurrency=1"] ``` **SCALING STRATEGY**: Emails: - Normal: 2 workers √ó 200 concurrency = 400 concurrent. - Peak: Auto-scale to 10 workers √ó 200 = 2000 concurrent. - Trigger: Queue depth > 1000 or CPU > 70%. Videos: - Fixed: 3 workers √ó 4 concurrency = 12 concurrent (handles 10/min). - If volume increases: Add more GPU workers. Cleanup: - Fixed: 1 worker (sufficient for 1/hour). **MONITORING**: ```python # Prometheus metrics worker_queue_depth{queue="emails"} # Alert if >1000 worker_queue_depth{queue="videos"} # Alert if >50 worker_task_latency_seconds{queue="emails"} # Alert if p99 >10s worker_task_latency_seconds{queue="videos"} # Alert if p99 >600s ``` **BENEFITS**: ‚úÖ Isolation: Slow videos don\'t block fast emails. ‚úÖ Specialization: gevent for I/O, prefork for CPU. ‚úÖ Scalability: Scale email workers independently. ‚úÖ Resource optimization: GPU for videos, lightweight for emails. ‚úÖ Priority: Cleanup doesn\'t interfere with critical tasks. **COST ANALYSIS**: - Email workers: 2 √ó t3.medium = $60/month. - Video workers: 3 √ó p3.2xlarge (GPU) = $3,000/month. - Cleanup worker: 1 √ó t3.micro = $7/month. - Total: ~$3,067/month. **KEY TAKEAWAY**: Route tasks to specialized queues based on workload characteristics (I/O vs CPU), volume, and priority. Use appropriate worker pools (gevent for I/O, prefork for CPU) and scale independently.',
    keyPoints: [
      'Separate queues by workload: emails (I/O), videos (CPU), cleanup (low priority)',
      'Worker pools: gevent (I/O, high concurrency), prefork (CPU, true parallelism)',
      'Concurrency: emails (200), videos (4 per worker), cleanup (1)',
      'Deployment: 2 email workers, 3 video workers (GPU), 1 cleanup worker',
      'Scaling: Auto-scale emails based on queue depth, fixed videos/cleanup',
    ],
  },
  {
    id: 'q2',
    question:
      'Explain the difference between task_acks_late=True and task_acks_late=False. What are the trade-offs, and when would you use each?',
    sampleAnswer:
      'task_acks_late: ACKNOWLEDGMENT TIMING TRADE-OFFS: **WHAT IS TASK ACKNOWLEDGMENT?**: When worker pulls task from broker, it can: (1) Acknowledge immediately (acks_late=False) - "I got the task", (2) Acknowledge after completion (acks_late=True) - "I finished the task". **task_acks_late=False (DEFAULT)**: Acknowledge immediately when task received. **Behavior**: ```python # Worker pulls task from queue task = broker.get_task() broker.acknowledge (task.id) # ‚úÖ ACK immediately try: result = task.run() # Now execute except Exception: pass # Task already ACKed, won\'t requeue! ``` **What happens**: 1. Worker pulls task from broker. 2. Broker removes task from queue immediately. 3. Worker executes task. 4. If worker crashes during execution ‚Üí Task lost forever! **Pros**: ‚úÖ Simple, predictable. ‚úÖ Task removed from queue immediately (lower queue depth metric). ‚úÖ No duplicate processing (task ACKed once). **Cons**: ‚ùå Task lost if worker crashes mid-execution. ‚ùå Task lost if worker killed (OOM, SIGKILL). ‚ùå No retry if worker dies. **task_acks_late=True**: Acknowledge after task completion. **Behavior**: ```python # Worker pulls task from queue task = broker.get_task() # Don\'t ACK yet! try: result = task.run() # Execute first broker.acknowledge (task.id) # ‚úÖ ACK after success except Exception: broker.reject (task.id, requeue=True) # Reject, requeue ``` **What happens**: 1. Worker pulls task from broker. 2. Task stays in broker (marked "processing" but not removed). 3. Worker executes task. 4. If success: ACK (task removed from broker). 5. If crash: Task requeued automatically (another worker picks it up)! **Pros**: ‚úÖ Task never lost (requeued if worker crashes). ‚úÖ Automatic retry on worker failure. ‚úÖ More reliable (production-grade). **Cons**: ‚ùå Risk of duplicate processing (if worker crashes after success but before ACK). ‚ùå Higher queue depth metric (tasks marked "processing" stay in queue). ‚ùå Slightly more complex. **COMPARISON TABLE**: | Feature | acks_late=False | acks_late=True | |---------|-----------------|----------------| | **ACK timing** | Immediately | After completion | | **Task lost on crash** | Yes ‚ùå | No ‚úÖ | | **Duplicate processing** | No ‚úÖ | Possible ‚ùå | | **Reliability** | Lower | Higher ‚úÖ | | **Simplicity** | Simpler ‚úÖ | More complex | | **Production use** | Non-critical tasks | Critical tasks ‚úÖ | **WHEN TO USE acks_late=False**: ‚úÖ Non-critical tasks (logging, analytics). ‚úÖ Tasks that are OK to lose occasionally. ‚úÖ Idempotent tasks (safe to run multiple times anyway). ‚úÖ Tasks where duplicate processing is worse than losing task. Example: ```python @app.task (acks_late=False) def log_event (event_type: str, data: dict): """Non-critical: OK to lose occasionally""" logger.info (f"Event: {event_type}", extra=data) ``` **WHEN TO USE acks_late=True**: ‚úÖ Critical tasks (payments, orders, emails). ‚úÖ Tasks that must complete (cannot be lost). ‚úÖ Production systems (reliability matters). ‚úÖ Idempotent tasks (duplicate processing safe). Example: ```python @app.task (acks_late=True) def process_payment (order_id: int): """Critical: Must not lose payment task!""" charge_result = stripe.charge(...) Order.update (order_id, status="paid") # If worker crashes here, task requeued (idempotent!) ``` **DUPLICATE PROCESSING SCENARIO** (acks_late=True): ```python Timeline: T+0s: Worker pulls task "send_email (user@example.com)" T+1s: Worker executes task (email sent) T+1.5s: Worker crashes (before ACK) üí• T+2s: Broker requeues task (no ACK received) T+3s: Another worker picks up task T+4s: Email sent again (duplicate!) ``` **Solution**: Make tasks idempotent! ```python @app.task (acks_late=True) def send_email_idempotent (user_id: int): """Idempotent: Check if already sent""" if EmailLog.exists (user_id, "welcome"): return # Already sent, skip try: send_email(...) EmailLog.create (user_id, "welcome") # Mark as sent except IntegrityError: pass # Another worker sent it (race condition) ``` **CONFIGURATION**: ```python # Global setting (all tasks) app.conf.task_acks_late = True # Per-task setting @app.task (acks_late=True) def critical_task(): pass @app.task (acks_late=False) def non_critical_task(): pass # In celeryconfig.py task_acks_late = True # Default for all tasks task_reject_on_worker_lost = True # Requeue if worker dies ``` **RELATED SETTING: task_reject_on_worker_lost**: ```python # Requeue task if worker crashes/dies app.conf.task_reject_on_worker_lost = True ``` Ensures task requeued even if worker killed ungracefully. **PRODUCTION RECOMMENDATION**: ```python # celeryconfig.py - Production settings task_acks_late = True # ACK after completion task_reject_on_worker_lost = True # Requeue on crash worker_prefetch_multiplier = 1 # Fetch 1 task at a time ``` **Why prefetch_multiplier=1 with acks_late=True?**: If worker prefetches 4 tasks but crashes after completing 1, the other 3 are requeued (duplicate work). With prefetch=1, worker only fetches next task after ACKing previous. **REAL-WORLD EXAMPLE**: **E-commerce payment processing**: ```python @app.task( acks_late=True, # Must not lose payment tasks! reject_on_worker_lost=True, max_retries=3 ) def process_payment (order_id: int): """Critical payment task (acks_late=True)""" # Idempotent: Check if already processed if Order.get (order_id).status == "paid": return # Already processed # Process payment charge = stripe.charge(...) # If worker crashes here, task requeued ‚Üí idempotent check prevents duplicate charge Order.update (order_id, status="paid") ``` **Analytics logging**: ```python @app.task (acks_late=False) # OK to lose def log_page_view (page: str, user_id: int): """Non-critical analytics (acks_late=False)""" analytics.track (event="page_view", user_id=user_id, page=page) # If worker crashes, this log is lost (acceptable) ``` **KEY TAKEAWAY**: acks_late=False: Simple, but task lost if worker crashes (non-critical tasks). acks_late=True: Reliable, task requeued if worker crashes (critical tasks, production). Trade-off: Reliability vs risk of duplicates. Solution: Make tasks idempotent + use acks_late=True.',
    keyPoints: [
      'acks_late=False: ACK immediately, task lost if worker crashes (non-critical tasks)',
      'acks_late=True: ACK after completion, task requeued if crash (critical tasks)',
      'Production: Use acks_late=True + task_reject_on_worker_lost=True',
      'Trade-off: Reliability (acks_late=True) vs risk of duplicates',
      'Solution: Make tasks idempotent to handle duplicates safely',
    ],
  },
  {
    id: 'q3',
    question:
      'Your Celery workers are prefetching 4 tasks at a time (worker_prefetch_multiplier=4), but some tasks take 10 minutes while others take 10 seconds. This causes inefficient worker utilization. Explain the problem and design a solution.',
    sampleAnswer:
      'WORKER PREFETCH PROBLEM & SOLUTION: **THE PROBLEM**: **Scenario**: Worker with prefetch_multiplier=4 pulls 4 tasks: Task 1: 10 minutes (long). Task 2: 10 minutes (long). Task 3: 10 seconds (fast). Task 4: 10 seconds (fast). **Timeline**: ```bash T+0s: Worker prefetches 4 tasks [Task1, Task2, Task3, Task4] T+0s: Worker starts Task1 (10 min) T+10min: Worker finishes Task1, starts Task2 (10 min) T+20min: Worker finishes Task2, starts Task3 (10 sec) T+20min 10s: Worker finishes Task3, starts Task4 (10 sec) T+20min 20s: Worker finishes Task4, prefetches 4 more tasks ``` **Problem**: Tasks 3 & 4 (fast) waited 20 minutes even though they only take 10 seconds! Meanwhile, other workers might be idle (could have processed Tasks 3 & 4). **ROOT CAUSE**: Prefetching greedily locks tasks to specific worker, preventing load balancing. **IMPACT**: - **Poor load balancing**: Fast tasks stuck behind slow tasks. - **Inefficient utilization**: Other workers idle while tasks queued. - **Increased latency**: Fast tasks wait unnecessarily. - **Unfair scheduling**: Head-of-line blocking. **SOLUTION 1: Reduce Prefetch** (Simple): ```python # celeryconfig.py worker_prefetch_multiplier = 1 # Fetch 1 task at a time ``` **Behavior**: ```bash T+0s: Worker 1 fetches Task1 (10 min), Worker 2 fetches Task2 (10 min) T+0s: Worker 3 fetches Task3 (10 sec), Worker 4 fetches Task4 (10 sec) T+10s: Worker 3 done, fetches Task5 T+10s: Worker 4 done, fetches Task6 # Fast tasks processed immediately by available workers! ``` **Pros**: ‚úÖ Perfect load balancing. ‚úÖ Fast tasks not blocked by slow tasks. ‚úÖ Minimal latency. **Cons**: ‚ùå More broker round-trips (fetch 1 task at a time). ‚ùå Slightly higher broker load. **When to use**: Critical for mixed workloads (fast + slow tasks). **SOLUTION 2: Separate Queues** (Best): Route fast and slow tasks to different queues: ```python # celeryconfig.py task_routes = { "tasks.fast_*": {"queue": "fast"}, "tasks.slow_*": {"queue": "slow"}, } # Fast queue workers (prefetch=4 OK, tasks uniform) celery -A tasks worker -Q fast --concurrency=10 --prefetch-multiplier=4 # Slow queue workers (prefetch=1, prevent blocking) celery -A tasks worker -Q slow --concurrency=4 --prefetch-multiplier=1 ``` **Pros**: ‚úÖ Isolation (fast tasks never blocked by slow). ‚úÖ Optimize prefetch per queue. ‚úÖ Scale queues independently. **SOLUTION 3: Time-Limited Prefetch**: Set soft time limits to prevent long-running tasks from blocking: ```python # Task with time limit @app.task (soft_time_limit=300) # 5 minutes def potentially_slow_task(): try: result = operation() return result except SoftTimeLimitExceeded: cleanup() raise # Task terminated, worker picks up next task ``` **SOLUTION 4: Dynamic Prefetch** (Advanced): Adjust prefetch based on task characteristics: ```python # Custom prefetch logic def get_prefetch_multiplier (task_name): if "slow" in task_name: return 1 # Slow tasks: fetch 1 at a time elif "fast" in task_name: return 4 # Fast tasks: prefetch 4 else: return 2 # Default ``` **COMPARISON**: | Solution | Complexity | Load Balancing | Throughput | Use Case | |----------|------------|----------------|------------|----------| | **Prefetch=1** | Simple ‚úÖ | Excellent ‚úÖ | Moderate | Mixed workloads | | **Separate queues** | Moderate | Excellent ‚úÖ | High ‚úÖ | Production (best) | | **Time limits** | Simple | Good | High | Prevent runaway tasks | | **Dynamic prefetch** | Complex | Good | High | Advanced optimization | **DETAILED ANALYSIS**: **Prefetch=4 (BAD for mixed workloads)**: ```bash Queue: [10min, 10min, 10sec, 10sec, 10min, 10min, 10sec, 10sec] Worker 1 prefetches: [10min, 10min, 10sec, 10sec] ‚Üê Locks 4 tasks Worker 2 prefetches: [10min, 10min, 10sec, 10sec] ‚Üê Locks 4 tasks Result: All fast tasks (10sec) wait for slow tasks (10min) Latency: 10sec tasks take 20+ minutes! üí• ``` **Prefetch=1 (GOOD for mixed workloads)**: ```bash Queue: [10min, 10min, 10sec, 10sec, 10min, 10min, 10sec, 10sec] Worker 1 fetches: [10min] ‚Üí 10 min Worker 2 fetches: [10min] ‚Üí 10 min Worker 3 fetches: [10sec] ‚Üí 10 sec ‚úÖ Worker 4 fetches: [10sec] ‚Üí 10 sec ‚úÖ Worker 3 (idle) fetches: [10min] ‚Üí 10 min Worker 4 (idle) fetches: [10min] ‚Üí 10 min Worker 3 (idle) fetches: [10sec] ‚Üí 10 sec ‚úÖ Worker 4 (idle) fetches: [10sec] ‚Üí 10 sec ‚úÖ Result: Fast tasks processed immediately Latency: 10sec tasks take 10-20 seconds ‚úÖ ``` **PRODUCTION CONFIGURATION**: ```python # celeryconfig.py # Solution 1: Prefetch=1 (if single queue) worker_prefetch_multiplier = 1 # Solution 2: Separate queues (better) task_routes = { "tasks.send_email": {"queue": "fast"}, # 1-2s "tasks.process_image": {"queue": "medium"}, # 10-30s "tasks.transcode_video": {"queue": "slow"}, # 5-10min } # Fast queue: Higher prefetch (uniform fast tasks) # celery -A tasks worker -Q fast --prefetch-multiplier=4 # Medium queue: Moderate prefetch # celery -A tasks worker -Q medium --prefetch-multiplier=2 # Slow queue: No prefetch (prevent blocking) # celery -A tasks worker -Q slow --prefetch-multiplier=1 # General best practice for mixed workloads task_acks_late = True # ACK after completion worker_prefetch_multiplier = 1 # Fetch 1 at a time ``` **MONITORING**: Track task wait time (time in queue before execution): ```python from celery.signals import task_prerun, task_postrun @task_prerun.connect def task_started (task_id, task, **kwargs): queued_at = task.request.kwargs.get("queued_at") if queued_at: wait_time = time.time() - queued_at metrics.histogram("task.wait_time", wait_time, tags=[f"task:{task.name}"]) # Alert if wait time > 60s for fast tasks if "fast" in task.name and wait_time > 60: alert("Fast task waited too long!") ``` **KEY TAKEAWAY**: Prefetch multiplier causes head-of-line blocking with mixed workloads (fast tasks wait for slow tasks). Solution: Set prefetch=1 (simple) or use separate queues for fast/slow tasks (best). Monitor task wait times to detect inefficient scheduling.',
    keyPoints: [
      'Prefetch=4: Worker locks 4 tasks, fast tasks blocked by slow tasks (head-of-line blocking)',
      'Solution 1: prefetch=1 (fetch one at a time, perfect load balancing)',
      'Solution 2: Separate queues (fast queue, slow queue) with different prefetch settings',
      'Production: Use prefetch=1 for mixed workloads or separate queues for isolation',
      'Monitor task wait time to detect inefficient worker utilization',
    ],
  },
];
