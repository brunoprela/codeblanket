/**
 * Quiz questions for Task Results & State Management section
 */

export const taskResultsStateManagementQuiz = [
  {
    id: 'q1',
    question:
      'Your web API endpoint queues a Celery task and immediately calls result.get (timeout=30) to wait for the result before returning to the user. This causes API timeouts and poor performance. Design a better architecture using async result polling.',
    sampleAnswer:
      'ASYNC RESULT POLLING ARCHITECTURE: **PROBLEM**: Blocking API endpoint: ```python @app.route("/process") def process(): result = heavy_task.delay() return result.get (timeout=30) # ❌ BLOCKS for 30s! ``` Issues: (1) Web worker blocked for 30s (wasted), (2) User waits 30s (poor UX), (3) Timeout if task >30s, (4) Can\'t handle 1000s concurrent requests. **SOLUTION: Async Polling Pattern**: **Step 1: Queue task, return immediately** ```python @app.route("/process", methods=["POST"]) def process(): data = request.json result = heavy_task.delay (data) return {"task_id": result.id, "status": "processing"}, 202 ``` Response time: 50ms (instant!). **Step 2: Status endpoint** ```python @app.route("/status/<task_id>") def check_status (task_id): result = AsyncResult (task_id, app=app) if result.state == "PENDING": return {"state": "PENDING", "status": "Task queued..."} elif result.state == "STARTED": return {"state": "STARTED", "status": "Task running..."} elif result.state == "PROGRESS": return {"state": "PROGRESS", "percent": result.info.get("percent", 0)} elif result.state == "SUCCESS": return {"state": "SUCCESS", "result": result.result} elif result.state == "FAILURE": return {"state": "FAILURE", "error": str (result.info)} return {"state": result.state} ``` **Step 3: Frontend polling** ```javascript async function processData (data) { // Queue task const response = await fetch("/process", {method: "POST", body: JSON.stringify (data)}); const {task_id} = await response.json(); // Poll status const pollInterval = setInterval (async () => { const status = await fetch(`/status/${task_id}`); const data = await status.json(); if (data.state === "PROGRESS") { updateProgressBar (data.percent); } else if (data.state === "SUCCESS") { clearInterval (pollInterval); displayResult (data.result); } else if (data.state === "FAILURE") { clearInterval (pollInterval); displayError (data.error); } }, 2000); // Poll every 2s } ``` **BENEFITS**: ✅ API returns immediately (50ms vs 30s), ✅ Non-blocking (handles 1000s concurrent), ✅ Progress updates (UX), ✅ No timeouts (task can run hours). **ALTERNATIVE: WebSockets** ```python from flask_socketio import SocketIO socketio = SocketIO(app) @app.route("/process") def process(): data = request.json result = heavy_task.delay (data, socketio_sid=request.sid) return {"task_id": result.id} @app.task (bind=True) def heavy_task (self, data, socketio_sid): for i in range(100): # Work... # Push update via WebSocket socketio.emit("progress", {"percent": i}, room=socketio_sid) return result ``` Frontend: ```javascript socket.on("progress", (data) => { updateProgressBar (data.percent); }); ``` **KEY TAKEAWAY**: Never block web workers with result.get(). Queue task → return task_id → poll status endpoint. User gets instant response, can track progress.',
    keyPoints: [
      'Never use result.get() in API endpoints (blocks web worker)',
      'Pattern: Queue task → return task_id immediately → separate status endpoint',
      'Frontend polls /status/<task_id> every 2 seconds',
      'Alternative: WebSockets for real-time push updates',
      'Benefits: Instant API response (50ms), handles 1000s concurrent, progress tracking',
    ],
  },
  {
    id: 'q2',
    question:
      'Your Redis result backend is consuming 10GB+ RAM with millions of expired task results. Design a comprehensive cleanup and prevention strategy.',
    sampleAnswer:
      'REDIS RESULT BACKEND CLEANUP STRATEGY: **PROBLEM DIAGNOSIS**: Redis memory growing unbounded: ```bash redis-cli INFO memory # used_memory_human:10.5G redis-cli DBSIZE # (integer) 5000000 # 5 million keys! ``` Root cause: Results never expire or expire too slowly. **SOLUTION 1: Set Expiration** ```python # Global expiration (CRITICAL!) app.conf.result_expires = 3600 # 1 hour # Per-task expiration @app.task (result_expires=300) # 5 minutes def short_lived(): pass ``` **SOLUTION 2: Ignore Results** ```python # Fire-and-forget tasks @app.task (ignore_result=True) def log_event(): pass @app.task (ignore_result=True) def send_email(): pass # 90% of tasks don\'t need results! ``` **SOLUTION 3: Periodic Cleanup Task** ```python @app.task def cleanup_expired_results(): """Run daily at 3 AM""" import redis r = redis.Redis (host="localhost", port=6379, db=1) deleted = 0 cutoff = time.time() - 86400 # 24 hours for key in r.scan_iter("celery-task-meta-*", count=1000): task_id = key.decode().replace("celery-task-meta-", "") result = AsyncResult (task_id, app=app) if result.date_done and result.date_done.timestamp() < cutoff: result.forget() # Delete deleted += 1 if deleted % 1000 == 0: logger.info (f"Deleted {deleted} results...") logger.info (f"Total deleted: {deleted}") # Schedule app.conf.beat_schedule = { "cleanup-results": { "task": "tasks.cleanup_expired_results", "schedule": crontab (hour=3, minute=0), } } ``` **SOLUTION 4: External Storage for Large Results** ```python @app.task def process_large_data (data_id): """Don\'t store 100MB result in Redis!""" result = expensive_processing (data_id) # 100MB # Upload to S3 s3_url = upload_to_s3(result, f"results/{data_id}.json") # Return URL (tiny!) return {"result_url": s3_url, "size": len (result)} ``` **SOLUTION 5: Database Backend** ```python # Switch to database for persistence app.conf.result_backend = "db+postgresql://user:pass@localhost/celery_results" # Cleanup in database DELETE FROM celery_taskmeta WHERE date_done < NOW() - INTERVAL \'7 days\'; ``` **MONITORING**: ```python @app.task def monitor_result_backend(): """Monitor Redis memory""" import redis r = redis.Redis (host="localhost", port=6379, db=1) info = r.info("memory") used_memory_gb = info["used_memory"] / 1e9 key_count = r.dbsize() logger.info (f"Redis memory: {used_memory_gb:.2f}GB, Keys: {key_count}") if used_memory_gb > 5: alert_ops (f"Result backend using {used_memory_gb:.2f}GB!") if key_count > 1000000: alert_ops (f"Result backend has {key_count} keys!") # Schedule hourly monitoring app.conf.beat_schedule = { "monitor-results": { "task": "tasks.monitor_result_backend", "schedule": 3600.0, } } ``` **IMMEDIATE CLEANUP** (Emergency): ```python # Script: cleanup_redis.py import redis from celery.result import AsyncResult from celery import Celery app = Celery("myapp", broker="redis://localhost:6379/0", backend="redis://localhost:6379/1") r = redis.Redis (host="localhost", port=6379, db=1) print(f"Current keys: {r.dbsize()}") deleted = 0 for key in r.scan_iter("celery-task-meta-*", count=1000): task_id = key.decode().replace("celery-task-meta-", "") result = AsyncResult (task_id, app=app) # Delete if old or completed if result.ready() and result.date_done: age_hours = (datetime.now() - result.date_done).total_seconds() / 3600 if age_hours > 24: result.forget() deleted += 1 if deleted % 1000 == 0: print(f"Deleted {deleted}...") print(f"Total deleted: {deleted}") print(f"Remaining keys: {r.dbsize()}") ``` **PREVENTION CHECKLIST**: ✅ Set result_expires globally (1 hour default), ✅ Use ignore_result=True for 90% of tasks, ✅ Store large results in S3, return URLs, ✅ Monitor Redis memory (alert >5GB), ✅ Scheduled cleanup task (daily), ✅ Consider database backend for persistence. **KEY TAKEAWAY**: Redis result backend grows unbounded without expiration. Set result_expires=3600, use ignore_result=True for most tasks, store large results externally, monitor memory, scheduled cleanup.',
    keyPoints: [
      'Set result_expires=3600 globally (1 hour expiration)',
      'Use ignore_result=True for fire-and-forget tasks (90% of tasks)',
      'Store large results in S3, return URLs (not 100MB in Redis)',
      'Scheduled cleanup: Delete results older than 24 hours (daily task)',
      'Monitor: Alert if Redis >5GB or >1M keys',
    ],
  },
  {
    id: 'q3',
    question:
      'Implement a task with granular progress tracking that updates a progress bar in real-time while processing 10,000 items. Include progress persistence (resume after crash) and cancellation support.',
    sampleAnswer:
      'COMPREHENSIVE PROGRESS TRACKING WITH RESUME & CANCELLATION: ```python from celery import Celery, current_task from celery.exceptions import Ignore import redis app = Celery("myapp", broker="redis://localhost:6379/0", backend="redis://localhost:6379/1") redis_client = redis.Redis (host="localhost", port=6379, db=2) @app.task (bind=True) def process_items (self, items): """Process with progress, resume, cancellation""" task_id = self.request.id total = len (items) # Check if resuming from crash checkpoint = get_checkpoint (task_id) start_index = checkpoint.get("last_index", 0) if start_index > 0: logger.info (f"Resuming from index {start_index}") for i in range (start_index, total): # Check if task cancelled if is_cancelled (task_id): logger.info (f"Task {task_id} cancelled at {i}/{total}") self.update_state (state="CANCELLED", meta={"cancelled_at": i, "total": total}) raise Ignore() # Graceful exit # Process item item = items[i] result = process_single_item (item) # Update progress every 10 items (reduce overhead) if i % 10 == 0 or i == total - 1: percent = (i + 1) / total * 100 self.update_state( state="PROGRESS", meta={ "current": i + 1, "total": total, "percent": percent, "status": f"Processing {i+1}/{total}" } ) # Save checkpoint (resume support) save_checkpoint (task_id, {"last_index": i + 1, "total": total}) return {"status": "complete", "processed": total} def process_single_item (item): """Process one item""" time.sleep(0.1) # Simulate work return f"Processed {item}" def save_checkpoint (task_id, data): """Save progress to Redis""" redis_client.setex (f"checkpoint:{task_id}", 3600, json.dumps (data)) def get_checkpoint (task_id): """Load checkpoint""" data = redis_client.get (f"checkpoint:{task_id}") return json.loads (data) if data else {} def is_cancelled (task_id): """Check if task cancelled""" return redis_client.exists (f"cancel:{task_id}") # API endpoint: Start task @app.route("/process", methods=["POST"]) def start_processing(): items = request.json.get("items") # 10,000 items result = process_items.delay (items) return {"task_id": result.id} # API endpoint: Check progress @app.route("/progress/<task_id>") def check_progress (task_id): result = AsyncResult (task_id, app=app) if result.state == "PENDING": return {"state": "PENDING", "percent": 0} elif result.state == "PROGRESS": info = result.info return { "state": "PROGRESS", "current": info["current"], "total": info["total"], "percent": info["percent"], "status": info["status"] } elif result.state == "SUCCESS": return {"state": "SUCCESS", "result": result.result} elif result.state == "FAILURE": return {"state": "FAILURE", "error": str (result.info)} elif result.state == "CANCELLED": return {"state": "CANCELLED", "info": result.info} return {"state": result.state} # API endpoint: Cancel task @app.route("/cancel/<task_id>", methods=["POST"]) def cancel_task (task_id): """Mark task for cancellation""" redis_client.setex (f"cancel:{task_id}", 3600, "1") return {"status": "cancellation requested"} # API endpoint: Resume task @app.route("/resume/<task_id>", methods=["POST"]) def resume_task (task_id): """Resume crashed task""" # Get checkpoint checkpoint = get_checkpoint (task_id) if not checkpoint: return {"error": "No checkpoint found"}, 404 # Get original items (stored separately) items = get_original_items (task_id) # Resume processing result = process_items.delay (items) return {"task_id": result.id, "resumed_from": checkpoint["last_index"]} # Frontend: Real-time progress bar async function processItems (items) { // Start task const {task_id} = await fetch("/process", { method: "POST", body: JSON.stringify({items}) }).then (r => r.json()); // Poll progress const progressBar = document.getElementById("progress"); const statusText = document.getElementById("status"); const cancelButton = document.getElementById("cancel"); let cancelled = false; cancelButton.onclick = async () => { await fetch(`/cancel/${task_id}`, {method: "POST"}); cancelled = true; statusText.textContent = "Cancelling..."; }; const poll = setInterval (async () => { const progress = await fetch(`/progress/${task_id}`).then (r => r.json()); if (progress.state === "PROGRESS") { progressBar.style.width = `${progress.percent}%`; statusText.textContent = progress.status; } else if (progress.state === "SUCCESS") { clearInterval (poll); progressBar.style.width = "100%"; statusText.textContent = "Complete!"; } else if (progress.state === "CANCELLED") { clearInterval (poll); statusText.textContent = "Cancelled"; // Show resume button showResumeButton (task_id); } else if (progress.state === "FAILURE") { clearInterval (poll); statusText.textContent = `Error: ${progress.error}`; } }, 1000); // Poll every second } ``` **FEATURES**: ✅ **Granular progress**: Updates every 10 items (1% increments). ✅ **Checkpoint/resume**: Saves progress to Redis, resumes after crash. ✅ **Cancellation**: Checks cancel flag every iteration, graceful exit. ✅ **Real-time updates**: Frontend polls every second. ✅ **Error handling**: FAILURE state with traceback. **PRODUCTION ENHANCEMENTS**: (1) WebSocket for push updates (no polling), (2) Database checkpoints (Redis persistence), (3) Cancel via signal (celery.control.revoke), (4) Progress batching (update every 1% not every item). **KEY TAKEAWAY**: Progress tracking with self.update_state (state="PROGRESS"), checkpoints for resume, cancellation flag check, frontend polling. Enables long-running tasks with user visibility.',
    keyPoints: [
      'Progress: self.update_state (state="PROGRESS", meta={percent, current, total})',
      'Checkpoint: Save last_index to Redis every N items (resume after crash)',
      'Cancellation: Check redis flag every iteration, raise Ignore() for graceful exit',
      'Frontend: Poll /progress/<task_id> every second, update progress bar',
      'Resume: Retrieve checkpoint, restart from last_index (not from beginning)',
    ],
  },
];
