// import { MultipleChoiceQuestion } from '@/lib/types';

export const alembicMigrationsQuiz = [
  {
    id: 'sql-alembic-q-1',
    question:
      'Design a zero-downtime migration to rename the "email" column to "email_address" in a users table with 10M rows in production. Address: (1) why a simple rename causes downtime, (2) step-by-step migration phases, (3) application code changes for each phase, (4) rollback strategy, (5) verification steps. Include all migration files and code.',
    sampleAnswer: `Zero-downtime column rename: (1) Why simple rename causes downtime: op.alter_column("users", "email", new_column_name="email_address") requires exclusive table lock. With 10M rows, lock held for minutes. All queries blocked → application down. (2) Four-phase approach: PHASE 1 - Add new column (nullable): def upgrade(): op.add_column("users", sa.Column("email_address", sa.String(255))). Deploy: No downtime, column added instantly (nullable, no data). Code change: Write to both columns: user.email = user.email_address = value. PHASE 2 - Backfill data: def upgrade(): op.execute("UPDATE users SET email_address = email WHERE email_address IS NULL LIMIT 10000"). Run in batches (10K rows/batch) to avoid long locks. Or: Background job updates rows gradually. Verify: SELECT COUNT(*) FROM users WHERE email_address IS NULL (should be 0). PHASE 3 - Make NOT NULL + add constraints: def upgrade(): op.alter_column("users", "email_address", nullable=False); op.create_unique_constraint("uq_users_email_address", "users", ["email_address"]); op.create_index("ix_users_email_address", "users", ["email_address"]). Deploy: Code now reads from email_address only: user.email_address (don't read email anymore). PHASE 4 - Drop old column: def upgrade(): op.drop_index("ix_users_email"); op.drop_column("users", "email"). Deploy: Old column removed, migration complete. (3) Rollback strategy: Each phase independently reversible. Phase 1 rollback: Drop email_address column. Phase 2 rollback: No-op (data backfill safe to leave). Phase 3 rollback: Drop constraints, make nullable. Phase 4 rollback: Recreate email column, backfill from email_address. (4) Verification: After Phase 1: SELECT COUNT(*) FROM users WHERE email_address IS NOT NULL (should be 0). After Phase 2: SELECT COUNT(*) FROM users WHERE email_address IS NULL (should be 0). After Phase 3: Test app reads from email_address successfully. After Phase 4: EXPLAIN SELECT * FROM users WHERE email_address = 'test' (should use new index). Timeline: Phase 1: Deploy immediately. Phase 2: Run overnight (batched updates). Phase 3: Next day deployment. Phase 4: 1 week later (after validation). Total: ~1 week, zero downtime.`,
    keyPoints: [
      'Simple rename requires exclusive lock (minutes for 10M rows, application down)',
      'Phase 1: Add nullable column. Phase 2: Backfill in batches. Phase 3: NOT NULL + constraints. Phase 4: Drop old',
      'Code: Phase 1-2 write both columns, Phase 3+ only email_address',
      'Rollback: Each phase independently reversible, Phase 2 safe to leave partial',
      'Verification: Count NULLs, test app, EXPLAIN query plans, 1 week timeline',
    ],
  },
  {
    id: 'sql-alembic-q-2',
    question:
      'You need to split a "name" column into "first_name" and "last_name" for 1M existing users. Requirements: (1) No data loss, (2) handle names with multiple spaces, (3) international names, (4) validation, (5) rollback capability. Provide complete migration with data transformation logic and error handling.',
    sampleAnswer: `Column split migration: (1) Migration phases: Phase 1 - Add new columns: def upgrade(): op.add_column("users", sa.Column("first_name", sa.String(100))); op.add_column("users", sa.Column("last_name", sa.String(100))). Phase 2 - Data migration with ORM: from sqlalchemy.orm import Session; from sqlalchemy import Table, Column, String, MetaData. def upgrade(): bind = op.get_bind(); session = Session (bind=bind); metadata = MetaData(); users = Table("users", metadata, Column("id", Integer, primary_key=True), Column("name", String), Column("first_name", String), Column("last_name", String)). Batch processing (1000 rows at a time): offset = 0; batch_size = 1000; while True: batch = session.execute (sa.select (users).offset (offset).limit (batch_size)).mappings().all(); if not batch: break. for user in batch: name = (user["name"] or "").strip(); if not name: first_name = last_name = "Unknown"; elif " " not in name: first_name = name; last_name = ""; else: parts = name.rsplit(" ", 1); first_name = parts[0]; last_name = parts[1]; session.execute (users.update().where (users.c.id == user["id"]).values (first_name=first_name, last_name=last_name)). session.commit(); offset += batch_size. (2) Handle edge cases: Empty names: Set "Unknown" for both. Single word names: first_name = name, last_name = "". Multiple spaces: rsplit(" ", 1) splits on last space - "John von Neumann" → first="John von", last="Neumann". International names: Store full name in first_name if single word. Validation: Log any names that couldn't be split for manual review: if len (name) > 200: logger.error (f"Name too long: user_id={user['id']}"). (3) Verification: def upgrade(): # After data migration, verify no NULLs: count = session.execute (sa.text("SELECT COUNT(*) FROM users WHERE first_name IS NULL OR last_name IS NULL")).scalar(); if count > 0: raise Exception (f"{count} users have NULL names - manual review needed"). Phase 3 - Make NOT NULL: def upgrade(): op.alter_column("users", "first_name", nullable=False); op.alter_column("users", "last_name", nullable=False). Phase 4 - Drop old column (after app deployed): def upgrade(): op.drop_column("users", "name"). (4) Rollback strategy: Downgrade Phase 4: Recreate name column, populate from first_name + last_name. def downgrade(): op.add_column("users", sa.Column("name", sa.String(200))); op.execute("UPDATE users SET name = first_name || ' ' || last_name WHERE last_name != ''"); op.execute("UPDATE users SET name = first_name WHERE last_name = ''"). Downgrade Phase 3: Make nullable. Downgrade Phase 2: Clear data (safe since phase 4 has backup). Downgrade Phase 1: Drop columns. (5) Production considerations: Run Phase 2 during low-traffic window. Monitor: Track progress (offset/total_rows). Error handling: Wrap in try/except, rollback on failure. Testing: Test on staging with production data copy. Manual review: Export problematic names for manual fixing: SELECT * FROM users WHERE LENGTH(first_name) > 100 OR first_name = 'Unknown'.`,
    keyPoints: [
      'Phase 1: Add columns. Phase 2: Data migration in batches (1000 rows). Phase 3: NOT NULL. Phase 4: Drop old',
      'Edge cases: Empty→"Unknown", single word→first_name only, multiple spaces→rsplit(" ", 1)',
      'Batch processing: 1000 rows/batch, commit per batch, track progress with offset',
      'Validation: Verify no NULLs, log names>200 chars, manual review for edge cases',
      'Rollback: Recreate name from first+last, each phase independently reversible',
    ],
  },
  {
    id: 'sql-alembic-q-3',
    question:
      'Two developers created migrations in parallel branches, both with down_revision pointing to the same parent. Explain: (1) what problem this causes, (2) how to detect it, (3) three solutions (merge, rebase, manual fix), (4) which to use when, (5) how to prevent future conflicts. Include commands and best practices.',
    sampleAnswer: `Parallel migration conflict: (1) Problem: Developer A: creates abc123 (down_revision=xyz789). Developer B: creates def456 (down_revision=xyz789). When merged, Alembic sees two heads (both claim to be next after xyz789). Running "alembic upgrade head" fails: "Multiple heads found". Migration chain broken - Alembic doesn't know which to apply first. (2) Detection: alembic heads - shows multiple heads: abc123 (head), def456 (head). alembic history --verbose - shows divergent branches at xyz789. alembic upgrade head - ERROR: "Multiple heads found". (3) Solution 1 - Merge migrations: alembic merge -m "merge heads" abc123 def456. Creates: merge_abc123_def456.py with down_revision = ('abc123', 'def456'). Both migrations applied, then merge. Pros: Preserves both migrations as-is, clear history. Cons: Extra merge migration. Use when: Migrations are independent (different tables), production safety matters. (4) Solution 2 - Rebase (manual fix): Edit def456 migration: change down_revision = 'xyz789' to down_revision = 'abc123'. Now linear: xyz789 → abc123 → def456. Pros: Linear history, no merge migration. Cons: Changes def456 revision (breaks if already deployed). Use when: Migrations not yet deployed to production, prefer linear history. (5) Solution 3 - Cherry-pick (advanced): Integrate one migration into the other: Combine operations from def456 into abc123. Delete def456 file. Pros: Single migration. Cons: Complex, manual work, error-prone. Use when: Migrations modify same table, want atomic change. (6) Prevention: Coordination: Team communicates before creating migrations (Slack: "Creating migration for users table"). Pull before creating: git pull && alembic history before alembic revision. Branch naming: Name branches after features, clearly indicate DB changes. CI checks: Pre-merge hook: alembic heads | grep -q "multiple" && echo "ERROR: Multiple heads". Migration order: Create migrations in order, merge smaller PRs first. Lock-free period: Designate "migration creation periods" where only one dev creates migrations. (7) Recommendation: Use Solution 1 (merge) for production safety. Use Solution 2 (rebase) for feature branches not yet merged. Commands: alembic heads (detect conflict), alembic merge heads (create merge migration), alembic history --verbose (visualize branches), git log alembic/versions/ (see who created what when). Best practice: Create migrations only on main branch after PR merge, not in feature branches.`,
    keyPoints: [
      'Problem: Two migrations same down_revision, "Multiple heads found" error',
      'Detection: alembic heads shows multiple, alembic upgrade head fails',
      'Solution 1: alembic merge heads (preserves both, extra merge file, production-safe)',
      'Solution 2: Manual rebase (edit down_revision, linear history, not if deployed)',
      'Prevention: Coordinate, pull before create, CI check for multiple heads',
    ],
  },
];
