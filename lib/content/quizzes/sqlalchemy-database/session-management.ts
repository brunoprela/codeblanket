export const sessionManagementQuiz = [
    {
        id: 'sql-session-q-1',
        question:
            'Explain the four object states in SQLAlchemy session lifecycle (transient, pending, persistent, detached). For each state: (1) how an object enters that state, (2) what operations are available, (3) how to transition to other states, (4) common pitfalls. Include code examples showing transitions.',
        sampleAnswer:
            \'SQLAlchemy object states: (1) TRANSIENT: Object created but not added to session. Entry: user = User(email=\"test@example.com\"). Operations: Can modify attributes, no database interaction. Transitions: session.add(user) → PENDING. Pitfall: Forgetting to add() means no persistence. (2) PENDING: Object added to session, will INSERT on flush. Entry: session.add(user). Operations: Can modify, tracked by session, no primary key yet. Transitions: session.flush()/commit() → PERSISTENT, session.expunge() → TRANSIENT. Pitfall: Accessing relationships before flush (no PK to join on). (3) PERSISTENT: Object in session with database identity (PK). Entry: After session.flush() or queried from DB. Operations: Full CRUD, relationships work, changes tracked. Transitions: session.expunge() → DETACHED, session.close() → DETACHED, session.delete() → DELETED. Pitfall: Not committing changes (lost on rollback). (4) DETACHED: Was in session, now removed. Entry: session.close(), session.expunge(). Operations: Can read attributes (cached), no database operations, accessing lazy relationships raises DetachedInstanceError. Transitions: session.merge() → PERSISTENT, session.add() → PERSISTENT. Pitfall: Accessing relationships after close(), passing between threads. Code example: user = User(email=\"test\") # TRANSIENT. session.add(user) # PENDING. session.flush() # PERSISTENT (has user.id now). session.expunge(user) # DETACHED. session.merge(user) # PERSISTENT again. Checking state: from sqlalchemy.inspect import inspect; state = inspect(user); print(state.persistent) # True if persistent.\',
        keyPoints: [
            'TRANSIENT: Created, not tracked (user = User()). PENDING: Added, no PK (session.add())',
            'PERSISTENT: In session + DB identity (after flush/query). DETACHED: Was tracked, now removed (after close)',
            'Transitions: add()→PENDING, flush()→PERSISTENT, close()→DETACHED, merge()→PERSISTENT',
            'Pitfalls: Accessing relationships before flush (PENDING), after close (DETACHED)',
            'Check state: from sqlalchemy.inspect import inspect; inspect(obj).persistent',
        ],
    },
    {
        id: 'sql-session-q-2',
        question:
            'Design session management for a FastAPI application handling 10,000 requests/second. Address: (1) session creation strategy, (2) connection pooling configuration, (3) handling long-running requests, (4) memory management for batch operations, (5) monitoring session health. Include complete production-ready code.',
        sampleAnswer:
            \'High-throughput FastAPI session management: (1) Session strategy: Use dependency injection with short-lived sessions (one per request). Code: def get_db(): db = SessionLocal(); try: yield db; finally: db.close(). @app.get(\"/users/{id}\") def get_user(id: int, db: Session = Depends(get_db)): return db.get(User, id). Each request gets fresh session, auto-closed after response. (2) Connection pooling: engine = create_engine(url, pool_size=20, max_overflow=40, pool_timeout=30, pool_recycle=3600, pool_pre_ping=True). Calculation: 10,000 req/s, avg 50ms request = 500 concurrent requests. With 5 app instances: 100 concurrent/instance. pool_size=20 handles normal load, max_overflow=40 handles spikes (total 60 connections/instance). pool_recycle=3600 prevents stale connections. pool_pre_ping=True handles DB restarts. Total: 5 instances × 60 = 300 connections (< PostgreSQL default 500). (3) Long-running requests: Use separate worker pool with higher timeout. BackgroundTasks for async processing: @app.post(\"/export\") def export_users(background_tasks: BackgroundTasks): background_tasks.add_task(export_task); return {\"status\": \"processing\"}. def export_task(): with get_db_session() as db: for offset in range(0, 1000000, 10000): users = db.execute(select(User).offset(offset).limit(10000)).scalars().all(); process(users); db.expire_all() # Free memory. Prevents long-lived sessions blocking connections. (4) Memory management: Batch operations with session reset: for i in range(100000): user = process_user(i); if i % 1000 == 0: session.commit(); session.expire_all() # Clear identity map. Alternative: New session per batch to prevent memory growth. (5) Monitoring: Middleware tracking: @app.middleware(\"http\") async def db_session_middleware(request: Request, call_next): query_count = 0; start = time.time(); ... track queries ...; response = await call_next(request); duration = time.time() - start; if duration > 1.0: logger.warning(f\"Slow: {duration}s, {query_count} queries\"); return response. Pool monitoring: def check_pool_health(): pool = engine.pool; return {\"size\": pool.size(), \"checked_out\": pool.checkedout(), \"overflow\": pool.overflow()}. Prometheus metrics: from prometheus_client import Gauge; pool_connections = Gauge(\"db_pool_connections\", \"Active connections\"); pool_connections.set(pool.checkedout()). Alert if pool.checkedout() / (pool.size() + pool.overflow()) > 0.8. (6) Production configuration: SessionLocal = sessionmaker(bind=engine, autocommit=False, autoflush=True, expire_on_commit=True). Never set autocommit=True (unpredictable transactions). expire_on_commit=True prevents stale data. Result: 10K req/s, < 50ms p95, 300 total DB connections, no memory leaks.\',
        keyPoints: [
            'One session per request via Depends(get_db), auto-closed after response',
            'Pool: size=20, max_overflow=40 per instance (5 instances = 300 total connections)',
            'Long-running: BackgroundTasks + batch with expire_all() to free memory',
            'Monitoring: Middleware tracking, pool health checks, Prometheus metrics',
            'Config: autoflush=True, expire_on_commit=True, pool_pre_ping=True for reliability',
        ],
    },
    {
        id: 'sql-session-q-3',
        question:
            'You have a DetachedInstanceError when accessing user.posts after session.close(). Explain: (1) why this error occurs, (2) three different solutions with pros/cons, (3) when each solution is appropriate, (4) how to prevent this class of errors in production. Include code for all solutions.',
        sampleAnswer:
            \'DetachedInstanceError analysis: (1) Why it occurs: user = session.get(User, 1); session.close(); print(user.posts) # ERROR. After session.close(), object is detached from session. Accessing lazy-loaded relationship (posts) requires database query, but session is closed. SQLAlchemy can\'t execute query without session, raises DetachedInstanceError. (2) Solution 1 - Eager load before close: session = SessionLocal(); stmt = select(User).where(User.id == 1).options(selectinload(User.posts)); user = session.execute(stmt).scalar_one(); session.close(); print(user.posts) # OK: already loaded. Pros: Simple, works with detached objects, good for passing data between layers. Cons: Must know needed relationships upfront. Use when: Returning objects from repository, passing data to other layers, batch processing. (3) Solution 2 - Keep session open: session = SessionLocal(); user = session.get(User, 1); print(user.posts) # OK: session still open; session.close(). Pros: Simple, lazy loading works, no need to predict relationships. Cons: Long-lived session (memory growth, stale data), connection held longer. Use when: Request-scoped sessions (web apps), operations within transaction boundary. (4) Solution 3 - Merge into new session: session1 = SessionLocal(); user = session1.get(User, 1); session1.close() # user detached. session2 = SessionLocal(); user = session2.merge(user) # user now in session2; print(user.posts) # OK: queries via session2. Pros: Reattach to different session, useful for multi-threaded. Cons: Overhead (SELECT to merge), complex, rarely needed. Use when: Passing objects between threads, long-running background jobs. (5) Solution 4 - Use expunge_all + lazy=\'raise\': class User(Base): posts = relationship(\"Post\", lazy=\"raise\") # Prevent lazy loading. session = SessionLocal(); stmt = select(User).where(User.id == 1).options(selectinload(User.posts)); user = session.execute(stmt).scalar_one(); session.close(); print(user.posts) # OK: already loaded. Pros: Catches lazy loading bugs at development time. Cons: Must eager load everything. Use when: Development/testing to enforce eager loading. (6) Prevention in production: Pattern 1: Repository pattern with DTOs: class UserDTO: def __init__(self, user): self.id = user.id; self.email = user.email; self.posts = [PostDTO(p) for p in user.posts]. Return DTOs instead of ORM objects (no detachment issues). Pattern 2: GraphQL-style field selection: def get_user(user_id, fields): stmt = select(User).where(User.id == user_id); if \"posts\" in fields: stmt = stmt.options(selectinload(User.posts)); return session.execute(stmt).scalar_one(). Pattern 3: Linting rules: Enforce eager loading in code reviews, use lazy=\"raise\" in development. Pattern 4: Context managers: Always use with get_db_session() to ensure cleanup. Recommendation: Solution 1 (eager load) for most cases. Use DTOs or Pydantic models for API responses to avoid detachment issues entirely.\',
        keyPoints: [
            'Error occurs: Accessing lazy relationship after session.close(), no session to query',
            'Solution 1: Eager load (selectinload) before close - simple, works with detached',
            'Solution 2: Keep session open - simple but long-lived (memory/stale data issues)',
            'Solution 3: Merge into new session - for multi-threaded, rarely needed',
            'Prevention: DTOs/Pydantic models, lazy=\"raise\" in dev, repository pattern',
        ],
    },
];

