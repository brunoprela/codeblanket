import { MultipleChoiceQuestion } from '@/lib/types';

export const relationshipLoadingQuiz = [
  {
    id: 'sql-loading-q-1',
    question:
      'Your API endpoint loads 100 users and displays their post count. Currently it executes 101 queries (N+1 problem). Provide: (1) code showing the N+1 problem, (2) three different solutions (selectinload, joinedload, subquery count), (3) performance comparison, (4) when to use each approach, (5) how to detect N+1 in production. Which solution would you choose and why?',
    sampleAnswer:
      'API endpoint optimization: (1) N+1 problem code: users = session.execute (select(User).limit(100)).scalars().all(); for user in users: print(f\"{user.email}: {len (user.posts)} posts\"). Executes: SELECT * FROM users LIMIT 100 (1 query), then SELECT * FROM posts WHERE user_id = ? for each user (100 queries). Total: 101 queries. At scale: 10,000 users = 10,001 queries, 10+ seconds. (2) Solution 1 - selectinload: stmt = select(User).options (selectinload(User.posts)).limit(100); users = session.execute (stmt).scalars().all(). Queries: SELECT * FROM users LIMIT 100, then SELECT * FROM posts WHERE user_id IN (1,2,...,100). Total: 2 queries. Access: for user in users: len (user.posts) - no additional queries. Pros: 2 queries, no cartesian product, works with LIMIT. Cons: Loads all post data (unnecessary if only counting). Solution 2 - joinedload: stmt = select(User).options (joinedload(User.posts)).limit(100); users = session.execute (stmt).scalars().unique().all(). Query: SELECT users.*, posts.* FROM users LEFT JOIN posts ON users.id = posts.user_id LIMIT 100. Total: 1 query. Pros: Single query. Cons: Cartesian product (user repeated for each post), LIMIT applies after JOIN (broken behavior), must call unique(), loads all post data. Solution 3 - Subquery count (BEST): stmt = select(User, func.count(Post.id).label(\"post_count\")).outerjoin(User.posts).group_by(User.id).limit(100). Query: SELECT users.*, COUNT(posts.id) FROM users LEFT JOIN posts GROUP BY users.id LIMIT 100. Total: 1 query. Pros: Single query, LIMIT works correctly, only loads count (not all post data), no cartesian after GROUP BY. Cons: More complex query, must access count separately. (3) Performance comparison (100 users, 1000 posts avg): N+1: 101 queries, 5 seconds. selectinload: 2 queries, 200ms. joinedload: 1 query but 100×1000 = 100,000 rows (cartesian), 500ms + memory issues. Subquery count: 1 query, 100 rows, 50ms (WINNER). (4) When to use: selectinload: Need full post data, default eager loading, multiple relationships. joinedload: One-to-one, small one-to-many without LIMIT, single relationship. Subquery count: Only need counts/aggregates, performance critical. (5) Detection in production: Enable SQL logging: engine = create_engine (url, echo=True) in development. Query counter: Event listener counts queries per request. APM tools: Datadog/New Relic show query count per endpoint (alert if > 10 queries). Performance monitoring: Track endpoint latency, investigate spikes. Testing: Automated test: with QueryCounter(): endpoint(); assert counter.count < 5. Recommendation: Use Solution 3 (subquery count) - fastest, most efficient. Only 1 query, no unnecessary data loaded, LIMIT works correctly.',
    keyPoints: [
      'N+1: 1 + N queries, linear degradation with scale (100 users = 101 queries)',
      'selectinload: 2 queries with IN clause, no cartesian, works with LIMIT',
      'joinedload: 1 query but cartesian product, LIMIT broken, requires unique()',
      'Subquery count: BEST for counts, 1 query, no unnecessary data, LIMIT works',
      'Detection: echo=True, query counter, APM tools (alert if > 10 queries/request)',
    ],
  },
  {
    id: 'sql-loading-q-2',
    question:
      'Explain the difference between joinedload and selectinload with a concrete example. Address: (1) SQL generated by each, (2) memory usage, (3) performance characteristics, (4) when each breaks (edge cases), (5) interaction with LIMIT/OFFSET, (6) which to use as default and why. Include benchmark results for 1000 users with 10 posts each.',
    sampleAnswer:
      'joinedload vs selectinload detailed comparison: (1) SQL generated: joinedload: stmt = select(User).options (joinedload(User.posts)). SQL: SELECT users.*, posts.* FROM users LEFT OUTER JOIN posts ON users.id = posts.user_id. Single query with JOIN. Returns: 1000 users × 10 posts = 10,000 rows (user data duplicated 10 times per user). selectinload: stmt = select(User).options (selectinload(User.posts)). SQL: Query 1: SELECT * FROM users (1000 rows). Query 2: SELECT * FROM posts WHERE user_id IN (1,2,3,...,1000) (10,000 rows). Two queries, no duplication. (2) Memory usage: joinedload: 10,000 rows of combined user+post data. Each row contains full user columns (id, email, name, ...) + post columns. Size: ~500 bytes/row × 10,000 = 5MB. selectinload: 1,000 user rows + 10,000 post rows, no duplication. Size: ~200 bytes × 1,000 + ~300 bytes × 10,000 = 3.2MB. selectinload uses 36% less memory (no cartesian duplication). (3) Performance: joinedload: Single network roundtrip, but larger result set (10,000 rows). Time: 150ms (100ms query + 50ms object creation from duplicated data). selectinload: Two roundtrips, but smaller result sets. Time: 120ms (50ms query 1 + 50ms query 2 + 20ms object creation). selectinload 20% faster despite two queries. (4) Edge cases where each breaks: joinedload + LIMIT: stmt = select(User).options (joinedload(User.posts)).limit(10). PROBLEM: LIMIT applies AFTER JOIN. If first user has 10 posts, query returns 10 rows (1 user), not 10 users. BROKEN BEHAVIOR. joinedload + multiple relationships: select(User).options (joinedload(User.posts), joinedload(User.comments)). PROBLEM: Cartesian explosion. 10 posts × 20 comments = 200 rows per user. 1000 users = 200,000 rows! OOM errors. selectinload edge case: Batch size limits. 1,000,000 users = IN clause with 1M values (may hit database limit). Solution: Use selectinload with polymorphic_identity for batch control. (5) LIMIT/OFFSET interaction: joinedload: LIMIT broken (applies after JOIN). NEVER use with LIMIT. selectinload: LIMIT works correctly (applies to users first). ALWAYS use with LIMIT. (6) Default recommendation: selectinload is default for production. Reasons: No cartesian product (memory efficient), Works with LIMIT, Scales to large collections, Multiple relationships safe, Predictable performance. Use joinedload only for: One-to-one relationships, Small one-to-many (< 10 items guaranteed), No LIMIT on query, Single relationship being loaded. (7) Benchmark (1000 users, 10 posts each): joinedload: 10,000 rows transferred, 5MB memory, 150ms query time. Must call unique() or get duplicates. selectinload: 11,000 rows transferred, 3.2MB memory, 120ms total time (50ms + 50ms + 20ms overhead). No unique() needed. Winner: selectinload (faster, less memory, works with LIMIT).',
    keyPoints: [
      'joinedload: 1 query, cartesian product, LIMIT broken, 5MB memory for 1K users',
      'selectinload: 2 queries, no cartesian, LIMIT works, 3.2MB memory (36% less)',
      'selectinload 20% faster despite 2 queries (less data transfer, object creation)',
      'joinedload breaks with LIMIT (applies after JOIN) and multiple relationships (explosion)',
      'Default: selectinload for production (predictable, efficient, scales)',
    ],
  },
  {
    id: 'sql-loading-q-3',
    question:
      'Design a loading strategy for a complex API endpoint that returns posts with: author (user), comments (with authors), tags, and like count. Requirements: (1) Load all data efficiently, (2) handle 100 posts per page, (3) < 5 database queries total, (4) optimize for read-heavy workload, (5) implement caching strategy. Include complete code, query plan, and caching implementation.',
    sampleAnswer:
      'Complex API with optimized loading: (1) Schema: Post (id, user_id, title, content), Comment (id, post_id, user_id, text), PostTag (post_id, tag_id), Tag (id, name), Like (post_id, user_id). (2) Efficient loading strategy: Use selectinload for nested relationships + subquery for aggregates. Code: stmt = select(Post, func.count (distinct(Like.post_id)).label(\"like_count\")).outerjoin(Like).options (selectinload(Post.user), selectinload(Post.comments).selectinload(Comment.user), selectinload(Post.tags)).group_by(Post.id).order_by(Post.created_at.desc()).limit(100). Query breakdown: Query 1: SELECT posts.*, COUNT(DISTINCT likes.post_id) FROM posts LEFT JOIN likes GROUP BY posts.id ORDER BY created_at DESC LIMIT 100. Returns 100 posts with like counts. Query 2: SELECT * FROM users WHERE id IN (post_author_ids). Returns 100 user objects (authors). Query 3: SELECT * FROM comments WHERE post_id IN (post_ids). Returns all comments for 100 posts. Query 4: SELECT * FROM users WHERE id IN (comment_author_ids). Returns comment authors. Query 5: SELECT post_tags.*, tags.* FROM post_tags JOIN tags WHERE post_id IN (post_ids). Returns tags for 100 posts. Total: 5 queries (meets requirement). (3) Why this strategy: Subquery for likes in main query (no extra query). selectinload for relationships (efficient IN clauses). Nested selectinload for comments.user (loads comment authors efficiently). No joinedload (avoid cartesian products). (4) Alternative approaches: BAD: Lazy loading (N+1 problem): 1 query for posts, 100 for users, 100 for comments, 100 for comment users, 100 for tags = 401 queries! BAD: Multiple joinedload: Cartesian explosion. 100 posts × 50 comments × 5 tags = 25,000 rows. Memory: 100MB+. GOOD: Our approach: 5 queries, minimal data transfer, predictable memory. (5) Caching strategy: Layer 1 - Application cache (Redis): Cache individual posts: key = f\"post:{post_id}\", TTL = 1 hour. Cache post list: key = f\"posts:page:{page_num}\", TTL = 5 minutes. Cache like counts: key = f\"post:{post_id}:likes\", TTL = 1 minute (updates frequently). Layer 2 - Query result cache: Cache expensive query results in Redis. Layer 3 - HTTP cache: Set Cache-Control: max-age=300 (5 minutes) for GET /posts. CDN caching for static content. Implementation: from functools import wraps; import redis; import pickle; redis_client = redis.Redis(). def cached (key_func, ttl=3600): def decorator (func): @wraps (func) def wrapper(*args, **kwargs): key = key_func(*args, **kwargs); cached_value = redis_client.get (key); if cached_value: return pickle.loads (cached_value); result = func(*args, **kwargs); redis_client.setex (key, ttl, pickle.dumps (result)); return result; return wrapper; return decorator. @cached (lambda page: f\"posts:page:{page}\", ttl=300) def get_posts (page): stmt = ...; return session.execute (stmt).scalars().all(). (6) Cache invalidation: On new post: Delete cache keys: posts:page:* (all pages). On new comment: Delete cache keys: post:{post_id}. On new like: Delete cache keys: post:{post_id}:likes. Use Redis keyspace notifications or pub/sub for distributed cache invalidation. (7) Performance results: Without optimization: 401 queries, 5 seconds, 100MB memory. With selectinload: 5 queries, 200ms, 10MB memory. With caching (cache hit): 0 queries, 5ms, 0MB database load. Read-heavy workload: 95% cache hit rate, average 10ms response time.',
    keyPoints: [
      '5 queries: Main with likes subquery, selectinload users, comments, comment users, tags',
      'selectinload for all relationships (no cartesian), nested for comments.user',
      'Caching: Redis for posts/lists (5min TTL), likes (1min TTL), HTTP cache headers',
      'Avoid: Lazy loading (401 queries), joinedload (25K rows, 100MB memory)',
      'Performance: 401 queries → 5 queries (200ms) → cached (5ms, 95% hit rate)',
    ],
  },
];
