export const financialDataSourcesAPIsQuiz = [
  {
    id: 'fdsa-q-1',
    question:
      'Design a production-grade data pipeline for a trading system. Address: (1) Data source selection (free vs paid, real-time vs historical), (2) Storage architecture (database choice, schema design), (3) Data validation and quality checks, (4) Update strategy (full refresh vs incremental), (5) Fault tolerance and monitoring. Include cost optimization and scalability considerations.',
    sampleAnswer:
      'Production data pipeline: (1) Data sources by use case: Backtesting (historical): yfinance (free, 15-min delay) or Polygon.io ($99/month, full history). Paper trading: Polygon.io real-time ($199/month) or IEX Cloud ($9/month limited). Live trading: Polygon.io professional ($499/month) or broker API (Interactive Brokers, Alpaca). Cost optimization: Start with yfinance for development, upgrade to Polygon when live. (2) Storage architecture: Time series database (TimescaleDB or InfluxDB) for OHLCV data. Schema: CREATE TABLE ohlcv (timestamp TIMESTAMPTZ, symbol TEXT, open REAL, high REAL, low REAL, close REAL, volume BIGINT, PRIMARY KEY (timestamp, symbol)). Index on (symbol, timestamp) for fast queries. Store metadata separately: CREATE TABLE metadata (symbol TEXT PRIMARY KEY, last_updated TIMESTAMPTZ, data_source TEXT). Alternative: Parquet files for large datasets (faster analytics, smaller size). (3) Validation checks: OHLC relationships: high >= max(open, close, low), low <= min(open, close, high). Price continuity: abs(return) < 0.5 (flag >50% jumps). Volume sanity: volume > 0, check for outliers (>10x average). Missing data: forward fill max 2 days, flag longer gaps. Corporate actions: adjust for splits/dividends. (4) Update strategy: Incremental updates daily: Query last_updated from metadata, fetch data from last_date+1 to today, validate, upsert into database. Full refresh weekly: Re-download last 252 days to catch corrections. Handle late adjustments: Some data sources revise historical data (splits, dividends). (5) Fault tolerance: Retry logic: 3 retries with exponential backoff (1s, 2s, 4s). Fallback sources: If Polygon fails, try Alpha Vantage or yfinance. Data versioning: Keep last 7 days of raw data for rollback. Monitoring: Track data freshness (alert if >1 hour old), coverage (alert if <95% symbols updated), quality metrics (validation pass rate). Logging: Store all API calls, errors, validation failures. Alerting: Email/Slack alerts for critical failures. Scalability: Horizontal: Partition by symbol (SPY in db1, QQQ in db2). Vertical: Use read replicas for analytics queries. Caching: Cache recent data in Redis for <1ms access. Cost: Development: $0 (yfinance). Paper trading: $10-100/month. Live trading: $200-500/month (depends on data needs).',
    keyPoints: [
      'Source selection: yfinance (dev), Polygon $99-499/month (production), scale with needs',
      'TimescaleDB for time series, schema with (timestamp, symbol) primary key',
      'Validation: OHLC relationships, price continuity (<50% jumps), volume sanity',
      'Incremental updates daily, full refresh weekly, retry with exponential backoff',
      'Monitoring: freshness (<1 hour), coverage (>95%), quality checks, alerting',
    ],
  },
  {
    id: 'fdsa-q-2',
    question:
      'Compare free (yfinance, Alpha Vantage) vs paid (Polygon, Bloomberg) data sources for algorithmic trading. Analyze: (1) Data quality differences, (2) Latency and reliability, (3) Coverage and history, (4) API rate limits, (5) Cost-benefit analysis for different trading strategies (daily, intraday, HFT). When should you upgrade from free to paid?',
    sampleAnswer:
      'Data source comparison: (1) Data quality: yfinance: 15-min delay, occasional gaps, adjusted prices (splits/dividends), good for daily+. Issues: Weekend data sometimes wrong, volume can be inaccurate. Alpha Vantage: Real-time on paid tier, cleaner data, but free tier has rate limits. Polygon: Tick-level accuracy, verified trades, microsecond timestamps, corporate actions handled. Bloomberg: Gold standard, verified by traders, no errors, complete history. (2) Latency: yfinance: 15-min delay (unusable for intraday). Alpha Vantage: ~1 second latency (free), ~100ms (paid). Polygon: <50ms latency (WebSocket), good for intraday. Bloomberg: <10ms, suitable for institutional HFT. (3) Coverage: yfinance: US stocks, ETFs, limited international. History: 20+ years. Alpha Vantage: US stocks, forex, crypto. History: 20 years. Polygon: US stocks, options, crypto. History: varies (stocks: 2004+, tick: 1 year). Bloomberg: Everything globally. History: 40+ years. (4) Rate limits: yfinance: None (but slow). Alpha Vantage: 5 calls/min (free), 500/min (paid). Polygon: 5/min (free), unlimited (paid $199+). Bloomberg: Unlimited (but $2000+/month). (5) Cost-benefit: Daily strategies: yfinance sufficient (free). Need: EOD prices, returns, basic fundamentals. MAE improvement with Polygon: ~2-5% (not worth $99/month initially). Intraday strategies: Polygon minimum ($199/month). Need: Minute bars, low latency, reliability. MAE improvement: 10-15% vs yfinance (worth it if trading >$10k). HFT strategies: Bloomberg/professional feeds ($2000+/month). Need: Microsecond latency, order book data. Edge: Milliseconds matter at this scale. Decision framework: Paper trading: yfinance (free, learn the system). Live trading <$10k capital: Polygon basic ($99/month). Live trading >$50k capital: Polygon pro ($499/month). Institutional: Bloomberg ($2000+/month). Break-even: If improved data increases Sharpe from 1.0 to 1.15 (15% improvement), worth $200/month if trading >$30k capital (assuming 1% monthly return = $300, 15% improvement = $45, pays for data). Upgrade triggers: Strategy consistently profitable for 3+ months, capital >$10k, need faster execution, data gaps causing losses.',
    keyPoints: [
      'Quality: yfinance has gaps/delays, Polygon verified, Bloomberg gold standard',
      'Latency: yfinance 15-min, Polygon <50ms, Bloomberg <10ms (matters for strategy type)',
      'Rate limits: yfinance none, Alpha Vantage 5/min free, Polygon unlimited paid',
      'Daily strategies: yfinance OK, intraday needs Polygon ($199/month), HFT needs Bloomberg',
      'Upgrade when: capital >$10k, consistently profitable, data quality impacts performance',
    ],
  },
  {
    id: 'fdsa-q-3',
    question:
      'Design an alternative data integration system. Sources: news sentiment, Reddit mentions, options flow, insider trading. How do you: (1) Collect and parse each data type, (2) Quantify signals (sentiment score, unusual activity threshold), (3) Integrate with price data, (4) Backtest alternative data strategies, (5) Handle real-time updates. What edge do alternative data provide?',
    sampleAnswer:
      "Alternative data system: (1) Collection: News sentiment: RSS feeds (Google News, Bloomberg), scrape headlines every 5 minutes. Parse with NLP: sentiment = (positive_words - negative_words) / total_words. Or use FinBERT (transformer for finance). Store: CREATE TABLE news (timestamp, symbol, headline, sentiment_score, source). Reddit mentions: Use PRAW (Reddit API), monitor r/wallstreetbets, r/stocks. Parse submissions + comments for ticker mentions. Count frequency, aggregate sentiment. Store: mentions_per_hour, sentiment_avg. Options flow: Requires paid data (e.g., Market Chameleon, FlowAlgo). Track: unusual_volume = volume / avg_volume_20d > 3, large_trades > 1000 contracts, IV_change > 10%. Store: timestamp, symbol, contract, volume, open_interest, IV. Insider trading: Scrape SEC Form 4 filings (EDGAR API). Parse: exec_name, title (CEO/CFO), transaction_type (buy/sell), shares, price, date. Flag: C-level buying = bullish, selling = bearish (or compensation). (2) Quantification: News sentiment: sentiment_score ∈ [-1, 1], aggregate daily. Signal: If avg_sentiment > 0.3 for 3 days → bullish. Reddit: mentions_spike = today_mentions / avg_mentions_30d. Signal: spike > 5x = attention surge. Options: unusual_activity = (volume > 3x avg) AND (volume/OI > 0.5). Signal: Large calls = bullish, large puts = bearish. Insider: net_insider_buying = sum(buy_shares) - sum(sell_shares) over 30 days. Signal: >10% of float = strong signal. (3) Integration with prices: Merge all signals by (date, symbol). Features: [return_t-1, volume_t-1, sentiment_score, reddit_mentions, unusual_options, insider_net]. Normalize: StandardScaler for each feature. Model: XGBoost or LSTM with all features. (4) Backtesting: Walk-forward: Train on [t-252:t], test on [t:t+21]. Signals generated at t-1 (no lookahead). Measure: Strategy return, Sharpe, info ratio vs price-only baseline. Example results: Price-only: Sharpe 0.8, Price + sentiment: Sharpe 1.0 (25% improvement). (5) Real-time updates: WebSocket for news: Connect to news feeds, process on arrival. Async processing: Use message queue (RabbitMQ), workers process sentiment scoring. Cache: Store last 24 hours in Redis for fast access. Aggregation: Update signals every 5 minutes. Integration: Trading system polls signals before each trade. Edge from alternative data: Information before it's priced in. Example: News breaks → sentiment score updates → trade before price fully adjusts. Typical edge: 5-10 basis points per trade, compounds over 1000s of trades. Challenges: Noisy signals (90% of alternative data is noise). Must backtest thoroughly. Cost: News feeds $100-500/month, options flow $200+/month.",
    keyPoints: [
      'Collection: RSS for news, PRAW for Reddit, paid APIs for options flow, SEC EDGAR for insiders',
      'Quantification: sentiment ∈ [-1,1], mention spikes >5x, unusual volume >3x avg',
      'Integration: Merge by (date, symbol), combine with price features in ML model',
      'Backtest: Walk-forward validation, measure Sharpe improvement vs price-only baseline',
      'Edge: 5-10bps per trade from information before price adjusts, but 90% noise',
    ],
  },
];
